<?xml version='1.0' encoding='UTF-8'?>
<dataset sourceName="Interstices" sourceUrl='https://interstices.info/' lang='fr'>
  <data class='com.jalios.jcms.FileDocument' id='p_89732' url='https://interstices.info/jcms/p_89732/figure4'>
    <field name='title'>figure4</field>
    <field name='pdate' time='1458748822142'>2016-03-23T17:00:22+01:00</field>
    <field name='udate' time='1458748822143'>2016-03-23T17:00:22+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1458748822143'>2016-03-23T17:00:22+01:00</field>
    <field name='mdate' time='1458748822143'>2016-03-23T17:00:22+01:00</field>
    <field name='filename' mtime='1458748823000' size='113804' ticket='8ohT5c+U5Dzrks+bJtpNvA=='>upload/docs/image/jpeg/2016-03/figure4.jpg</field>
    <field name='originalFilename'>figure4.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1458748822143'>2016-03-23T17:00:22+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>484</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.Date/Time</key>
        <value>2016:03:23 16:59:16</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.Orientation</key>
        <value>Top, left side (Horizontal / normal)</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.ResolutionUnit</key>
        <value>Inch</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.Software</key>
        <value>Adobe Photoshop CC 2015 (Macintosh)</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.XResolution</key>
        <value>1073240/10000 dots per inch</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.YResolution</key>
        <value>1073240/10000 dots per inch</value>
      </entry>
      <entry>
        <key>image.Exif SubIFD.ColorSpace</key>
        <value>Undefined</value>
      </entry>
      <entry>
        <key>image.Exif SubIFD.ExifImageHeight</key>
        <value>484 pixels</value>
      </entry>
      <entry>
        <key>image.Exif SubIFD.ExifImageWidth</key>
        <value>448 pixels</value>
      </entry>
      <entry>
        <key>image.Exif Thumbnail.ResolutionUnit</key>
        <value>Inch</value>
      </entry>
      <entry>
        <key>image.Exif Thumbnail.ThumbnailCompression</key>
        <value>JPEG (old-style)</value>
      </entry>
      <entry>
        <key>image.Exif Thumbnail.ThumbnailLength</key>
        <value>9785 bytes</value>
      </entry>
      <entry>
        <key>image.Exif Thumbnail.ThumbnailOffset</key>
        <value>310 bytes</value>
      </entry>
      <entry>
        <key>image.Exif Thumbnail.XResolution</key>
        <value>72 dots per inch</value>
      </entry>
      <entry>
        <key>image.Exif Thumbnail.YResolution</key>
        <value>72 dots per inch</value>
      </entry>
      <entry>
        <key>image.Iptc.ApplicationRecordVersion</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Iptc.CodedCharacterSet</key>
        <value>%G</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Progressive, Huffman</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>484 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>448 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.Photoshop.CaptionDigest</key>
        <value>-51 -49 -6 125 -88 -57 -66 9 5 112 118 -82 -81 5 -61 78</value>
      </entry>
      <entry>
        <key>image.Photoshop.ColorHalftoningInformation</key>
        <value>[72 bytes]</value>
      </entry>
      <entry>
        <key>image.Photoshop.ColorTransferFunctions</key>
        <value>[112 bytes]</value>
      </entry>
      <entry>
        <key>image.Photoshop.GlobalAltitude</key>
        <value>30</value>
      </entry>
      <entry>
        <key>image.Photoshop.GlobalAngle</key>
        <value>30</value>
      </entry>
      <entry>
        <key>image.Photoshop.GridandGuidesInformation</key>
        <value>0 0 0 1 0 0 2 64 0 0 2 64 0 0 0 0</value>
      </entry>
      <entry>
        <key>image.Photoshop.ICCUntaggedProfile</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Photoshop.IPTC-NAARecord</key>
        <value>15 bytes binary data</value>
      </entry>
      <entry>
        <key>image.Photoshop.JPEGQuality</key>
        <value>8 (High), Progressive  format, 3 scans</value>
      </entry>
      <entry>
        <key>image.Photoshop.PixelAspectRatio</key>
        <value>1.0</value>
      </entry>
      <entry>
        <key>image.Photoshop.PrintFlags</key>
        <value>0 0 0 0 0 0 0 0 1</value>
      </entry>
      <entry>
        <key>image.Photoshop.PrintFlagsInformation</key>
        <value>0 1 0 0 0 0 0 0 0 2</value>
      </entry>
      <entry>
        <key>image.Photoshop.PrintScale</key>
        <value>Centered, Scale 1.0</value>
      </entry>
      <entry>
        <key>image.Photoshop.ResolutionInfo</key>
        <value>107.324005x107.324005 DPI</value>
      </entry>
      <entry>
        <key>image.Photoshop.SeedNumber</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Photoshop.Slices</key>
        <value>Acr479320857740802504115 (0,0,484,448) 1 Slices</value>
      </entry>
      <entry>
        <key>image.Photoshop.ThumbnailData</key>
        <value>JpegRGB, 148x160, Decomp 71040 bytes, 1572865 bpp, 9785 bytes</value>
      </entry>
      <entry>
        <key>image.Photoshop.URLList</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Photoshop.VersionInfo</key>
        <value>1 (Adobe Photoshop, Adobe Photoshop CC 2015) 1</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>448</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89734' url='https://interstices.info/jcms/p_89734/figure1'>
    <field name='title'>figure1</field>
    <field name='pdate' time='1458749226037'>2016-03-23T17:07:06+01:00</field>
    <field name='udate' time='1458749226039'>2016-03-23T17:07:06+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1458749226039'>2016-03-23T17:07:06+01:00</field>
    <field name='mdate' time='1458749226039'>2016-03-23T17:07:06+01:00</field>
    <field name='filename' mtime='1458749227000' size='26511' ticket='UFx81s6uirrYza8Ze62tFg=='>upload/docs/image/jpeg/2016-03/figure1.jpg</field>
    <field name='originalFilename'>figure1.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1458749226039'>2016-03-23T17:07:06+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>150</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>150 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89735' url='https://interstices.info/jcms/p_89735/figure2'>
    <field name='title'>figure2</field>
    <field name='pdate' time='1458749244981'>2016-03-23T17:07:24+01:00</field>
    <field name='udate' time='1458749244982'>2016-03-23T17:07:24+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1458749244983'>2016-03-23T17:07:24+01:00</field>
    <field name='mdate' time='1458749244983'>2016-03-23T17:07:24+01:00</field>
    <field name='filename' mtime='1458749245000' size='39390' ticket='qCxYuxDwsjqFnYofLx7ZPg=='>upload/docs/image/jpeg/2016-03/figure2.jpg</field>
    <field name='originalFilename'>figure2.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1458749244983'>2016-03-23T17:07:24+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>189</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>189 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89738' url='https://interstices.info/jcms/p_89738/figure3'>
    <field name='title'>figure3</field>
    <field name='pdate' time='1458750050892'>2016-03-23T17:20:50+01:00</field>
    <field name='udate' time='1458750050894'>2016-03-23T17:20:50+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1458750050894'>2016-03-23T17:20:50+01:00</field>
    <field name='mdate' time='1458750050894'>2016-03-23T17:20:50+01:00</field>
    <field name='filename' mtime='1458750051000' size='55948' ticket='P0PYQF5/DbLvmoxDK0dKkQ=='>upload/docs/image/jpeg/2016-03/figure3_2016-03-23_17-20-50_884.jpg</field>
    <field name='originalFilename'>figure3.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1458750050894'>2016-03-23T17:20:50+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>136</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.Date/Time</key>
        <value>2016:03:23 17:20:02</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.Orientation</key>
        <value>Top, left side (Horizontal / normal)</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.ResolutionUnit</key>
        <value>Inch</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.Software</key>
        <value>Adobe Photoshop CC 2015 (Macintosh)</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.XResolution</key>
        <value>144 dots per inch</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.YResolution</key>
        <value>144 dots per inch</value>
      </entry>
      <entry>
        <key>image.Exif SubIFD.ColorSpace</key>
        <value>Undefined</value>
      </entry>
      <entry>
        <key>image.Exif SubIFD.ExifImageHeight</key>
        <value>136 pixels</value>
      </entry>
      <entry>
        <key>image.Exif SubIFD.ExifImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Exif Thumbnail.ResolutionUnit</key>
        <value>Inch</value>
      </entry>
      <entry>
        <key>image.Exif Thumbnail.ThumbnailCompression</key>
        <value>JPEG (old-style)</value>
      </entry>
      <entry>
        <key>image.Exif Thumbnail.ThumbnailLength</key>
        <value>2445 bytes</value>
      </entry>
      <entry>
        <key>image.Exif Thumbnail.ThumbnailOffset</key>
        <value>310 bytes</value>
      </entry>
      <entry>
        <key>image.Exif Thumbnail.XResolution</key>
        <value>72 dots per inch</value>
      </entry>
      <entry>
        <key>image.Exif Thumbnail.YResolution</key>
        <value>72 dots per inch</value>
      </entry>
      <entry>
        <key>image.Iptc.ApplicationRecordVersion</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Iptc.CodedCharacterSet</key>
        <value>%G</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Progressive, Huffman</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>136 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.Photoshop.CaptionDigest</key>
        <value>-51 -49 -6 125 -88 -57 -66 9 5 112 118 -82 -81 5 -61 78</value>
      </entry>
      <entry>
        <key>image.Photoshop.ColorHalftoningInformation</key>
        <value>[72 bytes]</value>
      </entry>
      <entry>
        <key>image.Photoshop.ColorTransferFunctions</key>
        <value>[112 bytes]</value>
      </entry>
      <entry>
        <key>image.Photoshop.GlobalAltitude</key>
        <value>30</value>
      </entry>
      <entry>
        <key>image.Photoshop.GlobalAngle</key>
        <value>30</value>
      </entry>
      <entry>
        <key>image.Photoshop.GridandGuidesInformation</key>
        <value>0 0 0 1 0 0 2 64 0 0 2 64 0 0 0 0</value>
      </entry>
      <entry>
        <key>image.Photoshop.ICCUntaggedProfile</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Photoshop.IPTC-NAARecord</key>
        <value>15 bytes binary data</value>
      </entry>
      <entry>
        <key>image.Photoshop.JPEGQuality</key>
        <value>8 (High), Progressive  format, 3 scans</value>
      </entry>
      <entry>
        <key>image.Photoshop.PixelAspectRatio</key>
        <value>1.0</value>
      </entry>
      <entry>
        <key>image.Photoshop.PrintFlags</key>
        <value>0 0 0 0 0 0 0 0 1</value>
      </entry>
      <entry>
        <key>image.Photoshop.PrintFlagsInformation</key>
        <value>0 1 0 0 0 0 0 0 0 2</value>
      </entry>
      <entry>
        <key>image.Photoshop.PrintScale</key>
        <value>Centered, Scale 1.0</value>
      </entry>
      <entry>
        <key>image.Photoshop.ResolutionInfo</key>
        <value>144.0x144.0 DPI</value>
      </entry>
      <entry>
        <key>image.Photoshop.SeedNumber</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Photoshop.Slices</key>
        <value>figure3 (0,0,136,750) 1 Slices</value>
      </entry>
      <entry>
        <key>image.Photoshop.ThumbnailData</key>
        <value>JpegRGB, 160x29, Decomp 13920 bytes, 1572865 bpp, 2445 bytes</value>
      </entry>
      <entry>
        <key>image.Photoshop.URLList</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Photoshop.VersionInfo</key>
        <value>1 (Adobe Photoshop, Adobe Photoshop CC 2015) 1</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89771' url='https://interstices.info/jcms/p_89771/realite-augmentee750'>
    <field name='title'>realite-augmentee750</field>
    <field name='pdate' time='1458903464474'>2016-03-25T11:57:44+01:00</field>
    <field name='udate' time='1458903464476'>2016-03-25T11:57:44+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1458903464476'>2016-03-25T11:57:44+01:00</field>
    <field name='mdate' time='1458903464476'>2016-03-25T11:57:44+01:00</field>
    <field name='filename' mtime='1458903465000' size='51475' ticket='VqtKz6jmOXk4pQu8bD1BiQ=='>upload/docs/image/jpeg/2016-03/realite-augmentee750.jpg</field>
    <field name='originalFilename'>realite-augmentee750.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1458903464476'>2016-03-25T11:57:44+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>300</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>300 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='generated.DocumentInterstices' id='p_83629' url='https://interstices.info/jcms/p_83629/realite-augmentee-entre-mythes-et-realites'>
    <field name='title'>Réalité augmentée : entre mythes et réalités</field>
    <field name='categories'>
      <item id='jalios_5000' class='com.jalios.jcms.Category'>Navigation/Rubriques/De la recherche</item>
      <item id='mf_46785' class='com.jalios.jcms.Category'>Tags/Virtuel</item>
      <item id='mf_46790' class='com.jalios.jcms.Category'>Tags/Technologie</item>
      <item id='mf_46802' class='com.jalios.jcms.Category'>Tags/Utilisateur</item>
      <item id='i_54981' class='com.jalios.jcms.Category'>Classification UNIT/Informatique/13.13 Réalité virtuelle et retour d&apos;effort</item>
      <item id='i_62034' class='com.jalios.jcms.Category'>CatTemporaire</item>
    </field>
    <field name='pdate' time='1459414800000'>2016-03-31T11:00:00+02:00</field>
    <field name='udate' time='1430735019483'>2015-05-04T12:23:39+02:00</field>
    <field name='version' major='1' minor='67'>1.67</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>full.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='int_64630' class='com.jalios.jcms.Member' login='maxime'>Maxime Amblard</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1430735019483'>2015-05-04T12:23:39+02:00</field>
    <field name='mdate' time='1462880767461'>2016-05-10T13:46:07+02:00</field>
    <field name='resume' abstract='true'>Intégrer des éléments virtuels dans des images réelles, en temps réel et en trois dimensions : comment fait-on ? À quoi cela sert-il ?</field>
    <field name='chapo'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Intégrer des éléments virtuels dans des images réelles, en temps réel et en trois dimensions : comment fait-on ? À quoi cela sert-il ?&lt;/p&gt;&lt;/div&gt;</field>
    <field name='imageChapeau'>upload/docs/image/jpeg/2016-03/realite-augmentee750.jpg</field>
    <field name='legendeImageChapeau'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Au &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.musee-orsay.fr/fr/info/mecenat/operation-courbet.html&quot; target=&quot;_blank&quot;&gt;musée d&apos;Orsay&lt;/a&gt;, les dispositifs de réalité augmentée au service de l&apos;art ont rapidement séduit le public ! &lt;br /&gt;Photo by &lt;span class=&quot;lienExterne&quot;&gt;Jean-Pierre Dalbéra&lt;/span&gt;, sur &lt;a class=&quot;lienExterne&quot; href=&quot;https://flic.kr/p/sascaV&quot; target=&quot;_blank&quot;&gt;Flickr&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</field>
    <field name='texte'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;La réalité augmentée vise à accroître notre perception de l&apos;environnement par ajout d&apos;informations de différentes natures. Bien qu&apos;elle puisse concerner les cinq sens, les informations ajoutées sont le plus souvent visuelles (textes, symboles ou images 3D). L&apos;expression est apparue au début des années 1990, mais n&apos;a connu de réel succès qu&apos;après l&apos;arrivée sur le marché de téléphones portables et de tablettes compatibles avec cette technologie. Passée une certaine période d&apos;engouement, la réalité augmentée est aujourd&apos;hui perçue de diverses manières par le grand public. Certains doutent de son utilité et de son avenir, d&apos;autres la considèrent comme une menace pour le respect de la vie privée et des libertés individuelles. Des technophiles convaincus y voient à l&apos;inverse un potentiel immense, sans être parfaitement conscients de ses limites intrinsèques. Ces différentes réactions, bien que légitimes, sont selon nous essentiellement dues à une méconnaissance de ce qu&apos;est exactement la réalité augmentée, de ce qu&apos;elle permet ou ne permet pas de faire, des applications utiles qu&apos;elle a déjà rendu possibles, et de celles auxquelles on peut raisonnablement s&apos;attendre dans les années à venir.&lt;/p&gt;&lt;p&gt;L&apos;expression « réalité augmentée » est définie de manière relativement précise : il s&apos;agit d&apos;incruster des éléments virtuels dans des images réelles (et non l&apos;inverse), en temps réel et en trois dimensions. Selon cette définition stricte, afficher des informations confidentielles sur la personne assise en face de soi à travers des lunettes connectées comme les Google Glass ne relève pas à proprement parler de la réalité augmentée, au sens où cela ne requiert pas d&apos;aligner spatialement les parties réelle et virtuelle de l&apos;image. Les Google Glass n&apos;exploitent pas encore à pleine puissance le principe de la réalité augmentée, des informations contextualisées y sont simplement affichées en surimpression de notre vision.&lt;/p&gt;&lt;p&gt;L&apos;intégration d&apos;un élément virtuel doit être géométriquement correcte, ce qui signifie que l&apos;élément ajouté doit être projeté dans l&apos;image avec le point de vue adopté par la caméra réelle. Pouvoir inférer le point de vue de la caméra à partir de l&apos;image est ainsi le premier besoin fondamental d&apos;un système de réalité augmentée. Ceci ne suffit cependant pas à assurer le réalisme géométrique, car il faut gérer les éventuelles occultations entre l&apos;objet ajouté et la scène.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;img title=&quot;figure1.&quot; src=&quot;upload/docs/image/jpeg/2016-03/figure1.jpg&quot; alt=&quot;figure1&quot; width=&quot;750&quot; height=&quot;150&quot; /&gt;&lt;br /&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Comment intégrer de manière cohérente un objet virtuel 3D dans une image réelle. (a) Image réelle représentant une carte mère sur&lt;br /&gt;laquelle on souhaite ajouter une barette mémoire virtuelle. (b) La barette virtuelle est positionnée par rapport à un modèle 3D, clone virtuel de l&apos;objet à augmenter. Entre l&apos;image (a) et l&apos;image (b), le point de vue est différent. (c) Le modèle 3D est projeté dans l&apos;image (a), de manière à être parfaitement aligné avec l&apos;objet réel : c&apos;est l&apos;étape cruciale du calcul du point de vue. (d) La barette mémoire est finalement affichée par-dessus l&apos;image réelle, en respectant la perspective de l&apos;image.&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;&lt;img title=&quot;figure2.&quot; src=&quot;upload/docs/image/jpeg/2016-03/figure2.jpg&quot; alt=&quot;figure2&quot; width=&quot;750&quot; height=&quot;189&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Le problème des occultations du virtuel par le réel. (a) Une partie de la barette (virtuelle) semble dépasser du slot mémoire (réel) : il s&apos;agit&lt;br /&gt;d&apos;une incohérence visuelle liée au fait que le dessin de l&apos;objet virtuel se fait entièrement par-dessus l&apos;image réelle. (b) C&apos;est encore une fois la connaissance du modèle 3D qui va nous permettre de résoudre ce problème : comme le modèle est correctement projeté dans l&apos;image, on sait quelle partie de l&apos;objet virtuel est censée être occultée par l&apos;objet réel. (c) Nouvelle représentation de l&apos;objet virtuel, tenant compte de cette connaissance.&lt;/p&gt;&lt;h2&gt;Le rôle du modèle dans un système de réalité augmentée&lt;/h2&gt;&lt;p&gt;Par ailleurs, la perception réaliste de la scène augmentée dépend fortement de la prise en compte des interactions lumineuses, donc des ombrages, entre réel et virtuel. À titre d&apos;exemple, un objet correctement positionné sur un plan sans prise en compte des effets d&apos;ombrage semblera flotter, alors que l&apos;ajout d&apos;une ombre portée permettra d&apos;avoir la sensation que l&apos;objet est bien ancré sur le sol.&lt;/p&gt;&lt;p&gt;Toutes ces tâches nécessitent de posséder un modèle 3D de la scène, mais la nature de ce modèle n&apos;est pas identique selon le problème considéré. Pour le calcul du point de vue, la formation d&apos;une image étant modélisée par une projection perspective, il suffit d&apos;identifier dans l&apos;image un ensemble de points 2D qui correspondent à des points 3D du modèle. Ainsi, un modèle de type « nuage de points » suffit à se positionner par rapport à l&apos;environnement. Dans le cas des occultations ou des inter-réflexions lumineuses, un modèle structuré est nécessaire. En effet, pour vérifier qu&apos;un pixel de l&apos;objet ajouté est ou n&apos;est pas occulté par un élément de la scène réelle, il faut comparer les profondeurs respectives de la scène et de l&apos;objet ajouté. Une connaissance surfacique de la scène est donc nécessaire. Il en est de même pour la gestion des inter-réflexions lumineuses, puisque l&apos;ombrage est calculé à partir d&apos;un modèle global de la scène, ou lors de la gestion de l&apos;interaction entre l&apos;utilisateur et les objets de la scène. La précision requise sur le modèle n&apos;est pas identique selon la tâche considérée. Si un modèle précis est nécessaire pour la gestion des occultations, un modèle grossier suffit pour les ombrages car, s&apos;il est important qu&apos;on perçoive l&apos;ombrage pour comprendre la scène, sa précision n&apos;a que peu d&apos;impact sur cette compréhension.&lt;/p&gt;&lt;p&gt;L&apos;acquisition d&apos;un modèle structuré est donc fondamentale pour la prise en compte de l&apos;interactivité dans un système de réalité augmentée. Il existe aujourd&apos;hui des méthodes automatiques de construction de nuages de points 3D à partir d&apos;images. L&apos;arrivée de la &lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/Kinect&quot; target=&quot;_blank&quot;&gt;Kinect&lt;/a&gt; a également permis d&apos;acquérir des modèles relativement denses pour des scènes peu profondes. Cependant, la construction de modèles structurés et précis nécessaires à l&apos;interactivité est plus délicate et est souvent réalisée hors ligne.&lt;/p&gt;&lt;h2&gt;Des exemples de systèmes effectifs&lt;/h2&gt;&lt;p&gt;Pour réaliser un système qui fonctionne, il n&apos;est pas toujours indispensable de résoudre l&apos;ensemble des problèmes évoqués ci-dessus. Les musées et sites historiques sont des exemples d&apos;espaces clos et balisés dans lesquels il est relativement aisé d&apos;introduire de la réalité augmentée. Des « tags » ou marqueurs visuels, utiles au positionnement, peuvent être placés à différents endroits de la visite et visés à travers l&apos;écran d&apos;une tablette numérique pour voir la scène augmentée.&lt;/p&gt;&lt;p&gt;La réalité augmentée est ainsi expérimentée au quotidien par des centaines de visiteurs dans des musées et lieux historiques tels que le &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.chambord.org/blog/histopad-chambord-votre-premier-voyage-dans-le-temps-a-lepoque-de-francois-ier/&quot; target=&quot;_blank&quot;&gt;château de Chambord&lt;/a&gt;, le château de Selles-sur-Cher ou le musée de Bibracte... pour ne citer que quelques exemples en France. Dans l&apos;industrie, il est également envisageable de mesurer et de préparer l&apos;environnement dans lequel un système de réalité augmentée sera utilisé. Des répliques virtuelles des lignes de productions, incluant les objets fabriqués ou les pièces assemblées (sous forme de modèles de &lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/Conception_assist%C3%A9e_par_ordinateur&quot; target=&quot;_blank&quot;&gt;conception assistée par ordinateur&lt;/a&gt; par exemple), mais aussi les automates programmables et les machines-outils, sont de plus en plus fréquemment exploités dans l&apos;industrie à des fins de simulation, d&apos;estimation des coûts, de formation et de diagnostic. Dans ce contexte de digitalisation croissante de l&apos;usine, la réalité augmentée semble toute indiquée pour « aligner » au plus près l&apos;usine numérique et l&apos;usine réelle, offrant à l&apos;opérateur humain des informations visuelles et contextuelles de nature à lui faciliter la tâche, notamment dans les domaines de la conception, de l&apos;assemblage, de la maintenance et du contrôle qualité. Récemment, Airbus a ainsi décidé d&apos;implanter la réalité augmentée de façon industrielle pour le marquage au sol des emplacements de fixation les sièges des cabines de l&apos;A330. Une expérience réalisée sur cinq appareils en cours d&apos;assemblage a permis de réduire par cinq le temps de travail tout en conservant un taux d&apos;erreur nul y compris chez les techniciens les moins expérimentés. Un autre exemple, toujours chez Airbus, est la vérification de l&apos;emplacement des « brackets » de l&apos;A380. Ces pièces, qui fixent dans chaque appareil les parois intérieures au fuselage, sont très nombreuses (plus de 60 000 dans un A380). Grâce à la réalité augmentée, les opérateurs munis de tablettes numériques procèdent à leur vérification en deux jours au lieu de plusieurs semaines auparavant.&lt;/p&gt;&lt;h2&gt;Le problème fondamental du calcul du point de vue&lt;/h2&gt;&lt;p&gt;Dans ces applications, des « tags » ou « marqueurs » facilement détectables dans l’environnement sont souvent utilisés pour faciliter la détection de correspondances 2D/3D et assurer la fiabilité de l’incrustation. Néanmoins, une telle instrumentation de l’environnement s’avère impossible dans de nombreuses applications, notamment celles se tenant en extérieur, soit parce que la scène est protégée, s&apos;il s&apos;agit d&apos;un lieu historique, soit parce qu’elle est vaste et qu’on ne sait pas où va se concentrer l’action de l’utilisateur. On ne peut évidemment pas truffer la scène de milliers de « tags » ! Des méthodes de calcul de point de vue dites « sans marqueur » ont donc fait l’objet de nombreux travaux depuis une quinzaine d’années. Elles visent à établir directement des correspondances entre le modèle et l&apos;image sans l’aide d’indices facilement détectables. La difficulté majeure vient du fait qu’il existe beaucoup d’hypothèses erronées de mise en correspondance, dues en particulier à la présence de motifs répétés dans les environnements urbains et industriels.&lt;/p&gt;&lt;p&gt;Des solutions existent désormais via, d&apos;une part, le développement de méthodes statistiques robustes permettant de ne pas prendre en compte les mises en correspondance erronées, et d&apos;autre part, grâce à une évolution dans l&apos;idée de ce que doit contenir un modèle 3D. Les modèles initiaux étaient de type CAO, et décrivaient seulement des transitions géométriques, qui n&apos;étaient souvent que peu détectables sur l&apos;image. Aujourd&apos;hui, la tendance est à la conception de modèles intégrant la géométrie du modèle et sa &lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/Photom%C3%A9trie_%28optique%29&quot; target=&quot;_blank&quot;&gt;photométrie&lt;/a&gt;, facilitant ainsi grandement la mise en relation entre le modèle et l&apos;image. Le problème de la mise en correspondance est ainsi converti en un problème de classification, chaque classe étant représentée par les différents aspects que peut prendre ce point dans une séquence d&apos;apprentissage. Cependant, un certain nombre de difficultés subsistent, en particulier pour établir des similarités géométriques ou photométriques entre modèles et images. Ces difficultés surviennent en particulier lorsque les images acquises pour construire le modèle et l’image courante sont prises sous des points de vue très différents. En ce qui concerne la photométrie, de nombreux facteurs dont l’ensoleillement et les conditions climatiques, comme la saison ou le temps pluvieux, contribuent à rendre les images prises lors de l’application très différentes de celles utilisées pour construire le modèle. Par ailleurs, les scènes « bougent » fréquemment entre l’acquisition et l’application, en raison de la présence de voitures, de modifications du mobilier urbain ou de déplacements d’objets. Les recherches dans le domaine du calcul du point de vue sont toujours très actives, afin de rendre les algorithmes robustes à de forts changements de points de vue, de conditions climatiques et de modifications partielles du modèle. De plus, n’oublions pas que la réalité augmentée est par nature interactive et qu’une difficulté supplémentaire est de développer des algorithmes temps réel et si possible portables sur architecture mobile.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;img title=&quot;figure3.&quot; src=&quot;upload/docs/image/jpeg/2016-03/figure3_2016-03-23_17-20-50_884.jpg&quot; alt=&quot;figure3&quot; width=&quot;750&quot; height=&quot;136&quot; /&gt;&lt;br /&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Prise en compte de la photométrie dans la description des modèles 3D. Ici, un descripteur de points invariant aux rotations et changements &lt;br /&gt;d&apos;échelle (SIFT) permet de mettre en correspondance des points extraits de la texture du modèle avec les mêmes points détectés dans une &lt;br /&gt;image vidéo où la déformation perspective de la façade est importante. Une méthode statistique robuste est utilisée pour distinguer les &lt;br /&gt;correspondances correctes (en vert) des correspondances erronées (en rouge).&lt;/p&gt;&lt;h2&gt;La réalité augmentée pour le médical : une application prometteuse&lt;/h2&gt;&lt;p&gt;Un champ d&apos;applications dans lequel la réalité augmentée semble extrêmement prometteuse est le domaine médical, en particulier en chirurgie. Pouvoir visualiser une tumeur extraite dans des données pré-opératoires sur des images per-opératoires acquises au bloc n&apos;est plus de la science-fiction. Dans le cas d&apos;organes non déformables, des prototypes existent depuis longtemps. Cependant, le véritable défi est d&apos;étendre la capacité d&apos;augmentation à des organes déformables (foie, rein) et d&apos;ajuster le positionnement de la tumeur pendant le geste chirurgical qui peut soumettre l&apos;organe à de fortes déformations. Ce domaine de recherche est actuellement en plein essor, mais le problème est rendu difficile par le faible champ de vue disponible en &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.chirurgie-mini-invasive.com/&quot; target=&quot;_blank&quot;&gt;chirurgie mini-invasive&lt;/a&gt; et la difficulté de construire des modèles d&apos;organes déformables réalistes. L&apos;utilisation de modèles bio-mécaniques est de ce point de vue une voie prometteuse.&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;&lt;img title=&quot;figure4.&quot; src=&quot;upload/docs/image/jpeg/2016-03/figure4.jpg&quot; alt=&quot;figure4&quot; width=&quot;448&quot; height=&quot;484&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Superposition du réseau vasculaire du foie sur des images endoscopiques pendant&lt;br /&gt;la déformation de l&apos;organe. Coopération entre les équipes de recherche Magrit et Shacra &lt;br /&gt;[Haouchine 2013, Int. Symp. on Mixed and Augmented Reality].&lt;/p&gt;&lt;p&gt;Pour conclure, soulignons qu&apos;un objet recalé correctement sur le visuel est nécessaire mais pas suffisant pour qu&apos;un système de réalité augmentée soit accepté par l&apos;utilisateur. Pour cela, il faut que le rendu de l&apos;image augmentée lui permette facilement d&apos;interpréter la scène augmentée pour pouvoir ensuite faire un geste clinique. Concevoir des moyens de rendu permettant une meilleure perception, notamment de la profondeur, est aujourd&apos;hui la préoccupation d&apos;un nombre croissant de chercheurs, de manière à ce que les systèmes de réalité augmentée puissent réellement entrer dans le quotidien du clinicien.&lt;/p&gt;&lt;p&gt;Plus généralement, dans les divers secteurs d&apos;activités concernés, des améliorations sont encore attendues avant que la réalité augmentée puisse être d&apos;abord introduite puis acceptée. Ces améliorations portent sur l&apos;utilisabilité, c&apos;est-à-dire la facilité de mise en œuvre des systèmes de réalité augmentée et l&apos;acquisition des modèles, sur la fiabilité du tracking en environnements non contrôlés et sur l&apos;ergonomie, en particulier le confort visuel et la liberté de déplacements.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='imagette'>upload/docs/image/jpeg/2016-03/realite-augmentee-img.jpg</field>
    <field name='auteurs'>
      <item id='p_89567' class='generated.Auteur'>Berger</item>
      <item id='p_87389' class='generated.Auteur'>Simon</item>
    </field>
    <field name='moissonnable'>true</field>
    <field name='motsCles'>
      <item>réalité augmentée</item>
      <item>modèle 3D</item>
      <item>traitement image</item>
      <item>classification image</item>
    </field>
    <field name='indiceDewey'>
      <item>006.8</item>
    </field>
    <field name='publicVise'>
      <item>enseignement supérieur</item>
      <item>enseignement secondaire</item>
      <item>autres</item>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89703' url='https://interstices.info/jcms/p_89703/des-robots-au-service-des-hommes'>
    <field name='title'>Des robots au service des hommes</field>
    <field name='categories'>
      <item id='c_34623' class='com.jalios.jcms.Category'>Podcasts</item>
      <item id='c_34624' class='com.jalios.jcms.Category'>Podcasts/Catégorie des Podcasts</item>
      <item id='c_34625' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes</item>
      <item id='c_34673' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes/Sciences et médecine</item>
      <item id='c_34687' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes/Technologies</item>
      <item id='mf_46782' class='com.jalios.jcms.Category'>Tags/Robot</item>
      <item id='mf_46802' class='com.jalios.jcms.Category'>Tags/Utilisateur</item>
      <item id='mf_46803' class='com.jalios.jcms.Category'>Tags/Apprentissage</item>
    </field>
    <field name='pdate' time='1459346400000'>2016-03-30T16:00:00+02:00</field>
    <field name='udate' time='1458916515913'>2016-03-25T15:35:15+01:00</field>
    <field name='version' major='3' minor='2'>3.2</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1458557318224'>2016-03-21T11:48:38+01:00</field>
    <field name='mdate' time='1459346837454'>2016-03-30T16:07:17+02:00</field>
    <field name='description' mlField='descriptionML' abstract='true'>Soixante-et-onzième épisode du podcast Interstices : Serena Ivaldi, roboticienne, répond aux questions de Joanna Jongwane.</field>
    <field name='filename' mtime='1458916516000' size='16361746' ticket='BveqJumso/EfBD4zacXzAw=='>upload/docs/audio/mpeg/2016-03/des_robots_au_service_des_hommes_.mp3</field>
    <field name='originalFilename'>Des robots au service des hommes .mp3</field>
    <field name='contentType'>audio/mpeg</field>
    <field name='uploadDate' time='1458916515907'>2016-03-25T15:35:15+01:00</field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89843' url='https://interstices.info/jcms/p_89843/main-robot'>
    <field name='title'>main-robot</field>
    <field name='pdate' time='1459343481546'>2016-03-30T15:11:21+02:00</field>
    <field name='udate' time='1459343481548'>2016-03-30T15:11:21+02:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1459343481548'>2016-03-30T15:11:21+02:00</field>
    <field name='mdate' time='1459343481548'>2016-03-30T15:11:21+02:00</field>
    <field name='filename' mtime='1459343482000' size='41137' ticket='LF7+UuFPm822T3sCXxa4Yw=='>upload/docs/image/jpeg/2016-03/main-robot.jpg</field>
    <field name='originalFilename'>main-robot.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1459343481548'>2016-03-30T15:11:21+02:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>260</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>260 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>749 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>749</value>
      </entry>
    </field>
  </data>
  <data class='generated.DocumentInterstices' id='p_88305' url='https://interstices.info/jcms/p_88305/des-robots-au-service-des-hommes'>
    <field name='title'>Des robots au service des hommes</field>
    <field name='categories'>
      <item id='jalios_5000' class='com.jalios.jcms.Category'>Navigation/Rubriques/De la recherche</item>
      <item id='mf_46782' class='com.jalios.jcms.Category'>Tags/Robot</item>
      <item id='mf_46802' class='com.jalios.jcms.Category'>Tags/Utilisateur</item>
      <item id='mf_46803' class='com.jalios.jcms.Category'>Tags/Apprentissage</item>
      <item id='new_47667' class='com.jalios.jcms.Category'>Navigation/Médias/Podcast</item>
      <item id='i_54903' class='com.jalios.jcms.Category'>Classification UNIT/Automatique/9.06 Robotique, vision et image</item>
      <item id='i_62034' class='com.jalios.jcms.Category'>CatTemporaire</item>
      <item id='ni_79457' class='com.jalios.jcms.Category'>Classification UNIT/Automatique/9.07 Systèmes Homme-Machine , ergonomie, anthropotechnique, biotechnologies, relations homme-machines</item>
    </field>
    <field name='pdate' time='1459346400000'>2016-03-30T16:00:00+02:00</field>
    <field name='udate' time='1452596894600'>2016-01-12T12:08:14+01:00</field>
    <field name='version' major='1' minor='21'>1.21</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>full.pod</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1452596894600'>2016-01-12T12:08:14+01:00</field>
    <field name='mdate' time='1462880936681'>2016-05-10T13:48:56+02:00</field>
    <field name='resume' abstract='true'>Comprendre les interactions entre les robots et les humains pour faciliter leur acceptation, voilà un des défis qui anime la chercheuse Serena Ivaldi au quotidien. Elle nous en parle dans cet épisode du podcast audio. </field>
    <field name='chapo'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Comprendre les interactions entre les robots et les humains pour faciliter leur acceptation, voilà un des défis qui anime la chercheuse Serena Ivaldi au quotidien. Elle nous en parle dans cet épisode du podcast audio.&lt;/p&gt;&lt;/div&gt;</field>
    <field name='imageChapeau'>upload/docs/image/jpeg/2016-03/main-robot.jpg</field>
    <field name='legendeImageChapeau'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;© Fotolia - Pixelbliss&lt;/p&gt;&lt;/div&gt;</field>
    <field name='soustitre'>
    </field>
    <field name='texte'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Bien qu&apos;elle semble encore lointaine, la perspective de l&apos;arrivée massive des robots dans notre quotidien ne relève plus de la science-fiction. Même si ce n&apos;est pas pour tout de suite, cela deviendra certainement une réalité, d&apos;ici quelques décennies.&lt;/p&gt;&lt;p&gt;Doués d&apos;une autonomie croissante, les robots ont un rôle à jouer dans l&apos;environnement humain. Comme nous l&apos;explique Serena Ivaldi, ils peuvent par exemple être très utiles dans la robotique de service ou d&apos;assistance, auprès des personnels soignants ou des personnes âgées. En ce sens, comprendre les mécanismes qui permettent de rendre ces machines plus sûres et de faciliter leur intégration, apparaît primordial d&apos;un point de vue scientifique et sociétal.&lt;/p&gt;&lt;p&gt;Dans le cadre de ses travaux à la frontière entre la robotique et la psychologie, la chercheuse étudie comment les robots interagissent physiquement et socialement avec les humains. Quels sont les mécanismes intervenant dans les interactions homme-robot ? Les enjeux de ces travaux ? Les défis scientifiques à venir ? Serena Ivaldi nous apporte son éclairage sur ces questions.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='imagette'>upload/docs/image/jpeg/2016-03/main-robot115.jpg</field>
    <field name='encarts'>
    </field>
    <field name='auteurs'>
      <item id='p_89620' class='generated.Auteur'>Ivaldi</item>
      <item id='c_24368' class='generated.Auteur'>Jongwane</item>
    </field>
    <field name='podcastItem' id='p_89703' class='com.jalios.jcms.FileDocument'>upload/docs/audio/mpeg/2016-03/des_robots_au_service_des_hommes_.mp3</field>
    <field name='moissonnable'>true</field>
    <field name='motsCles'>
      <item>robotique humanoïde</item>
      <item>interaction homme-machine</item>
      <item>psychologie</item>
    </field>
    <field name='indiceDewey'>
      <item>629.893</item>
      <item>620.82</item>
    </field>
    <field name='publicVise'>
      <item>enseignement supérieur</item>
      <item>enseignement secondaire</item>
      <item>autres</item>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89535' url='https://interstices.info/jcms/p_89535/icub750'>
    <field name='title'>icub750</field>
    <field name='pdate' time='1457019026813'>2016-03-03T16:30:26+01:00</field>
    <field name='udate' time='1457019026819'>2016-03-03T16:30:26+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1457019026819'>2016-03-03T16:30:26+01:00</field>
    <field name='mdate' time='1457019026819'>2016-03-03T16:30:26+01:00</field>
    <field name='filename' mtime='1457019027000' size='57828' ticket='8k+iLuylgmVZQHnu6NAVmg=='>upload/docs/image/jpeg/2016-03/icub750.jpg</field>
    <field name='originalFilename'>icub750.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1457019026819'>2016-03-03T16:30:26+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>260</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>260 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89539' url='https://interstices.info/jcms/p_89539/marche-bipede'>
    <field name='title'>marche-bipede</field>
    <field name='pdate' time='1457019683548'>2016-03-03T16:41:23+01:00</field>
    <field name='udate' time='1457019683549'>2016-03-03T16:41:23+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1457019683550'>2016-03-03T16:41:23+01:00</field>
    <field name='mdate' time='1457019683550'>2016-03-03T16:41:23+01:00</field>
    <field name='filename' mtime='1457019684000' size='9013' ticket='Z8UKHOtAjUX3FtcNUEkDOg=='>upload/docs/image/jpeg/2016-03/marche-bipede.jpg</field>
    <field name='originalFilename'>marche-bipede.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1457019683550'>2016-03-03T16:41:23+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>223</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>223 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>149 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>149</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89540' url='https://interstices.info/jcms/p_89540/poppy'>
    <field name='title'>poppy</field>
    <field name='pdate' time='1457020643122'>2016-03-03T16:57:23+01:00</field>
    <field name='udate' time='1457020643123'>2016-03-03T16:57:23+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1457020643124'>2016-03-03T16:57:23+01:00</field>
    <field name='mdate' time='1457020643124'>2016-03-03T16:57:23+01:00</field>
    <field name='filename' mtime='1457020644000' size='46014' ticket='NDWNn7EjGiC9OCMXS6j2RQ=='>upload/docs/image/jpeg/2016-03/poppy.jpg</field>
    <field name='originalFilename'>poppy.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1457020643124'>2016-03-03T16:57:23+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>333</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>333 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89544' url='https://interstices.info/jcms/p_89544/playground500'>
    <field name='title'>Playground500</field>
    <field name='pdate' time='1457022374377'>2016-03-03T17:26:14+01:00</field>
    <field name='udate' time='1457022374378'>2016-03-03T17:26:14+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1457022374378'>2016-03-03T17:26:14+01:00</field>
    <field name='mdate' time='1457022374378'>2016-03-03T17:26:14+01:00</field>
    <field name='filename' mtime='1457022375000' size='55025' ticket='IfQ0YX5bXSGXHd66GBrqeQ=='>upload/docs/image/jpeg/2016-03/playground500.jpg</field>
    <field name='originalFilename'>Playground500.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1457022374378'>2016-03-03T17:26:14+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>375</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>375 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>500 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>500</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89582' url='https://interstices.info/jcms/p_89582/robot-curieux'>
    <field name='title'>robot-curieux</field>
    <field name='pdate' time='1457347740119'>2016-03-07T11:49:00+01:00</field>
    <field name='udate' time='1457347740120'>2016-03-07T11:49:00+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1457347740120'>2016-03-07T11:49:00+01:00</field>
    <field name='mdate' time='1457347740120'>2016-03-07T11:49:00+01:00</field>
    <field name='filename' mtime='1457347741000' size='43256' ticket='DijNQh0ofJJO+2C907saSQ=='>upload/docs/image/jpeg/2016-03/robot-curieux.jpg</field>
    <field name='originalFilename'>robot-curieux.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1457347740120'>2016-03-07T11:49:00+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>310</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>310 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>650 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>650</value>
      </entry>
    </field>
  </data>
  <data class='generated.DocumentInterstices' id='p_88358' url='https://interstices.info/jcms/p_88358/l-eveil-des-bebes-robots'>
    <field name='title'>L&apos;éveil des bébés robots</field>
    <field name='categories'>
      <item id='jalios_5001' class='com.jalios.jcms.Category'>Navigation/Rubriques/Découvrir</item>
      <item id='mf_46782' class='com.jalios.jcms.Category'>Tags/Robot</item>
      <item id='mf_46803' class='com.jalios.jcms.Category'>Tags/Apprentissage</item>
      <item id='i_54903' class='com.jalios.jcms.Category'>Classification UNIT/Automatique/9.06 Robotique, vision et image</item>
      <item id='i_54949' class='com.jalios.jcms.Category'>Classification UNIT/Informatique/13.10 Intelligence artificielle</item>
      <item id='i_62034' class='com.jalios.jcms.Category'>CatTemporaire</item>
    </field>
    <field name='pdate' time='1458910800000'>2016-03-25T14:00:00+01:00</field>
    <field name='udate' time='1452696383203'>2016-01-13T15:46:23+01:00</field>
    <field name='version' major='1' minor='57'>1.57</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>full.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1452696383203'>2016-01-13T15:46:23+01:00</field>
    <field name='mdate' time='1462881061184'>2016-05-10T13:51:01+02:00</field>
    <field name='resume' abstract='true'>Comment mieux comprendre le développement cognitif d’un enfant ? En mettant dans les mêmes conditions d’apprentissage un robot curieux.</field>
    <field name='chapo'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Comment mieux comprendre le développement cognitif d’un enfant ? En mettant dans les mêmes conditions d’apprentissage un robot curieux.&lt;/p&gt;&lt;/div&gt;</field>
    <field name='imageChapeau'>upload/docs/image/jpeg/2016-03/icub750.jpg</field>
    <field name='legendeImageChapeau'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Les robots (ici &lt;em&gt;ICub&lt;/em&gt;) aident à étudier les interactions du cerveau, du corps et de l’environnement pendant le développement cognitif. &lt;br /&gt;© Inserm / Photo P. Latron&lt;/p&gt;&lt;/div&gt;</field>
    <field name='soustitre'>
    </field>
    <field name='texte'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;&lt;em&gt;&lt;em&gt;Une première version de cet article est parue dans le dossier n°87 &lt;strong&gt; Les robots en quête d&apos;humanité &lt;/strong&gt; de la revue &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.pourlascience.com/index.php&quot; target=&quot;_blank&quot;&gt;Pour la Science&lt;/a&gt;, numéro d&apos;avril/juin 2015.&lt;/em&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Dans son parc, un bambin empile consciencieusement un, deux, trois cubes, puis soudain, détruit l’édifice dans un grand éclat de rire. Et il recommence, avec à chaque fois un plaisir intact. Plus tard, près d’une rivière, il jettera quantité de cailloux pour les voir couler et autant de brindilles pour les suivre des yeux lorsqu’elles partent, flottant à la dérive. Ces gestes, mille fois répétés, ne sont pas anodins. Ils sont nécessaires aux êtres humains, dès leur plus jeune âge, pour comprendre le monde qui les entoure. De fait, les enfants expérimentent, construisent, manipulent, cassent... pour tenter de comprendre les forces physiques. Jean Piaget, l’un des pionniers de la psychologie développementale, a beaucoup étudié le rôle de l’action dans l’apprentissage et la découverte chez les enfants.&lt;br /&gt;La science ne fonctionne pas autrement ! Pour comprendre les vagues de l’océan, les chercheurs conçoivent des aquariums géants. Pour expliquer la formation des galaxies spirales, ils manipulent des simulations sur leurs ordinateurs. Ainsi, l’élaboration de modèles aide à construire un savoir. Qu’en est-il lorsque le sujet d’étude est l’être humain lui-même ? Comment élucider les mécanismes de l’apprentissage humain, des émotions, de la curiosité ? Étonnamment, nous pouvons procéder de la même façon, grâce à des robots !&lt;br /&gt;En effet, les chercheurs élaborent des « bébés robots » qui simulent certains aspects du corps et de l’esprit d’un enfant. Puis ils perturbent ces modèles de façon à déduire des comportements observés des informations sur les mécanismes internes. Les robots sont devenus des outils essentiels pour explorer la complexité du développement comportemental et psychologique d’un enfant.&lt;br /&gt;Les sciences du développement ont invalidé la distinction entre la culture et la nature. On sait aujourd’hui que les gènes ne constituent pas un programme figé qui se déroulerait indépendamment de l’environnement.&lt;br /&gt;Plus important, de nombreux comportements ne peuvent s’expliquer par l’expression de quelques gènes, par le fonctionnement d’organes ou par quelques caractéristiques isolées de l’environnement. À l’inverse, ils traduisent les interactions de cellules, d’organes, de mécanismes d’apprentissage, de propriétés physiques et sociales de l’environnement à diverses échelles spatio-temporelles... En des termes plus techniques, le développement cognitif d’un enfant est un système dynamique complexe caractérisé par des phénomènes spontanés d’auto-organisation. De quoi s’agit-il ?&lt;/p&gt;&lt;h2&gt;Des systèmes complexes&lt;/h2&gt;&lt;p&gt;Les concepts de systèmes complexes et d’auto-organisation ont révolutionné la physique du XX&lt;sup&gt;e&lt;/sup&gt; siècle. Ils s’appliquent à des phénomènes aussi divers que la formation des cristaux de glace, des dunes de sable, des structures galactiques... Ces systèmes se caractérisent notamment par un grand nombre d’entités interagissant et par l’émergence de structures dont le plan global n’est pas présent au départ dans les différentes parties. Les simulations informatiques et les développements des mathématiques ont été un élément clef de l’avènement de ces concepts.&lt;br /&gt;À la fin du XX&lt;sup&gt;e&lt;/sup&gt; siècle, les biologistes se sont emparés de ces idées, par exemple pour comprendre la formation des termitières. Grâce à des modèles, ils ont montré comment des interactions locales de milliers de petits termites, dépourvus de tout plan d’ensemble, peuvent conduire à l’érection de structures globales et fonctionnelles à grande échelle. D’autres simulations ont révélé les mécanismes auto-organisationnels qui expliquent les motifs sur la peau des zèbres et des girafes, les spirales des cornes et des coquilles, les battements du cœur...&lt;br /&gt;Le développement d’un enfant met également en jeu les interactions de nombreux éléments, à un niveau sans commune mesure avec celui des phénomènes précédents. Aussi, pour compléter l’arsenal d’outils conceptuels de la biologie et de la psychologie, les chercheurs ont commencé à construire des machines qui reproduisent certaines étapes du développement d’un enfant.&lt;br /&gt;La construction de machines qui se développent et apprennent comme des enfants n’est toutefois pas une idée entièrement nouvelle. Alan Turing, l’un des pionniers de l’informatique dans les années 1940, avait eu l’intuition de l’utilité des machines pour comprendre les processus psychologiques : « Plutôt que de créer un programme équivalent à l’esprit d’un adulte, pourquoi ne pas tenter d’en concevoir un qui reproduirait le cerveau d’un enfant ? »&lt;br /&gt;Pour plusieurs raisons, les idées de Turing n’ont pas été traduites en un programme de recherche avant la toute fin du XX&lt;sup&gt;e&lt;/sup&gt; siècle. D’abord, les années 1950 ont été celles de l’émergence du cognitivisme et de l’intelligence artificielle. Selon les tenants de ces deux champs scientifiques, l’intelligence est uniquement fondée sur la manipulation de symboles abstraits. Dès lors, ils imaginaient, à tort, pouvoir reproduire directement l’état adulte d’un cerveau.&lt;br /&gt;Ensuite, Turing a négligé deux éléments importants. Pour des organismes réels, l’apprentissage à partir d’une « feuille blanche », sans direction, est inopérant face à un flot gigantesque d’informations arrivant de toutes parts. Au contraire, l’épanouissement d’un enfant a besoin de balises, de mécanismes de guidage ! En outre, Turing n’a pas tenu compte du rôle du corps : le comportement et la cognition s’insèrent dans un « substrat », le corps, qui canalise le développement. Le rôle central du corps est la raison pour laquelle les robots, et non de simples simulations abstraites sur ordinateur, peuvent aider en sciences du développement.&lt;/p&gt;&lt;h2&gt;La marche spontanée&lt;/h2&gt;&lt;p style=&quot;text-align: left;&quot;&gt;&lt;img style=&quot;vertical-align: baseline;&quot; title=&quot;marche-bipede.&quot; src=&quot;upload/docs/image/jpeg/2016-03/marche-bipede.jpg&quot; alt=&quot;marche-bipede&quot; width=&quot;200&quot; height=&quot;299&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;En avant marche ! Cette structure adopte &lt;br /&gt;naturellement une marche bipède bien &lt;br /&gt;qu&apos;elle n&apos;ait ni moteur ni centre de contrôle. &lt;br /&gt;Cette marche est un comportement émergent&lt;br /&gt; qui résulte des interactions de l&apos;anatomie &lt;br /&gt;(mécanique) avec l&apos;environnement.&lt;br /&gt;© S. Collins et al / Photo H. Morgan.&lt;/p&gt;&lt;p&gt;Donnons quelques exemples, tel celui de la bipédie. Bien qu’elle nous soit familière, nous sommes loin de comprendre comment nous marchons sur deux jambes et comment les enfants apprennent à le faire. Ce mode de déplacement suppose une coordination en temps réel de nombreuses parties du corps. Chacun de nos muscles et de nos os est comme un musicien d’un orchestre symphonique jouant sa partition. De la cadence et de la coordination de l’ensemble naîtra une œuvre, en l’occurrence... une marche cohérente et efficace.&lt;br /&gt;Mais y a-t-il une partition qui précise le détail de la coordination ? Y a-t-il un chef d’orchestre ? Le cerveau a-t-il connaissance en permanence de l’état du corps et de l’environnement pour décider d’activer les bons muscles ? En termes plus techniques, la marche est-elle équivalente à un calcul ? La plupart des spécialistes de la marche humaine ont longtemps répondu oui. Dans ce cadre, la compréhension du développement de la marche nécessitait d’expliquer comment les enfants apprennent à effectuer ces calculs en temps réel et à faire des prédictions sur la dynamique du corps. Quelques roboticiens désireux de concevoir des machines bipèdes se sont fondés sur cette vision. Cependant, même si l’on compte quelques jolies performances, la plupart des robots obtenus tombaient facilement et avaient une démarche très peu naturelle. On doit donc se rendre à l’évidence, la marche serait un peu plus qu’un calcul. Ou un peu moins...&lt;br /&gt;Dans les années 1990, le roboticien Tad McGeer a conçu une expérience qui a bouleversé cette conception. Il a construit une paire de jambes mécaniques, calquée sur l’anatomie des membres humains et dépourvue de moteur ou de dispositif de calcul. Lancé sur une pente légère, le dispositif a... marché ! À l’aide des interactions des composants mécaniques et de la gravité, les deux jambes ont automatiquement adopté une démarche similaire à celle d’un humain, le mouvement étant par ailleurs robuste et résistant aux perturbations.&lt;/p&gt;&lt;p&gt;D’autres laboratoires ont reproduit l’expérience et montré que la marche bipède pouvait durer « éternellement » sur un tapis roulant. La coordination des parties mécaniques du « robot », interagissant localement via les contacts physiques, est donc un phénomène auto-organisé à l’instar d’une termitière. La marche est un comportement dynamique émergent où la physique et l’anatomie ont un rôle essentiel, chacune fournissant à l’autre un support et un ensemble de contraintes.&lt;br /&gt;Ces expérimentations révèlent comment des robots aident à élucider les rôles respectifs du corps et du système nerveux dans un modèle de la marche. Ce faisant, ils améliorent notre compréhension du développement humain. Ici, nous observons l’émergence spontanée d’un phénomène (la marche humaine) qui n’est ni inné (il n’est fondé sur aucun gène) ni acquis (l’apprentissage est absent). La distinction entre l’inné et l’acquis est parfois dépourvue de sens.&lt;br /&gt;Une structure, ici la marche bipède, peut apparaître spontanément et émerger d’interactions biophysiques complexes. Une telle structure peut être mise à profit pour l’apprentissage et le développement. L’expérience précédente conduit ainsi à formuler l’hypothèse selon laquelle apprendre à marcher consiste à exploiter des mouvements qui sont inhérents à la dynamique du corps.&lt;br /&gt;Détaillons un second exemple, celui du rôle de la curiosité dans le développement des enfants. Ces derniers assimilent quantité de choses, le plus souvent progressivement, selon une chronologie spécifique. Ainsi, avant de marcher sur deux jambes sans soutien, ils apprennent à contrôler leur cou, puis à ramper sur le ventre, à s’asseoir, à se tenir debout, à marcher en se tenant aux murs... Comment expliquer cette progression ?&lt;br /&gt;Plusieurs étapes d’une telle « trajectoire développementale » apparaissent dans le même ordre chez de nombreux enfants. Cependant, quelques-uns suivent des parcours différents. Comment expliquer, d’une part, cette apparente universalité et, d’autre part, la variabilité individuelle ? Cette universalité est-elle le fruit d’un programme ? Chaque écart signifie-t-il que quelque chose s’est déréglé dans le programme ?&lt;br /&gt;L’environnement social est un élément central dans le guidage des processus développementaux. Il a été l’objet d’études de roboticiens qui se sont intéressés au rôle de l’imitation, de l’attention conjointe, du langage, de la synchronisation enseignant-élève. Mais une autre force tout aussi fondamentale est à l’œuvre en nous : la curiosité. Elle nous pousse à la découverte, à la création, à l’invention...&lt;br /&gt;Des travaux en neurosciences et en psychologie ont montré que notre cerveau est naturellement enclin à tester de nouvelles activités pour le simple plaisir d’apprendre et de les pratiquer. Toutefois, nous ne savons que peu de choses sur la curiosité et son rôle dans le développement. Les neurobiologistes commencent à peine à identifier les circuits impliqués dans les comportements d’exploration spontanée.&lt;br /&gt;Plusieurs équipes ont proposé, pour améliorer nos connaissances sur la curiosité et son rôle, de fabriquer des robots qui apprennent, découvrent et fixent leurs propres objectifs à partir de modèles d’apprentissage fondés sur des mécanismes d’exploration spontanée. Un exemple est fourni par l’expérience du tapis d’éveil, ou &lt;em&gt;Playground experiment&lt;/em&gt; (&lt;span style=&quot;background-color: #ffffff;&quot;&gt;voir la figure ci-dessous&lt;/span&gt;).&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;img style=&quot;vertical-align: middle;&quot; title=&quot;Playground500.&quot; src=&quot;upload/docs/image/jpeg/2016-03/playground500.jpg&quot; alt=&quot;Playground500&quot; width=&quot;500&quot; height=&quot;375&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Un modèle de curiosité artificielle équipe ces robots. Ainsi dotés, ils explorent un tapis d’éveil&lt;br /&gt;où ils apprennent à prédire les effets de leurs actions. Ce faisant, ils acquièrent spontanément &lt;br /&gt;des comportements et des connaissances dont la complexité augmente progressivement, &lt;br /&gt;par étapes. Photo © Inria / Flowers&lt;/p&gt;&lt;p&gt;Un robot apprend en faisant des expériences : il essaie, observe les effets de ses actes et détecte les régularités entre ses actions et les conséquences. Il peut ensuite faire des prédictions. La façon dont il choisit ses actions relève de la démarche scientifique : il sélectionne les expérimentations qui, selon lui, vont améliorer ses propres prédictions, lui apporter de nouvelles informations, augmenter sa capacité d’apprentissage. Ce faisant, il continue de consacrer une part de son temps à tester d’autres choses afin de découvrir de nouvelles pistes pour progresser. Le robot est aussi doté de mécanismes qui classent des expériences sensori-motrices en différentes catégories selon leur degré d’enrichissement et de contrôlabilité.&lt;/p&gt;&lt;h2&gt;Curiosité et auto-organisation&lt;/h2&gt;&lt;p&gt;À tout moment de son développement, le robot se concentre sur les activités exploratoires qui améliorent l’apprentissage, en sélectionnant celles qui ne sont ni trop faciles ni trop compliquées &lt;span style=&quot;background-color: #ffffff;&quot;&gt;(&lt;/span&gt;&lt;a href=&quot;javascript:ouvreEncart(1,%20700,%20500%20)&quot;&gt;voir l’encadré&lt;/a&gt;&lt;span style=&quot;background-color: #ffffff;&quot;&gt;)&lt;/span&gt;. Ce comportement incarne l’hypothèse que le cerveau privilégie les expérimentations qui sont juste au-dessus de son niveau actuel de connaissances et de compétences. Un tel modèle permet de proposer une définition pratique de la curiosité : elle serait un mécanisme de motivation qui pousse l’organisme à explorer des activités dans le seul but d’obtenir des informations pour elles-mêmes (par opposition à la recherche d’informations dans le but de trouver de la nourriture ou un abri par exemple).&lt;br /&gt;Dans l’expérience du tapis d’éveil, le robot apprend des tâches à partir de ses propres initiatives (par exemple, attraper un objet posé devant lui), mais il fait aussi évoluer son comportement, où apparaissent des phénomènes d’auto-organisation, en en augmentant progressivement la complexité.&lt;br /&gt;Des étapes cognitives apparaissent sans qu’elles soient préprogrammées. Ainsi, après avoir commencé par des mouvements désordonnés, le robot se concentre souvent d’abord sur les mouvements de ses membres pour, éventuellement, atteindre des objets. Ensuite, il s’applique à attraper ces objets avec sa bouche, puis, finalement, explore les interactions vocales avec les autres robots. Pourtant, les ingénieurs n’ont programmé aucune de ces activités, ni &lt;em&gt;a fortiori&lt;/em&gt; la chronologie de leur apparition.&lt;br /&gt;Ces paliers, qui traduisent une auto-organisation, résultent des interactions dynamiques entre la curiosité, l’apprentissage et les propriétés du corps et de l’environnement. Quand on répète plusieurs fois la même expérience avec des paramètres identiques, ce sont les mêmes phases, approximativement, qui apparaissent le plus souvent. Mais, quelquefois, des individus intervertissent des étapes, voire acquièrent des savoir-faire différents.&lt;br /&gt;C’est dû à de petites contingences, à des faibles variations de l’environnement physique et au fait que la dynamique du développement dispose de ce que les mathématiciens nomment des attracteurs. Ce sont des états particuliers vers lesquels un système évolue spontanément dès qu’il se trouve à proximité.&lt;br /&gt;Ces expérimentations robotisées nous aident à comprendre le développement. Elles permettent de modéliser les mécanismes d’un apprentissage guidé par la curiosité. Elles montrent aussi comment, sur le long terme, des processus développementaux fondés sur la curiosité peuvent s’auto-organiser et gagner en complexité, sans pour autant avoir un plan prédéfini. Dans ce cadre, les différences individuelles deviennent des phénomènes émergents. On comprend alors comment des processus développementaux peuvent varier selon les contextes, même avec une trame identique sous-jacente.&lt;/p&gt;&lt;h2&gt;Comprendre et créer&lt;/h2&gt;&lt;p&gt;&lt;img title=&quot;poppy.&quot; src=&quot;upload/docs/image/jpeg/2016-03/poppy.jpg&quot; alt=&quot;poppy&quot; width=&quot;750&quot; height=&quot;333&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Poppy a été développé à l&apos;Inria. Ce robot, en &lt;em&gt;open source&lt;/em&gt; (tous ses composants sont publics), aide à explorer les mécanismes du développement cognitif des enfants. Il est aussi utilisé pour l&apos;éducation des écoliers et des collégiens.&lt;br /&gt;© Inria / Flowers&lt;/p&gt;&lt;p&gt;La compréhension du développement infantile est un des plus grands défis de la science. Une difficulté importante est que ce développement résulte d’interactions de très nombreux mécanismes à diverses échelles spatiales et temporelles. Une approche systémique et constructiviste semble nécessaire.&lt;br /&gt;Les physiciens l’ont compris il y a longtemps quand ils se sont confrontés aux systèmes complexes. Pour les étudier, ils ont bâti des modèles formels avec lesquels ils simulent des aspects de la réalité. Le physicien prix Nobel Richard Feynman l’a ainsi exprimé : « On ne peut pas comprendre ce que l’on ne peut créer. » Une telle approche a désormais sa place dans les sciences du développement. Avec les robots, le corps devient une variable expérimentale, un élément que l’on peut systématiquement modifier de façon à étudier les effets de ces changements sur le développement. Ce fut longtemps un rêve, c’est aujourd’hui possible.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;lienPlus&quot; href=&quot;javascript:ouvreEncart(2,%20600,%20500%20)&quot;&gt;Références bibliographiques&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://creativecommons.org/licenses/by/4.0/&quot; rel=&quot;license&quot;&gt;&lt;img style=&quot;border-width: 0;&quot; src=&quot;https://i.creativecommons.org/l/by/4.0/80x15.png&quot; alt=&quot;Licence Creative Commons&quot; /&gt;&lt;/a&gt;&lt;em&gt; Cette œuvre est mise à disposition selon les termes de la &lt;a href=&quot;http://creativecommons.org/licenses/by/4.0/&quot; rel=&quot;license&quot;&gt;Licence Creative Commons Attribution 4.0 International&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='imagette'>upload/docs/image/jpeg/2016-03/playground115.jpg</field>
    <field name='encarts'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;h3&gt;Comment un robot peut-il être curieux ?&lt;/h3&gt;&lt;p&gt;Le modèle de curiosité du robot lui permet de trouver de nouvelles « niches de progrès ». Imaginons un environnement avec quatre types de contextes sensoriels et moteurs pour le robot : il peut dormir, bouger une patte, taper dans une balle sans bouger ou faire du scooter.&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;robot-curieux.&quot; src=&quot;upload/docs/image/jpeg/2016-03/robot-curieux.jpg&quot; alt=&quot;robot-curieux&quot; width=&quot;650&quot; height=&quot;310&quot; /&gt;&lt;br /&gt;Si l’on forçait le robot à se concentrer sur chacune de ces activités séparément, on mesurerait l’évolution de son erreur en prédiction dans chaque contexte (&lt;span style=&quot;background-color: #ffffff;&quot;&gt;à gauche)&lt;/span&gt; . Dans la situation a (faire du scooter), l’erreur en prédiction est toujours élevée, peut-être parce que cette situation est trop compliquée pour le système d’apprentissage. Dans la situation d (dormir), l’erreur est toujours basse et ne change pas (cette situation est facile et donc peu intéressante pour le système d’apprentissage). Dans les situations b (taper dans une balle) et c (bouger une patte), l’erreur en prédiction est importante au départ, mais diminue ensuite. En pratique, le robot placé dans cet environnement ignore les quatre types de situations et, &lt;em&gt;a fortiori&lt;/em&gt;, les courbes d’apprentissage correspondantes. Au départ, il explore aléatoirement son environnement, découvrant qu’il existe des situations différentes, et évalue l’intérêt de chacune en termes de réduction potentielle de ses erreurs en prédiction.&lt;/p&gt;&lt;p&gt;Les courbes du temps passé à explorer chaque situation (&lt;span style=&quot;background-color: #ffffff;&quot;&gt;à droite&lt;/span&gt;) montrent que le robot évite les situations a (trop compliquée) et d (trop simple), qui ne permettent pas de progrès en apprentissage. Il les explore cependant de temps en temps et par hasard pour vérifier qu’elles restent peu intéressantes. À l’inverse, il se consacre à la situation c pour laquelle ses prédictions s’améliorent le plus vite. Après un certain temps, la situation c est maîtrisée et, par conséquent, prédictible : il l’abandonne. Il consacre alors l’essentiel de son temps à la situation b qui, à ce stade de son développement, lui procure le plus de progrès en apprentissage.&lt;/p&gt;&lt;/div&gt;</item>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;h3&gt;Références bibliographiques&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Livres :&lt;/strong&gt; &lt;br /&gt;• A. Cangelosi et M. Schlesinger, &lt;em&gt;Developmental Robotics : From Babies to Robots&lt;/em&gt;, MIT Press, 2015.&lt;br /&gt;• P.-Y. Oudeyer, &lt;em&gt;Aux sources de la parole&lt;/em&gt;, Odile Jacob, 2013.&lt;br /&gt;• G. Baldassare et M. Mirolli, &lt;em&gt;Intrinsically motivated learning in natural and artificial systems&lt;/em&gt;, Springer-Verlag, 2013.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Articles&lt;/strong&gt; :&lt;br /&gt;• J. Gottlieb et &lt;em&gt;al.&lt;/em&gt;, &lt;em&gt;Information seeking, curiosity and attention : computational and neural mechanisms&lt;/em&gt;, in Trends in Cognitive Science, vol. 17(11), pp. 585-596, 2013.&lt;br /&gt;• S. Collins et &lt;em&gt;al.&lt;/em&gt;, &lt;em&gt;Efficient bipedal robots based on passive-dynamic walkers&lt;/em&gt;, in Science, vol. 307, pp. 1082-1085, 2005.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Liens :&lt;/strong&gt;&lt;br /&gt;• Le &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.pyoudeyer.com&quot; target=&quot;_blank&quot;&gt;site de P.-Y. Oudeyer&lt;/a&gt; &lt;br /&gt;• Le &lt;a class=&quot;lienExterne&quot; href=&quot;http://bit.ly/PLS-McG&quot; target=&quot;_blank&quot;&gt;bipède de Tad McGeer&lt;/a&gt; &lt;br /&gt;• La &lt;a class=&quot;lienExterne&quot; href=&quot;http://bit.ly/PLS-Play&quot; target=&quot;_blank&quot;&gt;Playground expriment&lt;/a&gt; : &lt;br /&gt;• &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.icub.org&quot; target=&quot;_blank&quot;&gt;ICub&lt;/a&gt;&lt;br /&gt;• &lt;a class=&quot;lienExterne&quot; href=&quot;http://bit.ly/PLS-Pop&quot; target=&quot;_blank&quot;&gt;Poppy&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='auteurs'>
      <item id='c_44091' class='generated.Auteur'>Oudeyer</item>
    </field>
    <field name='moissonnable'>true</field>
    <field name='motsCles'>
      <item>curiosité</item>
      <item>neurosciences</item>
      <item>éducation</item>
    </field>
    <field name='indiceDewey'>
      <item>629.893</item>
      <item>006.3</item>
    </field>
    <field name='publicVise'>
      <item>enseignement supérieur</item>
      <item>enseignement secondaire</item>
      <item>autres</item>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89875' url='https://interstices.info/jcms/p_89875/data-management'>
    <field name='title'>data-management</field>
    <field name='pdate' time='1459351721588'>2016-03-30T17:28:41+02:00</field>
    <field name='udate' time='1459351721589'>2016-03-30T17:28:41+02:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1459351721589'>2016-03-30T17:28:41+02:00</field>
    <field name='mdate' time='1459351721589'>2016-03-30T17:28:41+02:00</field>
    <field name='filename' mtime='1459351722000' size='23387' ticket='R4mTI9TBwpDbOWCN9MzZOA=='>upload/docs/image/jpeg/2016-03/data-management.jpg</field>
    <field name='originalFilename'>data-management.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1459351721589'>2016-03-30T17:28:41+02:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>273</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>273 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>460 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>460</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89926' url='https://interstices.info/jcms/p_89926/donnees750'>
    <field name='title'>donnees750</field>
    <field name='pdate' time='1459430468065'>2016-03-31T15:21:08+02:00</field>
    <field name='udate' time='1459430468066'>2016-03-31T15:21:08+02:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1459430468066'>2016-03-31T15:21:08+02:00</field>
    <field name='mdate' time='1459430468066'>2016-03-31T15:21:08+02:00</field>
    <field name='filename' mtime='1459430469000' size='44472' ticket='OZ3j7CQyb3QacMhPW7E84w=='>upload/docs/image/jpeg/2016-03/donnees750.jpg</field>
    <field name='originalFilename'>donnees750.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1459430468066'>2016-03-31T15:21:08+02:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>260</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>260 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89937' url='https://interstices.info/jcms/p_89937/terre-numerique'>
    <field name='title'>terre-numerique</field>
    <field name='pdate' time='1459436423310'>2016-03-31T17:00:23+02:00</field>
    <field name='udate' time='1459436423311'>2016-03-31T17:00:23+02:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1459436423311'>2016-03-31T17:00:23+02:00</field>
    <field name='mdate' time='1459436423311'>2016-03-31T17:00:23+02:00</field>
    <field name='filename' mtime='1459436424000' size='48996' ticket='cOt6s5pXHHvG2ZCyc1NJaA=='>upload/docs/image/jpeg/2016-03/terre-numerique.jpg</field>
    <field name='originalFilename'>terre-numerique.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1459436423311'>2016-03-31T17:00:23+02:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>307</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>307 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>460 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>460</value>
      </entry>
    </field>
  </data>
  <data class='generated.DocumentInterstices' id='p_84069' url='https://interstices.info/jcms/p_84069/les-donnees-en-question'>
    <field name='title'>Les données en question</field>
    <field name='categories'>
      <item id='jalios_5001' class='com.jalios.jcms.Category'>Navigation/Rubriques/Découvrir</item>
      <item id='mf_46784' class='com.jalios.jcms.Category'>Tags/Algorithme</item>
      <item id='i_62034' class='com.jalios.jcms.Category'>CatTemporaire</item>
      <item id='p_83322' class='com.jalios.jcms.Category'>Navigation/Spécial/Données - Vie privée</item>
      <item id='p_83851' class='com.jalios.jcms.Category'>Tags/Donnée</item>
    </field>
    <field name='pdate' time='1459437300000'>2016-03-31T17:15:00+02:00</field>
    <field name='udate' time='1432636041791'>2015-05-26T12:27:21+02:00</field>
    <field name='version' major='1' minor='68'>1.68</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>full.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='n_52355' class='com.jalios.jcms.Member' login='jocelyne'>Jocelyne Erhel</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1432636041791'>2015-05-26T12:27:21+02:00</field>
    <field name='mdate' time='1462881323413'>2016-05-10T13:55:23+02:00</field>
    <field name='resume' abstract='true'>Au cœur de la connaissance et de l&apos;information, les données ont peu à peu pris une importance qui nous dépasse. Mais qu&apos;entend-on exactement par données ? Quels sont les enjeux autour de leur gestion ou de leur analyse ? Quels impacts sur la société ?</field>
    <field name='chapo'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Au cœur de la connaissance et de l&apos;information, les données ont peu à peu pris une importance qui nous dépasse. Mais qu&apos;entend-on exactement par données ? Quels sont les enjeux autour de leur gestion ou de leur analyse ? Quels impacts sur la société ?&lt;/p&gt;&lt;/div&gt;</field>
    <field name='imageChapeau'>upload/docs/image/jpeg/2016-03/donnees750.jpg</field>
    <field name='legendeImageChapeau'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;© &lt;span class=&quot;lienExterne&quot;&gt;Fotolia&lt;/span&gt; - ptnphotof &lt;/p&gt;&lt;/div&gt;</field>
    <field name='texte'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Une donnée est la description élémentaire d’une réalité ou d’un fait, comme par exemple un relevé de température,  la note d’un élève à un examen, l’état d’un compte, un message, une photo, une transaction, etc. Une donnée peut donc être très simple et, prise isolément, peu utile. Mais le recoupement avec d’autres données devient très intéressant. Par exemple, une liste de températures pour une région donnée sur une longue période peut nous renseigner sur le réchauffement climatique. Ou bien la note moyenne d’un élève dans une matière sur une année nous informe du niveau d’acquisition des connaissances de l’élève dans cette matière. Il y a donc une relation subtile entre donnée et information, termes qui sont d’ailleurs souvent confondus dans le langage courant. Mais obtenir de l’information demande un travail d’analyse et d’interprétation des données (ex. une liste de notes) pour leur donner un sens dans un certain contexte (ex. une matière sur une année). Ainsi, les données sont la matière brute qui permet de produire des informations, qui, elles, sont exploitables pour diverses activités quotidiennes : évaluation, recommandation, prise de décision, prévision, recherche, etc. Inversement, pour comprendre d’où vient une information, il faut pouvoir retrouver les données initiales, d’où la nécessité d’enregistrer ces données dans une mémoire.&lt;/p&gt;&lt;p&gt;Pendant longtemps, le papier a fourni une mémoire pratique pour stocker et organiser les données. En effet, les documents sont faciles à transporter, partager, ranger et archiver. Et on peut les organiser, par exemple sous forme de répertoires, registres, annuaires ou tableaux pour faciliter la recherche de données. Afin d’enregistrer correctement les données, il faut aussi pouvoir les identifier précisément, de manière unique, ce qui demande un travail d’uniformisation des identifiants, comme le numéro de sécurité sociale en France, afin d’éviter les problèmes d’homonymie. Enfin, pour pouvoir retrouver des données dans de grandes collections, des métadonnées (données décrivant des données), comme des mots-clés, permettent de faire des index, en associant par exemple chaque mot-clé aux identifiants des données correspondantes.&lt;/p&gt;&lt;p&gt;Cependant, l’utilisation du papier pour stocker les données se heurte à un problème majeur : le lien indissociable entre la donnée et son support. Si le support disparaît, la donnée aussi. On peut bien sûr faire des copies, mais avec un coût non négligeable. Si l’on veut extraire une donnée d’un document pour l’utiliser dans un autre document, il faut la réinscrire, ce qui est fastidieux et peut conduire à des erreurs de saisie, et donc des incohérences. Enfin, les méthodes ou &lt;a href=&quot;jcms/c_5776/quest-ce-quun-algorithme&quot;&gt;algorithmes&lt;/a&gt; pour rechercher et manipuler les données doivent être réalisés par des êtres humains, ce qui prend du temps.&lt;/p&gt;&lt;p&gt;Avec l’informatique et le monde numérique, la donnée peut être séparée de son support, ce qui offre des possibilités nouvelles de traitement de données. Notons que ça n’a pas toujours été le cas : les premiers ordinateurs ne disposaient que d’une petite mémoire de travail et les données devaient être stockées sur des &lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/Carte_perfor%C3%A9e&quot; target=&quot;_blank&quot;&gt;cartes perforées&lt;/a&gt;. Une donnée numérique est codée dans un format binaire (une suite de 0 et de 1) et il y a des formats pour représenter toutes sortes de données : des nombres bien sûr, mais aussi des caractères, des graphiques, des images, etc. Par exemple, le format ASCII (&lt;em&gt;American Standard Code for Information Interchange&lt;/em&gt;) développé dans les années 1960, et encore très répandu aujourd’hui, représente les caractères sur un &lt;a class=&quot;lienDef&quot; href=&quot;display.jsp?id=c_19937&quot; target=&quot;_blank&quot;&gt;octet&lt;/a&gt; (8 bits), soit 256 caractères possibles. Les caractères chinois à l’inverse nécessitent un code sur deux octets, soit 65.536 possibilités. Ainsi, les données numériques peuvent être stockées sur différents supports (disque dur d’un ordinateur, clé USB, mémoire flash d’un smartphone, etc.), répliquées à l’infini et être échangées aisément sur le réseau. Ces possibilités ont été exploitées pour créer &lt;a href=&quot;jcms/p_81650/idee-recue-web-et-internet-c-est-la-meme-chose&quot;&gt;Internet et le Web&lt;/a&gt;, qui ont profondément modifié notre rapport aux données et à l’information.&lt;/p&gt;&lt;p style=&quot;text-align: justify;&quot;&gt;&lt;img style=&quot;vertical-align: middle;&quot; title=&quot;data-management.&quot; src=&quot;upload/docs/image/jpeg/2016-03/data-management.jpg&quot; alt=&quot;data-management&quot; width=&quot;460&quot; height=&quot;273&quot; /&gt;&lt;span class=&quot;legende&quot;&gt;&lt;br /&gt;Photo : janneke staaks/ &lt;a class=&quot;lienExterne&quot; href=&quot;https://flic.kr/p/nDcncM&quot; target=&quot;_blank&quot;&gt;Flickr&lt;/a&gt; - Licence Creative Commons &lt;span style=&quot;display: inline-block; padding-left: 2px;&quot;&gt;&lt;span style=&quot;display: inline;&quot;&gt;CC BY-NC 2.0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;On utilise souvent le terme « data » pour parler des données numériques échangées sur le réseau, dans des expressions comme « forfait data » pour télécharger une quantité de données en internet mobile. Le terme « data » a pour origine le pluriel du mot latin « datum » (don, présent), mais est utilisé en anglais comme nom indénombrable, donc soit au singulier soit au pluriel. La gestion de données (ou &lt;em&gt;data management&lt;/em&gt;) est devenu un domaine important qui désigne le stockage, l’organisation, la recherche et la manipulation de données de toutes sortes. Ce domaine a permis le développement des systèmes de fichiers et des bases de données, au cœur de tout système d’information d’entreprise pour gérer des données structurées. Il a aussi contribué aux moteurs de recherche, et plus généralement aux systèmes de gestion de documents Web.&lt;/p&gt;&lt;p&gt;Avec le développement du Web, la quantité de données a augmenté subitement et massivement. Tout le monde a été en capacité de produire des données comme les pages Web par exemple. Dans un deuxième temps, de nouveaux protocoles sont apparus qui ont permis les interactions entre personnes en ligne. C’est ce qu’on appelle le Web 2.0, avec les outils de communication, les réseaux sociaux, les plateformes d’échange ou de partage, le commerce en ligne... Enfin, dans un troisième temps, sont apparus les appareils de la mobilité qui nous suivent partout, et que l’on qualifie d’intelligents, comme les smartphones. Ils nous permettent d’accéder aux services en ligne à n’importe quel moment, n’importe où. Ils permettent également au réseau de savoir où nous sommes et ce que nous faisons de manière continue. Finalement, avec l’internet des objets, ce ne sont plus seulement les personnes qui sont connectées au réseau, mais également les objets qui nous entourent, dans lesquels sont embarqués des puces qui permettent de produire, de traiter et d’échanger des données. Le volume et la variété des données — ex. tweets, position GPS, photos, paroles, etc. — ont explosé.&lt;/p&gt;&lt;p&gt;On parle aujourd’hui de « Big Data ». L’abondance des données suffit à justifier ce terme. La quantité de données se mesure désormais avec des métriques introduites récemment, les zetta-octets (10&lt;sup&gt;21&lt;/sup&gt; octets). On parle même de yotta-octets (10&lt;sup&gt;24&lt;/sup&gt; octets), des ordres de grandeur jamais atteints dans le passé par l’activité humaine. Pour l’informaticien, ces données constituent une chance et un défi. Une chance, parce qu’il y aura du travail pendant longtemps pour être capable de les traiter de manière satisfaisante. Un défi également, tant ces données posent des problèmes de tous ordres. Les données du big data sont de nature différente de celles que l’on pouvait stocker sur le papier. Il s’agit surtout d’un flux de données, comme d’une fontaine, qui coulerait en permanence et dont nous ne prélèverions qu’une petite partie pour notre usage. Une partie qui peut être vue comme l’information qu’on extrait, parfois à grand coût, de ce flux. Comme dans le domaine des moteurs, on parle de 3V, 5V, ou même 7V — avec le volume, la variété, la vélocité, la valeur, la véracité, la visualisation, la viabilité, etc. — pour caractériser le big data.&lt;/p&gt;&lt;p&gt;Les données n’ont d’intérêt ou de sens qu’avec les &lt;a href=&quot;jcms/c_5776/quest-ce-quun-algorithme&quot;&gt;algorithmes&lt;/a&gt; qui les traitent. Contrairement aux données stockées sur support papier, les données numériques sont manipulées par des algorithmes codés dans des programmes, et tournant sur des ordinateurs sans cesse plus puissants. L’explosion de la quantité de données a donc été directement accompagnée d’une explosion de la capacité des algorithmes soutenus par des architectures parallèles pouvant supporter des quantités de données croissantes et dans une logique de meilleur effort (de l&apos;anglais &lt;em&gt;best effort&lt;/em&gt;), garantissant un temps d’exécution maitrisé. De plus, des problèmes de grande complexité ont pu être résolus grâce au développement de l’intelligence artificielle. Depuis la victoire du programme joueur d&apos;échecs Deep Blue contre Garry Kasparov en 1997, les algorithmes accumulent les victoires : la conduite automobile, le jeu de go, pourtant si combinatoire, etc. De nombreuses tâches sont appelées à être automatisées pour être réalisées par des machines directement à partir des données, comme la rédaction d’articles de presse par exemple, et petit à petit un nombre croissant de tâches qui paraissaient relever de l’intelligence humaine. Il faut noter de surcroît le cercle vertueux entre les données et les algorithmes. Plus il y a de données, meilleurs sont les algorithmes d’apprentissage.&lt;/p&gt;&lt;p&gt;Le changement qui résulte de la libération des données est toutefois bien plus profond que la simple mécanisation de tâches considérées comme difficiles. Il ne s’agit plus seulement de la réduction progressive de l’utilisation de la force humaine dans le travail, mais des principes même de l’organisation de nos sociétés qui sont remis en question. Les données récoltées par tous les capteurs permettent en effet l’émergence d’un monde virtuel, une sorte de reflet du monde physique, purement constitué de données numériques. Cette couche virtuelle permet désormais d&apos;appréhender le monde à une granularité très fine. Si on pouvait autrefois connaître le monde entier avec une approximation grossière et une petite zone, autour de soi, avec une granularité fine, on peut désormais percevoir l’ensemble de la planète et de ses habitants avec une granularité très fine, savoir où ils sont, ce qu’ils font, etc.&lt;/p&gt;&lt;p style=&quot;text-align: justify;&quot;&gt;&lt;img title=&quot;terre-numerique.&quot; src=&quot;upload/docs/image/jpeg/2016-03/terre-numerique.jpg&quot; alt=&quot;terre-numerique&quot; width=&quot;460&quot; height=&quot;307&quot; /&gt;&lt;br /&gt;&lt;span class=&quot;legende&quot;&gt;© Fotolia - Victoria&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Les conséquences sont multiples. Tout d’abord, de nombreuses activités réalisées précédemment par les acteurs du monde physique peuvent être exécutées par les acteurs du monde virtuel, purement dans le monde virtuel et avec une efficacité accrue. C’est précisément ce qu’un acteur comme la société de service de voitures de tourisme avec chauffeur Uber propose. Il met en relation passagers et chauffeurs, avec un service d’une telle qualité qu’il est largement adopté sur l’ensemble de la planète et rend caduques les sociétés de taxi. Sa supériorité sur les services antérieurs repose précisément sur le fait qu’il travaille sur les données et seulement sur les données. Grâce aux données, Uber peut satisfaire ses utilisateurs de manière personnalisée et exploiter au mieux les connaissances de contexte comme le trafic. Et parce qu’il travaille seulement dans la couche virtuelle, il n’a pas les nombreuses contraintes du monde physique et peut concevoir un service au plus près des besoins.&lt;/p&gt;&lt;p&gt;Cette mise en relation des producteurs et consommateurs de biens et de services est bien connue des économistes, qui parlent de &lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/March%C3%A9_biface&quot; target=&quot;_blank&quot;&gt;marchés bifaces&lt;/a&gt;&lt;span class=&quot;lienExterne&quot;&gt;, &lt;/span&gt;mettant en relation deux types d’agents qui ont un intérêt à interagir. L’une des conséquences les plus fondamentales de la disponibilité des données est l’émergence de nouvelles formes d’&lt;a class=&quot;lienExterne&quot; href=&quot;http://www.societe-informatique-de-france.fr/wp-content/uploads/2015/12/1024-no7-Grumbach.pdf&quot; target=&quot;_blank&quot;&gt;intermédiation algorithmique&lt;/a&gt; (réalisée directement par des algorithmes) et qui pénètreront l’ensemble des marchés bifaces qui structurent notre société, parmi lesquels, outre les activités commerciales bien sûr, la presse, l’éducation, la santé, etc.&lt;/p&gt;&lt;p&gt;Le monde numérique qui émerge sous nos yeux a été rendu possible par les développements de la recherche dans de nombreux domaines, et tout particulièrement en informatique, science qui s’occupe des données et des algorithmes. Le numérique et l’informatique se nourrissent l’un l’autre de manière vertueuse, le monde numérique générant de très nombreux nouveaux problèmes de recherche liés aux données ou à l’automatisation de tâches de plus en plus complexes. Et parce que le numérique conduit à une remise en cause profonde de nos modes d’organisation, il suscite également des recherches au carrefour des disciplines, pour penser les nombreuses questions juridiques, économiques, environnementales, politiques, etc. qu’il soulève.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='imagette'>upload/docs/image/jpeg/2016-03/donnees-imgt.jpg</field>
    <field name='auteurs'>
      <item id='p_85949' class='generated.Auteur'>Grumbach</item>
      <item id='i_61324' class='generated.Auteur'>Valduriez</item>
    </field>
    <field name='references'>
      <item id='ni_76920' class='generated.DocumentInterstices'>Un déluge de données</item>
      <item id='p_84511' class='generated.DocumentInterstices'>La déferlante des données</item>
      <item id='int_71721' class='generated.DocumentInterstices'>L’Open Data, l’ouverture des données pour de nouveaux usages</item>
    </field>
    <field name='moissonnable'>false</field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89384' url='https://interstices.info/jcms/p_89384/un-logiciel-capable-de-verifier-les-faits-en-temps-reel'>
    <field name='title'>Un logiciel capable de vérifier les faits en temps réel</field>
    <field name='categories'>
      <item id='c_34624' class='com.jalios.jcms.Category'>Podcasts/Catégorie des Podcasts</item>
      <item id='c_34625' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes</item>
      <item id='c_34673' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes/Sciences et médecine</item>
    </field>
    <field name='pdate' time='1456765200000'>2016-02-29T18:00:00+01:00</field>
    <field name='udate' time='1456755547496'>2016-02-29T15:19:07+01:00</field>
    <field name='version' major='1' minor='3'>1.3</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1456755547496'>2016-02-29T15:19:07+01:00</field>
    <field name='mdate' time='1456841649015'>2016-03-01T15:14:09+01:00</field>
    <field name='filename' mtime='1456755548000' size='14722971' ticket='MfHSA7XRTeGYyI4MOzBaCw=='>upload/docs/audio/mpeg/2016-02/un_logiciel_capable_de_verifier_les_faits_en_temps_reel__.mp3</field>
    <field name='originalFilename'>Un logiciel capable de vérifier les faits en temps réel _.mp3</field>
    <field name='contentType'>audio/mpeg</field>
    <field name='uploadDate' time='1456755547496'>2016-02-29T15:19:07+01:00</field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89393' url='https://interstices.info/jcms/p_89393/lancement-presse750'>
    <field name='title'>lancement-presse750</field>
    <field name='pdate' time='1456758582406'>2016-02-29T16:09:42+01:00</field>
    <field name='udate' time='1456758582407'>2016-02-29T16:09:42+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1456758582408'>2016-02-29T16:09:42+01:00</field>
    <field name='mdate' time='1456758582408'>2016-02-29T16:09:42+01:00</field>
    <field name='filename' mtime='1456758583000' size='317026' ticket='VJW/e1V3xomhkAAzVNN9HQ=='>upload/docs/image/png/2016-02/lancement-presse750.png</field>
    <field name='originalFilename'>lancement-presse750.png</field>
    <field name='contentType'>image/png</field>
    <field name='uploadDate' time='1456758582408'>2016-02-29T16:09:42+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>260</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='generated.DocumentInterstices' id='p_88301' url='https://interstices.info/jcms/p_88301/un-logiciel-capable-de-verifier-les-faits-en-temps-reel'>
    <field name='title'>Un logiciel capable de vérifier les faits en temps réel ?</field>
    <field name='categories'>
      <item id='jalios_5001' class='com.jalios.jcms.Category'>Navigation/Rubriques/Découvrir</item>
      <item id='c_34623' class='com.jalios.jcms.Category'>Podcasts</item>
      <item id='c_34624' class='com.jalios.jcms.Category'>Podcasts/Catégorie des Podcasts</item>
      <item id='c_34625' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes</item>
      <item id='c_34673' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes/Sciences et médecine</item>
      <item id='c_34687' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes/Technologies</item>
      <item id='mf_46795' class='com.jalios.jcms.Category'>Tags/Information</item>
      <item id='mf_46802' class='com.jalios.jcms.Category'>Tags/Utilisateur</item>
      <item id='new_47667' class='com.jalios.jcms.Category'>Navigation/Médias/Podcast</item>
      <item id='i_62034' class='com.jalios.jcms.Category'>CatTemporaire</item>
      <item id='p_83851' class='com.jalios.jcms.Category'>Tags/Donnée</item>
    </field>
    <field name='pdate' time='1456765200000'>2016-02-29T18:00:00+01:00</field>
    <field name='udate' time='1452596150883'>2016-01-12T11:55:50+01:00</field>
    <field name='version' major='1' minor='26'>1.26</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>full.pod</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1452596150883'>2016-01-12T11:55:50+01:00</field>
    <field name='mdate' time='1462881375562'>2016-05-10T13:56:15+02:00</field>
    <field name='resume' abstract='true'>Info ou intox ? Démêler le vrai du faux dans un flot torrentiel d&apos;informations n&apos;est pas toujours simple... Automatiser la vérification des faits, ou fact-checking, semble être une solution prometteuse pour s&apos;assurer de la véracité des propos. Xavier Tannier nous en parle dans cet épisode du podcast audio.</field>
    <field name='chapo'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Info ou intox ? Démêler le vrai du faux dans un flot torrentiel d&apos;informations n&apos;est pas toujours simple... Automatiser la vérification des faits, ou fact-checking, semble être une solution prometteuse pour s&apos;assurer de la véracité des propos. Xavier Tannier nous en parle dans cet épisode du podcast audio.&lt;/p&gt;&lt;/div&gt;</field>
    <field name='imageChapeau'>upload/docs/image/png/2016-02/lancement-presse750.png</field>
    <field name='legendeImageChapeau'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;© Inria / Photo S. Borghi&lt;/p&gt;&lt;/div&gt;</field>
    <field name='soustitre'>
    </field>
    <field name='texte'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Comment faire le tri dans la masse d&apos;informations qui nous inonde inlassablement ? Cette question est devenue primordiale avec la montée en puissance des technologies de l&apos;information et de la communication. Déterminer la fiabilité d&apos;une information est à la base du travail du journaliste. Mais nul n&apos;est à l&apos;abri de tomber dans le piège des mauvaises sources d&apos;informations. Xavier Tannier, spécialiste du traitement automatique des langues, s&apos;est intéressé à cette pratique journalistique qu&apos;on appelle le fact-checking et il tente, avec l&apos;aide d&apos;autres spécialistes, de concevoir un outil qui permettrait d&apos;automatiser la vérification des faits.&lt;/p&gt;&lt;p&gt;Comme l&apos;explique le chercheur, l&apos;idée n&apos;est évidemment pas de remplacer le journaliste mais de faciliter son travail lors de son opération de fact-checking. Quels sont les enjeux de ce projet ? Comment fonctionnerait un tel outil ? Quelles sont les méthodes utilisées ? Les difficultés rencontrées ? Une série de questions auxquelles répond Xavier Tannier.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='imagette'>upload/docs/image/jpeg/2016-02/factchecking115.jpg</field>
    <field name='encarts'>
    </field>
    <field name='auteurs'>
      <item id='p_89145' class='generated.Auteur'>Tannier</item>
      <item id='c_24368' class='generated.Auteur'>Jongwane</item>
    </field>
    <field name='podcastItem' id='p_89384' class='com.jalios.jcms.FileDocument'>upload/docs/audio/mpeg/2016-02/un_logiciel_capable_de_verifier_les_faits_en_temps_reel__.mp3</field>
    <field name='moissonnable'>false</field>
    <field name='motsCles'>
    </field>
    <field name='indiceDewey'>
    </field>
    <field name='publicVise'>
    </field>
  </data>
  <data class='generated.DocumentInterstices' id='c_24463' url='https://interstices.info/jcms/c_24463/l-informatique-de-a-a-z'>
    <field name='title'>L’informatique de A à Z</field>
    <field name='categories'>
      <item id='jalios_5001' class='com.jalios.jcms.Category'>Navigation/Rubriques/Découvrir</item>
      <item id='c_18168' class='com.jalios.jcms.Category'>Catégories hors navigation/Anciennes thématiques/Une première approche...</item>
      <item id='new_47669' class='com.jalios.jcms.Category'>Navigation/Médias/Animations</item>
      <item id='i_62034' class='com.jalios.jcms.Category'>CatTemporaire</item>
    </field>
    <field name='pdate' time='1456761600000'>2016-02-29T17:00:00+01:00</field>
    <field name='udate' time='1170433051149'>2007-02-02T17:17:31+01:00</field>
    <field name='version' major='1' minor='51'>1.51</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>full.aide</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6753' class='com.jalios.jcms.Member' login='bernard-a'>Bernard Hidoine</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1170433051149'>2007-02-02T17:17:31+01:00</field>
    <field name='mdate' time='1462881407825'>2016-05-10T13:56:47+02:00</field>
    <field name='repertoire'>abc</field>
    <field name='resume' abstract='true'>Découvrez dans cet abécédaire, les notions fondamentales de la science informatique ! Chaque lettre illustrée renvoie à un mot choisi pour évoquer une facette de l&apos;informatique et des mathématiques appliquées.</field>
    <field name='chapo'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Découvrez, sous la forme d&apos;un abécédaire, les notions fondamentales de la science informatique !&lt;/p&gt;&lt;/div&gt;</field>
    <field name='texte'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Chaque lettre illustrée renvoie à un mot choisi pour évoquer une facette de l&apos;informatique et des mathématiques appliquées. Un court texte présente chaque notion au travers d&apos;un exemple, la situe dans son contexte d&apos;utilisation et évoque la recherche dans ce domaine. Pour aller plus loin sur chaque sujet, des liens vous sont proposés.&lt;/p&gt;&lt;p&gt;Réalisé par la communauté scientifique et le &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.inria.fr/recherches/mediation-scientifique/actions-de-mediation-scientifique/presentation&quot; target=&quot;_blank&quot;&gt;réseau de médiation scientifique Inria&lt;/a&gt;, cet abécédaire constitue une porte d&apos;entrée vers la science informatique.&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe src=&quot;https://files.inria.fr/abecedaire/index.html&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot; width=&quot;820&quot; height=&quot;584&quot;&gt;&lt;/iframe&gt;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;legende&quot;&gt;&lt;a class=&quot;lienPlus&quot; href=&quot;javascript:ouvreEncart(1,%20600,%20500%20);&quot;&gt;Matériel pédagogique associé&lt;/a&gt; - &lt;a class=&quot;lienPlus&quot; href=&quot;javascript:ouvreEncart(2,600,500);&quot;&gt;Remerciements &lt;/a&gt;&lt;span class=&quot;lienPlus&quot;&gt;-&lt;/span&gt;&lt;a class=&quot;lienPlus&quot; href=&quot;javascript:ouvreEncart(3,600,500);&quot;&gt; Accéder au texte de l&apos;abécédaire&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='imagette'>upload/abc/abc-img.jpg</field>
    <field name='encarts'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Cet abécédaire existe sous forme de livrets de cartes postales : il peut être mis à disposition des enseignants, des animateurs, des musées, CCSTI et autres lieux de culture scientifique.&lt;/p&gt;&lt;p&gt;Adressez votre demande à &lt;a href=&quot;mailto:webmaster@interstices.info&quot;&gt;webmaster@interstices.info&lt;/a&gt; en précisant le cadre d&apos;utilisation et le nombre d&apos;exemplaires souhaités.&lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;/div&gt;</item>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;h3&gt;Contributeurs&lt;/h3&gt;&lt;p&gt;Nous remercions les nombreuses personnes qui ont contribué à l&apos;élaboration de ce document, ainsi qu&apos;à sa mise à jour.&lt;/p&gt;&lt;p&gt;Pour la version initiale en 2007, le contenu éditorial initial a été élaboré par Christine Genest (Inria), Nicolas Graner et Sébastien Descotes-Genon (CVC-Université Paris-Sud 11 - CNRS) avec le concours de :&lt;/p&gt;&lt;ul&gt;&lt;li&gt;au &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.cvc.u-psud.fr/&quot; target=&quot;_blank&quot;&gt;Centre de Vulgarisation de la Connaissance&lt;/a&gt;, Sylvie Furois, sa directrice, &lt;span class=&quot;lienExterne&quot;&gt;Olivier Pérès &lt;/span&gt;et &lt;span class=&quot;lienexterne&quot;&gt;Florence Plateau&lt;/span&gt;, doctorants au Laboratoire de Recherche en Informatique ;&lt;/li&gt;&lt;li&gt;à l&apos;Inria, Bernard Hidoine, Christine Leininger, Thierry Viéville, Pascal Guitton, Pierre Alliez, Anne Canteaut, Thierry Priol.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Pour la mise à jour en 2015, la coordination a été assurée par Christine Leininger, Martine Courbin-Coulaud, Valérie François, Thierry Viéville et Jocelyne Erhel (Inria).&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Ont aussi contribué à la relecture et la réécriture (par ordre alphabétique) : Sara Alouf, Sylvie Boldo, François Chaumette, Marie-Odile Cordier, Colin de la Higuera, Robert de Simone, Gilles Dowek, Marie-Agnès Énard, Fabien Gandon, Pascal Guitton, Jean-Paul Haton, Florent Lafarge, Jean-Louis Lanet, Florent Masseglia, Philippe Poulard, Olivier Ridoux, Antoine Rousseau, Didier Roy, Bernard Senach, David Simplot-Ryl, Laurent Théry, Laurent Viennot.&lt;/li&gt;&lt;li&gt;La version en ligne a été programmée par Ludovic Bellier.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt; &lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;/div&gt;</item>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;&lt;strong&gt;A : Algorithme&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Chercher un mot dans le dictionnaire, effectuer une addition, trouver le trajet le plus court sur une carte... Pour résoudre ces problèmes, il existe des méthodes systématiques conduisant à coup sûr au résultat : des algorithmes.&lt;/p&gt;&lt;p&gt;Un algorithme, c&apos;est une suite de tâches élémentaires qui s&apos;enchaînent selon des règles précises, sans place pour l&apos;interprétation personnelle. « Additionner deux chiffres, écrire la somme au-dessous et la retenue à gauche » peut faire partie d&apos;un algorithme ; mais « faire cuire à point, saler à votre goût », c&apos;est juste une recette ! On peut décrire un algorithme en français, en chinois ou dans toute autre langue... Traduit dans un langage de programmation, il devient un programme informatique   exécutable par un ordinateur. Pour résoudre certains types de problèmes - comme trouver la répartition du travail qui réduit au maximum la durée d&apos;un gros chantier -, même les meilleurs algorithmes exigent un temps de calcul considérable. C&apos;est un véritable défi d&apos;en élaborer sans cesse   de plus rapides et de plus fiables !&lt;/p&gt;&lt;p&gt;On ne cherche pas de la même façon l&apos;as de trèfle dans un jeu de cartes, un mot dans le dictionnaire ou une page web parmi des milliards... Plus il y a de données à traiter, plus il est important de mettre au point un algorithme efficace, mais il restera encore longtemps des problèmes hors de portée.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;B : Bug&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Sur l&apos;écran clignote un message : « Le programme doit s&apos;interrompre suite à une erreur de type inconnu. » Vous venez de perdre les dix dernières minutes de votre travail... Souriez ! Vous êtes victime d&apos;un bug !&lt;/p&gt;&lt;p&gt;Ces arrêts intempestifs ne constituent pourtant pas les bugs les plus critiques. Certains apparaissent quand on utilise un programme hors de son champ d&apos;application : si vous essayez de lire un fichier dans un format inattendu, votre logiciel peut accepter pour finalement « se planter » ! D&apos;autres bugs se révèlent seulement lorsque plusieurs facteurs se combinent, ce qui les rend plus difficiles à détecter.&lt;br /&gt;Éliminer ces bugs consomme du temps et de l&apos;argent. Pour s&apos;épargner cette peine, on élabore des standards rigoureux de programmation et des langages adaptés. Bien sûr, on teste et on documente. On essaie aussi de limiter les erreurs d&apos;interprétation de la part des programmeurs et de faciliter la communication entre les différents programmes, le système d&apos;exploitation et un jeu par exemple.&lt;/p&gt;&lt;p&gt;L&apos;omniprésence de l&apos;informatique nécessite une chasse au bug impitoyable ! Au delà des objets de la vie courante, comme le téléphone ou l&apos;automobile, ce problème concerne des appareils de haute technologie comme les satellites, ou encore des instruments d&apos;imagerie médicale et de chirurgie de précision.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;C : Cryptographie&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;D&apos;un simple clic, vous réglez un achat en ligne par carte bancaire. La communication est sécurisée : un pirate qui l&apos;intercepterait n&apos;y verrait rien d&apos;utilisable, juste une suite de chiffres apparemment sans signification.&lt;/p&gt;&lt;p&gt;Le numéro de votre carte a été transformé à l&apos;aide d&apos;une procédure de « chiffrement ».&lt;br /&gt;L&apos;algorithme utilisé n&apos;a rien de confidentiel. Mais pour déchiffrer et récupérer l&apos;information sous forme lisible, il faut connaître un élément secret : la clé. Cette clé est connue de la banque mais ni du site marchand ni de son client, ni d&apos;un éventuel pirate !&lt;br /&gt;Tout site ou toute personne souhaitant recevoir des communications sécurisées peut posséder sa propre clé. Il en tire une procédure de chiffrement que quiconque peut utiliser pour lui envoyer un message. C&apos;est un exemple de méthode cryptographique.&lt;br /&gt;Autrefois réservée aux militaires et aux diplomates, la cryptographie se retrouve aujourd&apos;hui dans les téléphones portables, le courrier électronique, certaines serrures de voiture...&lt;/p&gt;&lt;p&gt;La sécurité des méthodes cryptographiques les plus connues repose sur l&apos;extrême difficulté de certains problèmes mathématiques. Des progrès théoriques pourraient donc remettre en cause ces méthodes. Certains chercheurs explorent une nouvelle voie : la cryptographie quantique, qui exploite des propriétés fondamentales de la matière.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;D : Données&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Envie de cinéma ? Vous consultez un site qui vous renseigne sur les nouveaux films, puis votre smartphone vous indique le cinéma le plus proche et, après la séance, vous guide vers un restaurant, d&apos;où vous diffusez une photo... Vous voilà consommateur et producteur de données !&lt;/p&gt;&lt;p&gt;Le nom du cinéma, ses films et leurs horaires, pour chaque film son réalisateur et ses acteurs, pour chaque acteur... Autant de données que l&apos;on peut produire, stocker mais aussi interroger et manipuler.&lt;br /&gt;Pour les organiser, des systèmes de gestion de bases de données imposent des formats rigoureux et offrent des garanties sur leur cohérence et leur disponibilité. Or les données sont de plus en plus nombreuses. Et vous n&apos;y êtes pas pour rien ! Le site du cinéma enregistre votre visite. Votre banque enregistre le paiement de vos places. La carte qui vous guide enregistre votre déplacement… Alors imaginez les quantités de données concernant les activités de milliards d&apos;individus ! Mais ce n&apos;est pas tout. Les scientifiques, par exemple, produisent eux aussi des données en très grandes quantités, en décodant un génome, ou bien en observant des étoiles.&lt;/p&gt;&lt;p&gt;Les données, sans traitement, n&apos;apportent aucune information. Ce qui leur donne de la valeur, c’est de les manipuler et les analyser pour en extraire des connaissances. Mais analyser les données que j&apos;ai produites en allant au cinéma, est-ce vraiment compatible avec le respect de ma vie privée ?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;E : Equation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Les équations sont les phrases du grand livre de la nature qui, comme le disait Galilée, « est écrit en langage mathématique ». Dans ce langage universel, les symboles les plus abstraits ont le pouvoir des mots : ils nous racontent une histoire.&lt;/p&gt;&lt;p&gt;Dynamique des courants marins, réactions biochimiques dans nos cellules, contraintes sur la structure de bâtiments..., nous connaissons des équations qui représentent l&apos;évolution de ces phénomènes au fil du temps.&lt;br /&gt;On cherche d&apos;abord la solution de ces équations sous forme d&apos;expressions écrites avec des symboles abstraits. Mais ce n&apos;est pas toujours possible !&lt;br /&gt;On recourt alors aux ordinateurs. Plus rapides que nous avec les nombres, ils décrivent une fonction par ses valeurs en de multiples points. Si en chaque point cette fonction satisfait l&apos;équation, nous avons déniché une solution numérique du problème.&lt;br /&gt;À de nombreuses questions mathématiques sont associées des méthodes de calcul numérique, sans cesse raffinées pour améliorer leur précision et leur rapidité.&lt;/p&gt;&lt;p&gt;Savez-vous qu’on peut mettre en équations des instruments de musique ? Un piano, par exemple. Avec un peu d’imagination, en modifiant les équations, on peut même simuler le son de pianos impossibles à construire : pianos flottants, cordes de 7 mètres de long, etc. !&lt;/p&gt;&lt;p&gt;&lt;strong&gt;F : Forme&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Une forme n&apos;est pas seulement un motif visuel. Reconnaître un visage, comprendre un mot, distinguer un spam d’un autre message, repérer un électrocardiogramme anormal, pour un ordinateur, c&apos;est reconnaître une forme.&lt;/p&gt;&lt;p&gt;Pour un ordinateur, l’aspect des données importe peu : images, sons, textes ou résultats de mesures sont simplement une série de nombres. Ce qui est important, c’est la manière dont les données vont être classifiées. Parfois avec une définition explicite : « tout message contenant l’un des mots suivants sera rejeté ».  Parfois également avec une information moins tranchée qui s’interprète en termes statistiques : l’électrocardiogramme doit présenter des pics assez hauts mais pas trop larges. Enfin, souvent, avec des exemples que l’on cherche à apprendre : comme à un enfant, on montre à l’ordinateur des images d’une girafe, de telle sorte qu’il puisse identifier de lui-même les girafes dans d’autres images.  Pour l’instant, l’ordinateur reste moins fort que l’enfant dans ce domaine...&lt;/p&gt;&lt;p&gt;La nature produit des formes étonnantes, du relief des montagnes aux structures des organismes vivants. Ces formes sont étudiées et modélisées pour en comprendre l’origine et en prévoir les évolutions.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;G : Graphe&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;À quoi ressemblent vos relations ? À un graphe ! Constitué de nœuds et de liens, c’est la structure mathématique la plus élémentaire pour représenter des relations. Par exemple, les nœuds du graphe sont vos amis et les liens sont leurs relations d’amitié.&lt;/p&gt;&lt;p&gt;Si le terme de graphe est apparu pour désigner le squelette d’une molécule, aujourd’hui l’image du réseau ou du filet (net en anglais) s’impose. Autorisez un filet avec tous types de mailles, des nœuds sans lien, d’autres avec mille liens ou plus, vous obtenez un graphe.&lt;br /&gt;Les informaticiens voient des graphes un peu partout. Les réseaux informatiques en sont un domaine d’application évident. Pour acheminer un message de votre ordinateur jusqu’à un serveur, il faut trouver un chemin dans le graphe d’Internet. Trouver son chemin… Un problème plutôt simple quand on a une carte, mais qui se complique quand on ne dispose que d’informations partielles comme dans Internet. Les réseaux de transport sont aussi des graphes et le GPS dans votre voiture s’appuie sur des algorithmes sophistiqués de calcul de plus court chemin.&lt;/p&gt;&lt;p&gt;Malgré leur apparente simplicité mathématique et plusieurs siècles d’études, les graphes ont encore leurs mystères tant pour le mathématicien que pour l’informaticien. Par exemple, tester si deux graphes sont identiques est un problème pour lequel on ne sait pas encore s’il existe un algorithme efficace.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;H : HTTP &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;- C&apos;est sûr que je peux fournir le numéro de ma carte bancaire sur ce formulaire web ?&lt;br /&gt;- Mais oui, HTTP s&apos;est doté du « S » pour sécuriser cette transaction.&lt;br /&gt;- HTTP vous dites ? &lt;br /&gt;- Oui, HyperText Transfer Protocol !&lt;/p&gt;&lt;p&gt;HTTP est un protocole, c&apos;est-à-dire un ensemble de conventions qui permettent à deux machines de communiquer. A chaque fois qu&apos;on utilise le web, ce protocole applicatif est utilisé pour le transfert des données d&apos;un serveur vers l&apos;utilisateur via un navigateur. Il repose sur toute une hiérarchie d&apos;autres protocoles comme TCP/IP qui assurent sur Internet la connexion de l’utilisateur à n&apos;importe quel serveur et le transport des données via le réseau, de machine en machine. HTTP fonctionne sur le modèle client-serveur : le navigateur est le client d&apos;un serveur qui fournit par exemple la page web demandée.&lt;/p&gt;&lt;p&gt;Pour réduire la durée d&apos;un téléchargement, on optimise les protocoles de transfert ainsi que les systèmes de caches qui gardent des copies temporaires des données le long du chemin entre l’utilisateur et le serveur. On peut aussi dupliquer les serveurs afin d’envoyer les contenus à partir du serveur le plus proche de l’utilisateur.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;I : Internet&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Vous voulez souhaiter un bon anniversaire à un vieil ami qui s&apos;est retiré à Bora Bora ? Appelez le en vidéo grâce à Internet, le réseau des réseaux, qui relie les ordinateurs et autres appareils connectés tout autour du monde !&lt;/p&gt;&lt;p&gt;Comment toutes les données qui transitent par Internet arrivent-elles à bon port ?&lt;br /&gt;Le flux vidéo est d’abord découpé en petits paquets de données, faciles à ré-émettre s’il y a une erreur de transmission. Au début de chaque paquet, une étiquette indique son expéditeur, son destinataire et d’autres informations. Chaque paquet envoyé au boîtier  qui vous relie à Internet passe ensuite par plusieurs relais informatiques, les routeurs, reliés par des liens de communication. Il trouve ainsi sa route au fur et à mesure. Si un lien est coupé, les autres routeurs doivent se reconfigurer. Et il faut éviter les embouteillages dans le réseau, quitte à baisser la qualité de la vidéo. À destination, il reste à redemander les paquets erronés ou perdus, puis à réassembler les paquets dans le bon ordre.&lt;br /&gt;Au fait, comment dites-vous « bon anniversaire » en tahitien ?&lt;/p&gt;&lt;p&gt;Lorsqu’un ordinateur se connecte par radio à un point d’accès, l’information circule dans le réseau du fournisseur d’accès en charge de ce point. Puis elle passe au réseau plus étendu d’un opérateur national ou international. Les réseaux de plus haut niveau qui déploient leurs fibres tout autour du globe forment la colonne vertébrale d’Internet.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;J : Jeu &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Jérémy Le Robot vous lance un défi : une partie de morpion.&lt;br /&gt;La défaite est interdite. Pouvez-vous relever ce défi ?&lt;/p&gt;&lt;p&gt;Comment fait un ordinateur pour décider quel coup jouer ? Sa méthode est bien au point : il construit un arbre. La racine est la position initiale et il crée une branche pour chaque coup possible. Il obtient ainsi toutes les positions atteignables après un coup. En répétant ce processus, il peut donc anticiper les suites de la partie. S&apos;il arrive à tout calculer jusqu&apos;à la fin de la partie, il se transforme en joueur parfait. C&apos;est le cas pour le morpion, jeu auquel il ne peut pas perdre, et pour le puissance 4, où il gagne s’il commence.&lt;br /&gt;Pour des jeux comme les échecs ou le go, l&apos;arbre a trop de branches, impossibles à parcourir toutes.  Il n&apos;existe donc pas de joueur parfait. Mais un ordinateur reste tout de même un redoutable adversaire, capable par exemple de couper les branches les moins prometteuses.&lt;/p&gt;&lt;p&gt;Vous pouvez à présent relever le défi de Jérémy. Un petit conseil : demandez à jouer en premier et placez votre croix au centre. Et qui sait, peut-être un jour pourrez-vous programmer votre propre jeu ?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;K : Kilo&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;La quantité d&apos;information numérique n&apos;en finit plus d&apos;exploser. Avec régularité, elle double tous les deux ans, jusqu&apos;à plus de 50 milliards de milliards d’octets en 2020. Quelle masse énorme ! Mais qui ne « pèse » rien, car tout est question de codage.&lt;/p&gt;&lt;p&gt;Pour capter, stocker, traiter ou transmettre une information à l’aide d’un système informatique, il est nécessaire de coder cette information sous une forme permettant sa manipulation.&lt;br /&gt;Pour cela, on utilise seulement deux valeurs, 0 ou 1, ou bien « vrai » ou « faux », ou encore « oui » ou « non » : c&apos;est le codage binaire.  La plus petite information mémorisable et manipulable par une machine, un « atome » d&apos;information, est appelée &lt;em&gt;bit&lt;/em&gt; par contraction de &lt;em&gt;binary digit&lt;/em&gt;. Ces bits sont regroupés par paquets de huit, des octets.&lt;br /&gt;On peut ainsi représenter tout nombre, mais aussi des caractères, des images, des sons, avec des octets. Une page de texte pèsera ainsi de l&apos;ordre du kilo-octet (un millier), une image de l&apos;ordre du méga-octet (un million), un film de l&apos;ordre du giga-octet (un milliard).&lt;/p&gt;&lt;p&gt;Pour qu&apos;un texte, un son ou une image numérisés puissent être relus, il faut se mettre d&apos;accord sur un format de codage standard. C&apos;est par exemple le format mp3 pour les sons, le format jpeg pour les images. Pour gagner de la place, ces formats prévoient de compresser les données en éliminant les informations négligeables.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;L : Langage&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;L&apos;informatique a emprunté -volé ?- le mot langage pour parler des notations employées pour programmer les ordinateurs.  D&apos;où vient cet acharnement à toujours en inventer de nouveaux ?&lt;/p&gt;&lt;p&gt;On dit souvent qu&apos;un langage (de programmation) sert à dire à une machine ce qu&apos;elle doit faire.  Mais cela n&apos;explique pas la variété de ces langages ni comment ils ont évolué !  La raison en est que la programmation se pratique à plusieurs et dans la durée.  Du coup, un langage est d&apos;abord un moyen de dire à d&apos;autres humains ce qu&apos;on demande de faire à une machine.  Cette tâche étant très difficile, il n&apos;est pas étonnant de ne pas y arriver du premier coup, d&apos;où l&apos;invention permanente de nouveaux langages.  Une approche pour y arriver est de parler de moins en moins machine, pour parler de plus en plus domaine d&apos;application.  On espère ainsi faciliter la tâche des humains spécialistes de ces domaines.  Mais les domaines d&apos;applications étant très diversifiés, voici une nouvelle raison de créer de nouveaux langages.&lt;/p&gt;&lt;p&gt;Aujourd’hui un langage de programmation se développe souvent en s&apos;affranchissant des contraintes de la machine. C&apos;est donc aux chercheurs et ingénieurs créateurs de ces langages de prévoir la traduction des programmes pour humains en des programmes pour machines.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;M : Machine&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;De l’ordinateur au smartphone en passant par le processeur d’une machine à laver ou d’un pacemaker, ces machines ont toutes un point commun : elles traitent de l&apos;information.&lt;/p&gt;&lt;p&gt;Un outil, c&apos;est un objet avec un algorithme pour l’utiliser : ainsi une pierre pourra me servir de marteau. Une machine est un outil qui utilise une force motrice autonome. Les premières machines étaient construites pour faire plusieurs fois la même chose. Ainsi, l&apos;invention de l&apos;imprimerie a révolutionné la possibilité de reproduire et mémoriser de l&apos;information. Les machines à calculer, comme celle de Pascal, travaillaient déjà sur l&apos;information. Le métier à tisser de Jacquard est allé plus loin, en produisant des choses différentes en fonction de son programme de tissage. Mais cette machine mécanique ne pouvait pas se modifier elle-même. Au contraire, ce qui caractérise une machine à traiter l’information, c’est qu’elle peut modifier sa propre mémoire, exécuter tous les programmes, voire apprendre à adapter son programme aux données entrées.&lt;/p&gt;&lt;p&gt;Une tablette ou un ordinateur est une machine à traiter l’information, qui peut modifier son propre programme et devient ainsi une machine universelle. Toutes les machines universelles connues sont équivalentes, comme l&apos;avait compris Alan Turing, mathématicien anglais célébré pour cela comme l’un des pères de l’informatique.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;N : Numérique &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;10010111000010... c&apos;est à cela que ressemblent un texte, une image, un son, une vidéo... pour un ordinateur. Cette représentation numérique des objets permet de les transformer, dupliquer, partager et archiver, à un coût très faible... et le monde en est changé.&lt;/p&gt;&lt;p&gt;On parle de « société numérique », mais dans son sens le plus restreint, une information est numérique lorsqu’elle se présente sous forme de nombres.&lt;br /&gt;Les données  numérisées ne prennent qu&apos;un nombre fini de valeurs bien déterminées. Chaque caractère correspond à une valeur distincte. Une image est découpée en tous petits carrés : des pixels. À chaque pixel est associé un nombre qui représente une des couleurs de la palette. La musique ? Le découpage en minuscules intervalles de temps où l&apos;intensité du son est codée par un nombre permet de faire d’un morceau une suite de valeurs numériques.&lt;br /&gt;Une fois numérisées, toutes les données peuvent être mémorisées, transmises, compressées, chiffrées (pour être protégées) de la même façon. Et les appareils qui nous restituent ces informations (téléphone, téléviseur ou ordinateur) deviennent interchangeables.&lt;/p&gt;&lt;p&gt;La valeur numérisée d&apos;une information est forcément une représentation approximative de sa valeur réelle. Mais selon la finesse de l’échantillonnage et le degré de compression, la différence peut être imperceptible.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;O : Objet&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Quoi de plus simple qu&apos;un objet ? Cet abécédaire papier est là dans ma main : c&apos;est un objet. Mais il est aussi en ligne, numérisé. Alors qu&apos;en est-il du lien entre objets matériels et numériques ?&lt;/p&gt;&lt;p&gt;Avec la miniaturisation des systèmes informatiques, les objets de notre quotidien sont envahis de processeurs qui permettent d&apos;y intégrer du traitement de l&apos;information captée tout autour de nous.&lt;br /&gt;Ainsi, avec l’« Internet des objets », tout objet matériel est susceptible d&apos;être « identifié » par des dispositifs numériques, et  directement mis en relation avec du traitement de l&apos;information. Si mon stylo a un marqueur radio-fréquence, je peux le retrouver quand je l’ai égaré ou consulter ses données de fabrication, ou encore le relier à un logiciel de dessin.&lt;br /&gt;Cela crée un lien nouveau entre les objets matériels et logiciels et fait de notre monde usuel un monde enrichi par des objets numériques.&lt;/p&gt;&lt;p&gt;En programmation, un objet est défini par des données (ses attributs), et des fonctions programmées (ses méthodes), pour manipuler ses données et l&apos;interfacer avec d&apos;autres objets logiciels (algorithmes, bases de données…) ou matériels (caméra, robot…). Cette approche par objets permet de concevoir de grands systèmes logiciels complexes.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;P : Programme&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;On sait en général programmer une machine à laver ou entrer des formules dans une calculatrice programmable. De là à développer des applications pour tablette ou programmer un jeu sur ordinateur, il n’y a qu’un pas !&lt;/p&gt;&lt;p&gt;Qu’est-ce au juste qu’un programme ? C’est un texte, écrit dans un langage de programmation, qui transcrit un algorithme. Ce texte est traduit ou interprété dans le langage de la machine par un autre programme. La machine peut ensuite exécuter le programme, c’est-à-dire réaliser pas à pas les opérations indiquées.&lt;br /&gt;Pour résoudre des problèmes difficiles, il faut souvent enchaîner des algorithmes. Les programmes forment alors un ensemble structuré, qu’on nomme logiciel. Le programme principal définit l’enchaînement des sous-programmes, appelés pour traiter une partie des opérations. La structure d’un logiciel peut vite devenir complexe et un bug peut facilement s’y glisser. C’est pourquoi un autre programme vient à la rescousse pour vérifier la bonne exécution de l’ensemble.&lt;br /&gt;Les programmes de traduction et de vérification sont eux-mêmes traduits et vérifiés !&lt;/p&gt;&lt;p&gt;Souvent qualifiés d&apos;immatériels, les programmes utilisent pourtant des ressources pour être stockés, transmis ou exécutés.  Et certains sont trop gourmands.  Le développement durable de l&apos;informatique demande de réfréner cette gourmandise dans une démarche qu&apos;on appelle Green IT.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q : Qualité&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Une voiture de qualité, on sait ce que c&apos;est : fiable, solide, sûre, sobre, confortable... Mais un logiciel de qualité ?&lt;/p&gt;&lt;p&gt;Les propriétés que l&apos;on attend idéalement d&apos;un logiciel ne sont pas tellement différentes. Fiable, il donne toujours un résultat exact quand on lui fournit des données valides. Robuste, il détecte sans se « planter » les données qu&apos;il ne sait pas traiter. Sécurisé, il n&apos;ouvre pas de portes aux « pirates ».&lt;br /&gt;Efficace, il est rapide, ne mobilise pas trop de ressources de l&apos;ordinateur. Facile à utiliser pour les novices, il est performant pour les utilisateurs experts.&lt;br /&gt;Pour s&apos;approcher de cet idéal, les ingénieurs s&apos;appuient parfois sur des méthodes mathématiques rigoureuses : si l&apos;on parvient à décrire par des formules ce que l&apos;on attend d&apos;un logiciel, prouver qu&apos;il satisfait ces exigences revient à démontrer un ou plusieurs théorèmes. Une approche indispensable pour les applications où la sécurité est critique : cartes à puce ou pilotage de voiture ou d&apos;avion.&lt;/p&gt;&lt;p&gt;Pour les logiciels dits libres, la qualité passe par une autre voie : possibilité pour tout le monde d&apos;inspecter les « codes sources » et diffusion à de nombreux utilisateurs encouragés à signaler les problèmes rencontrés. Ainsi les éventuels défauts d&apos;un logiciel sont rapidement repérés et corrigés.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;R : Robot &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Quel lien y a-t-il entre « La guerre des étoiles » et une chaîne de montage automobile ?&lt;br /&gt;Les robots y sont nombreux ! En fait, ils sont partout : dans les usines et  les champs, au fond des mers, dans l’espace, dans les jardins et les salons.&lt;/p&gt;&lt;p&gt;Les robots sont les lointains cousins des ballerines mécaniques qui tournoient au sommet de boîtes à musique. Mais ils se distinguent de ces automates par leur capacité à s&apos;adapter à leur environnement dans leurs déplacements et leurs actions. &lt;br /&gt;Un robot n’est pas seulement doté d’un programme fixé de tâches à accomplir. Des questions imprévues peuvent se poser : que faire face à une pièce défectueuse, à un obstacle ? Un robot analyse son environnement par le biais de capteurs et de programmes informatiques, puis il s&apos;appuie sur des connaissances et des procédures variées pour déterminer comment réagir. &lt;br /&gt;Les robots sont utilisés pour des tâches qu&apos;ils remplissent mieux que les humains. Il peut s&apos;agir d&apos;un travail répétitif, d’une tâche de haute précision, ou d’une activité dans un environnement hostile.&lt;/p&gt;&lt;p&gt;Les robots sont des outils extraordinaires pour étudier et comprendre l’être humain et les animaux. Même si des robots aux allures d&apos;insectes ou de grues articulées sont bien éloignés des humanoïdes de la science-fiction, leur comportement si proche et pourtant si différent du nôtre n&apos;en finit pas de nous surprendre.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;S : Simulation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Qui n’a jamais rêvé de voyager dans le temps, tels les héros du film « Retour vers le futur » ? Pour voyager dans des mondes virtuels comme pour prévoir la météo, la simulation numérique s’appuie sur des modèles et des algorithmes.&lt;/p&gt;&lt;p&gt;Simuler pour prévoir, c’est le lot quotidien des centres de météo. &lt;br /&gt;Pour simuler, il faut un modèle qui représente la réalité en la simplifiant. C’est ici un système d’équations qui traduit l’évolution au cours du temps des grandeurs physiques comme la température. Il faut aussi connaître les conditions météo du jour.&lt;br /&gt;La simulation calcule une  solution approchée des équations en un nombre fini de points, qui forment un maillage de l’espace. Les calculs avancent dans le temps par petits intervalles, de l’instant initial à l’instant final.&lt;br /&gt;La simulation fait aussi voler les avions, battre les cœurs, pousser les végétaux. Les prévisions sont de plus en plus fiables grâce aux progrès dans la modélisation, l’assimilation des conditions initiales, les schémas d’approximation, les algorithmes de calcul, la vitesse des ordinateurs.&lt;/p&gt;&lt;p&gt;Les modèles multi-agents définissent les comportements individuels de chaque agent, qui peuvent être aléatoires. Les agents sont  par exemple des combattants dans une armée, comme dans le film « La bataille des cinq armées (Hobbit 3) ». La simulation fait alors émerger un phénomène collectif.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;T : Temps&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Combien de temps faut-il pour trier un paquet de cartes ?&lt;br /&gt;Pour résoudre un système de plusieurs équations ?&lt;br /&gt;Cela dépend de la vitesse d’exécution et de la méthode employée, mais aussi de la taille du paquet de cartes ou du nombre d’équations.&lt;/p&gt;&lt;p&gt;Grâce aux ordinateurs, il est possible de réaliser des opérations en un temps record. Mais gare au sortilège de la taille ! Trier un petit paquet de cartes va toujours vite, alors que trier un gros paquet peut prendre beaucoup de temps si l’algorithme n’est pas efficace. De même, il faut choisir l’algorithme le plus rapide pour résoudre un gros système d’équations. Parfois, le problème est tellement difficile que tout algorithme prend un temps énorme pour le résoudre.&lt;br /&gt;Pour aller plus vite, on peut aussi faire le travail à plusieurs. Un algorithme parallèle répartit les opérations entre plusieurs cœurs d’un processeur de calcul. Mais il faut éviter de perdre du temps à attendre ou à communiquer ! En effet, les opérations doivent être indépendantes pour être exécutées en même temps et les cœurs doivent échanger des résultats de calcul pour la suite des opérations.&lt;/p&gt;&lt;p&gt;Les systèmes temps réel doivent satisfaire des contraintes de temps cruciales pour la sécurité, comme pour le pilotage des avions ou le contrôle de centrales nucléaires. Ces systèmes embarqués doivent notamment respecter les délais et l’ordre des opérations.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;U : Utilisateur&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Qu&apos;est-ce qu&apos;un utilisateur en informatique ? Un simple numéro ? Un identifiant avec son mot de passe ? Ou alors, un homme ou une femme dont les besoins et les attentes sont pris en compte ?&lt;/p&gt;&lt;p&gt;Prendre en compte l&apos;utilisateur en informatique, c&apos;est d&apos;abord réduire l&apos;apprentissage nécessaire pour qu&apos;il se familiarise avec la machine. C&apos;est faire en sorte que la machine s’adapte au langage et au comportement de l&apos;utilisateur, et non l&apos;inverse. Cela demande aussi de tenir compte des différences entre les individus.&lt;br /&gt;Pour avoir une compréhension en profondeur de ses besoins et de ses attentes, il est nécessaire d’accorder à l’utilisateur un rôle central au cours de la conception. Ainsi, de simple « testeur  », il devient acteur.&lt;br /&gt;Enfin, n’oublions pas la dimension émotionnelle des interactions. Pourquoi ne pas faire en sorte qu&apos;utiliser un logiciel devienne plaisant comme un jeu ?&lt;/p&gt;&lt;p&gt;Après l’interface textuelle, où on entre des commandes que l&apos;on doit connaître, puis les  interfaces graphiques,  manipulées à la souris, ou de manière tactile, voici des interfaces qui se basent sur les mouvements de l&apos;utilisateur, la direction de son regard… Peu à peu l&apos;interface disparaît au profit d&apos;une interaction directe avec les objets numériques.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;V : Virtuel&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Vous souhaitez dépasser les limites de la vie quotidienne ? Embarquez avec nous pour découvrir les mondes parallèles de la « réalité virtuelle » !&lt;/p&gt;&lt;p&gt;Notre communication avec l&apos;ordinateur se limite en général à un écran, un clavier et une souris, alors que nos interactions avec l’environnement sont bien plus complexes.&lt;br /&gt;Munissez-vous d’un casque de visualisation et vous vivrez des expériences surprenantes où vous pourrez vous abstraire des limites de la réalité.&lt;br /&gt;Des capteurs vous permettront d’interagir avec l’environnement virtuel pour vous déplacer ou pour y réaliser des tâches. Vous voici immergés dans un univers numérique de la réalité virtuelle et au cœur de l&apos;action !&lt;br /&gt;La « réalité augmentée », quant à elle, insère des éléments virtuels dans la vision du monde qui nous entoure. Ainsi, un chirurgien peut superposer sur le corps du patient l&apos;image d&apos;un organe et des informations médicales comme des résultats d&apos;analyses, afin de mieux identifier les points essentiels d&apos;une opération.&lt;/p&gt;&lt;p&gt;La réalité virtuelle sert non seulement aux jeux vidéo, mais aussi à l&apos;entraînement des pilotes d&apos;avion, à la conception de voitures ou à la reconstitution par des archéologues de bâtiments disparus. Ces utilisations se généralisent grâce à la diminution du coût des équipements et à de nouveaux algorithmes.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;W : Web&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Vous cherchez un Musée. Vous achetez une place de concert. Vous vérifiez une formule de math. Vous dialoguez avec votre réseau d&apos;amis. Vous vendez votre voiture... Vous faites tout cela sur le Web, qui relie des quantités d&apos;informations et d&apos;applications.&lt;/p&gt;&lt;p&gt;WWW pour World Wide Web ou « la toile mondiale », un gigantesque réseau ubiquitaire de ressources numériques auquel nous accédons depuis de plus en plus d&apos;objets connectés : ordinateur, tablette, téléphone, mais aussi voiture, réfrigérateur... Dans toutes ces données liées, comment s’y retrouver ? Comment faire la différence par exemple entre la biographie de l&apos;auteur « Victor Hugo » et la description d&apos;une rue « Victor Hugo » ? Donner du sens aux termes que nous utilisons pour décrire le monde, c’est l&apos;objectif des chercheurs du Web sémantique et du Web de données. Ils étudient comment aider les machines et leurs applications, par exemple un moteur de recherche, à opérer ainsi des distinctions ou des rapprochements entre les données.&lt;/p&gt;&lt;p&gt;Les modèles et algorithmes du Web sémantique permettent d&apos;échanger, d&apos;enrichir et de relier des informations sur un film, une protéine, un auteur célèbre, une recette de cuisine, un médicament… Grâce à ces métadonnées, les machines peuvent traiter et utiliser la diversité des ressources du Web.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;X : XML &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Avez-vous déjà vécu le cauchemar des fichiers incompatibles ?&lt;br /&gt;Passer d&apos;un logiciel à un autre, parfois juste installer une nouvelle version... et hop, que de données sont irrécupérables ! Heureusement voici XML, le format universel !&lt;/p&gt;&lt;p&gt;Dans un fichier XML, chaque élément -paragraphe, titre, formule mathématique, graphique, son- est « étiqueté » selon sa nature. Une application peut facilement reconnaître, parmi ces éléments, ceux qu&apos;elle sait traiter, et les utiliser à sa façon. Un titre ? On l&apos;affiche en caractère gras... ou on l&apos;extrait pour constituer une table des &lt;br /&gt;matières. Une note de musique ? On la joue, ou on la dessine sur une portée. La structure du fichier est parfaitement mise en évidence, indépendamment des avatars qu&apos;on veut faire subir à son contenu.&lt;br /&gt;La norme XML n&apos;établit pas une liste prédéfinie d&apos;étiquettes mais standardise la façon d&apos;en créer selon les besoins pour chaque type de données : page web (XHTML), graphiques (SVG), partitions musicales (MusicXML). D&apos;où le X... comme eXtensible !&lt;/p&gt;&lt;p&gt;XML (eXtensible Markup Language, ou langage de balisage extensible), format unifié, aide à donner un sens aux données, mais permet aussi de réaliser des programmes « génériques » qui peuvent manipuler ou échanger des données de tous types sans avoir besoin de les interpréter.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Y : Yeux&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Les machines n&apos;ont pas d&apos;yeux,  ni de cerveau,  mais des caméras et des algorithmes.  &lt;br /&gt;Alors que peut signifier « voir » pour ces machines dépourvues de vie ?&lt;/p&gt;&lt;p&gt;Dès les années 1950, on programme les ordinateurs pour traiter des images. Le but est surtout d’en améliorer la qualité, par exemple augmenter le contraste en renforçant les contours.&lt;br /&gt;Puis, avec l&apos;explosion du nombre d’images et de vidéos, on commence à chercher à automatiser leur analyse : ces photos aériennes montrent-elles des zones urbaines ou des forêts ? &lt;br /&gt;Avec l&apos;amélioration des performances, on peut aussi équiper les robots de capteurs visuels. Ces capteurs extraient en temps réel quelques traits de la scène pour guider le robot dans la réalisation de sa tâche. La géométrie permet de calibrer  automatiquement ces données.&lt;/p&gt;&lt;p&gt;En vision par ordinateur, c&apos;est l&apos;amélioration des algorithmes qui bouleverse la donne : il devient possible de reconnaître un visage, détecter un événement visuel, analyser un scanner 3D.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Z : Zéro &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Les informaticiens aiment à dire pour plaisanter qu&apos;il y a 10 sortes de personnes : celles qui ne connaissent pas la numération binaire et celles qui la connaissent.&lt;br /&gt;Dans quelle catégorie êtes-vous ?&lt;/p&gt;&lt;p&gt;Une calculatrice qui additionne le prix des articles que l&apos;on veut acheter utilise les chiffres de 0 à 9 pour afficher son résultat.&lt;br /&gt;Pourtant, la machine effectue les calculs avec seulement deux valeurs : 0 et 1. Ils sont représentés par deux états d&apos;un composant électronique.&lt;br /&gt;Les machines comptent donc en base 2 : zéro est représenté par 0, un par 1, deux par 10, trois par 11... Ainsi il y a 10 (deux) catégories de personnes !&lt;br /&gt;Nous ne sommes plus à l&apos;époque héroïque où les programmeurs étaient directement confrontés à cette numération déroutante. Heureusement pour nous, les ordinateurs savent communiquer leurs résultats sous forme de nombres, lettres ou  images autrement plus compréhensibles !&lt;/p&gt;&lt;p&gt;La conversion des nombres décimaux en binaire, et réciproquement, introduit de petites erreurs d&apos;arrondis qui, amplifiées lors de séries de calculs, peuvent en fausser le résultat. Les algorithmes utilisés pour effectuer les opérations élémentaires dans les processeurs sont conçus pour limiter la propagation de ces erreurs.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='auteurs'>
      <item id='c_28972' class='generated.Auteur'>Auvin</item>
    </field>
    <field name='moissonnable'>false</field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89322' url='https://interstices.info/jcms/p_89322/intelligence-artificielle750'>
    <field name='title'>intelligence-artificielle750</field>
    <field name='pdate' time='1456493850471'>2016-02-26T14:37:30+01:00</field>
    <field name='udate' time='1456493850473'>2016-02-26T14:37:30+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1456493850473'>2016-02-26T14:37:30+01:00</field>
    <field name='mdate' time='1456493850473'>2016-02-26T14:37:30+01:00</field>
    <field name='filename' mtime='1456493851000' size='68827' ticket='Ot/9Tn/KliDIeXF1yaLF+Q=='>upload/docs/image/jpeg/2016-02/intelligence-artificielle750.jpg</field>
    <field name='originalFilename'>intelligence-artificielle750.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1456493850473'>2016-02-26T14:37:30+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>300</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>300 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89329' url='https://interstices.info/jcms/p_89329/asamples'>
    <field name='title'>asamples</field>
    <field name='pdate' time='1456494918384'>2016-02-26T14:55:18+01:00</field>
    <field name='udate' time='1456494918386'>2016-02-26T14:55:18+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1456494918386'>2016-02-26T14:55:18+01:00</field>
    <field name='mdate' time='1456494918386'>2016-02-26T14:55:18+01:00</field>
    <field name='filename' mtime='1456494919000' size='509666' ticket='YBlBjODL0Q7eI54ldhsbdQ=='>upload/docs/image/gif/2016-02/asamples.gif</field>
    <field name='originalFilename'>asamples.gif</field>
    <field name='contentType'>image/gif</field>
    <field name='uploadDate' time='1456494918386'>2016-02-26T14:55:18+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>200</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>8</value>
      </entry>
      <entry>
        <key>image.number-of-images</key>
        <value>37</value>
      </entry>
      <entry>
        <key>width</key>
        <value>320</value>
      </entry>
    </field>
  </data>
  <data class='generated.DocumentInterstices' id='p_89081' url='https://interstices.info/jcms/p_89081/les-enjeux-de-la-recherche-en-intelligence-artificielle'>
    <field name='title'>Les enjeux de la recherche en intelligence artificielle</field>
    <field name='categories'>
      <item id='jalios_5001' class='com.jalios.jcms.Category'>Navigation/Rubriques/Découvrir</item>
      <item id='mf_46787' class='com.jalios.jcms.Category'>Tags/Intelligence</item>
      <item id='mf_46803' class='com.jalios.jcms.Category'>Tags/Apprentissage</item>
      <item id='i_62034' class='com.jalios.jcms.Category'>CatTemporaire</item>
    </field>
    <field name='pdate' time='1456743600000'>2016-02-29T12:00:00+01:00</field>
    <field name='udate' time='1455727412057'>2016-02-17T17:43:32+01:00</field>
    <field name='version' major='1' minor='28'>1.28</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>full.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1455727412057'>2016-02-17T17:43:32+01:00</field>
    <field name='mdate' time='1462881433229'>2016-05-10T13:57:13+02:00</field>
    <field name='resume' abstract='true'>Qu’est-ce que l’intelligence ? Est-ce la capacité à percevoir le monde, à prédire le futur immédiat ou lointain, ou à planifier une série d’actions pour atteindre un but ? Est-ce la capacité d’apprendre, ou celle d’appliquer son savoir à bon escient ? La définition est difficile à cerner.</field>
    <field name='imageChapeau'>upload/docs/image/jpeg/2016-02/intelligence-artificielle750.jpg</field>
    <field name='legendeImageChapeau'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Image By Tej3478 (Own work) [&lt;a href=&quot;http://creativecommons.org/licenses/by-sa/4.0&quot;&gt;CC BY-SA 4.0&lt;/a&gt;], &lt;a href=&quot;https://commons.wikimedia.org/wiki/File%3AArtificial-intelligence-elon-musk-hawking.jpg&quot;&gt;via Wikimedia Commons&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</field>
    <field name='soustitre'>
    </field>
    <field name='texte'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;&lt;em&gt;&lt;em&gt;Une première version de cet article est parue sur le site du &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.college-de-france.fr/site/college/index.htm&quot; target=&quot;_blank&quot;&gt;Collège de France&lt;/a&gt;.&lt;/em&gt;&lt;/em&gt;&lt;/p&gt;&lt;h2&gt;Qu’est-ce que l’intelligence artificielle ?&lt;/h2&gt;&lt;p&gt;Qu’est-ce que l’intelligence ? Est-ce la capacité à percevoir le monde, à prédire le futur immédiat ou lointain, ou à planifier une série d’actions pour atteindre un but ? Est-ce la capacité d’apprendre, ou celle d’appliquer son savoir à bon escient ? La définition est difficile à cerner.&lt;/p&gt;&lt;p&gt;On pourrait dire que l’intelligence artificielle (IA) est un ensemble de techniques permettant à des machines d’accomplir des tâches et de résoudre des problèmes normalement réservés aux humains et à certains animaux.&lt;/p&gt;&lt;p&gt;Les tâches relevant de l’IA sont parfois très simples pour les humains, comme par exemple reconnaître et localiser les objets dans une image, planifier les mouvements d’un robot pour attraper un objet, ou conduire une voiture. Elles requièrent parfois de la planification complexe, comme par exemple pour jouer aux &lt;a href=&quot;jcms/int_70460/programmation-des-echecs-et-d-autres-jeux&quot;&gt;échecs&lt;/a&gt; ou au &lt;a href=&quot;jcms/c_43860/le-jeu-de-go-et-la-revolution-de-monte-carlo&quot;&gt;Go&lt;/a&gt;. Les tâches les plus compliquées requièrent beaucoup de connaissances et de sens commun, par exemple pour traduire un texte ou conduire un dialogue.&lt;/p&gt;&lt;p&gt;Depuis quelques années, on associe presque toujours l’intelligence aux capacités d’apprentissage. C’est grâce à l’apprentissage qu’un système intelligent capable d’exécuter une tâche peut améliorer ses performances avec l’expérience. C’est grâce à l’apprentissage qu’il pourra apprendre à exécuter de nouvelles tâches et acquérir de nouvelles compétences.&lt;/p&gt;&lt;p&gt;Le domaine de l’IA n’a pas toujours considéré l’apprentissage comme essentiel à l’intelligence. Par le passé, construire un système intelligent consistait à écrire un programme « à la main » pour jouer aux échecs (par recherche arborescente), reconnaître des caractères imprimés (par comparaison avec des images prototypes), ou faire un diagnostic médical à partir des symptômes (par déduction logique à partir de règles écrites par des experts). Mais cette approche « manuelle » a ses limites.&lt;/p&gt;&lt;h2&gt;L’apprentissage machine&lt;/h2&gt;&lt;p&gt;Les méthodes manuelles se sont avérées très difficiles à appliquer pour des tâches en apparence très simples comme la reconnaissance d’objets dans les images ou la reconnaissance vocale. Les données venant du monde réel — les échantillons d’un son ou les pixels d’une image — sont complexes, variables et entachées de bruit.&lt;/p&gt;&lt;p&gt;Pour une machine, une image est un tableau de nombres indiquant la luminosité (ou la couleur) de chaque pixel, et un signal sonore une suite de nombres indiquant la pression de l’air à chaque instant.&lt;/p&gt;&lt;p&gt;Comment une machine peut-elle transcrire la suite de nombres d’un signal sonore en série de mots tout en ignorant le bruit ambiant, l’accent du locuteur et les particularités de sa voix ? Comment une machine peut-elle identifier un chien ou une chaise dans le tableau de nombres d’une image quand l’apparence d’un chien ou d’une chaise et des objets qui les entourent peut varier infiniment ?&lt;/p&gt;&lt;p&gt;Il est virtuellement impossible d’écrire un programme qui fonctionnera de manière robuste dans toutes les situations. C’est là qu’intervient l’apprentissage machine (que l’on appelle aussi apprentissage automatique). C’est l’apprentissage qui anime les systèmes de toutes les grandes entreprises d’Internet. Elles l’utilisent depuis longtemps pour filtrer les contenus indésirables,&lt;br /&gt;ordonner des réponses à une recherche, faire des recommandations, ou sélectionner les informations intéressantes pour chaque utilisateur.&lt;/p&gt;&lt;p&gt;Un système entraînable peut être vu comme une boite noire avec une entrée, par exemple une image, un son, ou un texte, et une sortie qui peut représenter la catégorie de l’objet dans l’image, le mot prononcé, ou le sujet dont parle le texte. On parle alors de systèmes de classification ou de reconnaissance des formes.&lt;/p&gt;&lt;p&gt;Dans sa forme la plus utilisée, l’apprentissage machine est supervisé : on montre en entrée de la machine une photo d’un objet, par exemple une voiture, et on lui donne la sortie désirée pour une voiture. Puis on lui montre la photo d’un chien avec la sortie désirée pour un chien. Après chaque exemple, la machine ajuste ses paramètres internes de manière à rapprocher sa sortie de la sortie désirée. Après avoir montré à la machine des milliers ou des millions d’exemples étiquetés avec leur catégorie, la machine devient capable de classifier correctement la plupart d’entre eux. Mais ce qui est plus intéressant, c’est qu’elle peut aussi classifier correctement des images de voiture ou de chien qu’elle n’a jamais vues durant la phase l’apprentissage. C’est ce qu’on appelle la &lt;em&gt;capacité de généralisation&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;Jusqu’à récemment, les systèmes de reconnaissance des formes classiques étaient composés de deux blocs : un extracteur de caractéristiques (&lt;em&gt;feature extractor&lt;/em&gt; en anglais), suivi d’un classifieur entraînable simple. L’extracteur de caractéristiques est programmé « à la main », et transforme le tableau de nombres représentant l’image en une série de nombres, un &lt;em&gt;vecteur de caractéristiques&lt;/em&gt;, dont chacun indique la présence ou l’absence d’un motif simple dans l’image. Ce vecteur est&lt;br /&gt;envoyé au classifieur, dont un type commun est le &lt;em&gt;classifieur linéaire&lt;/em&gt;. Ce dernier calcule une somme pondérée des caractéristiques : chaque nombre est multiplié par un poids (positif ou négatif) avant d’être sommé. Si la somme est supérieure à un seuil, la classe est reconnue. Les poids forment une sorte de « prototype » pour la classe à laquelle le vecteur de caractéristiques est comparé. Les poids sont différents pour les classifieurs de chaque catégorie, et ce sont eux qui sont modifiés lors de l’apprentissage. Les premières méthodes de classification linéaire entraînable datent de la fin des années cinquante et sont toujours largement utilisées aujourd’hui. Elles prennent les doux noms de &lt;em&gt;perceptron&lt;/em&gt; ou &lt;em&gt;régression logistique&lt;/em&gt;.&lt;/p&gt;&lt;h2&gt;Apprentissage profond et réseaux neuronaux&lt;/h2&gt;&lt;p&gt;Le problème de l’approche classique de la reconnaissance des formes est qu’un bon extracteur de caractéristiques est très difficile à construire, et qu’il doit être repensé pour chaque nouvelle application.&lt;/p&gt;&lt;p&gt;C’est là qu’intervient l’apprentissage profond ou &lt;em&gt;deep learning&lt;/em&gt; en anglais. C’est une classe de méthodes dont les principes sont connus depuis la fin des années 1980, mais dont l’utilisation ne s’est vraiment généralisée que depuis 2012, environ.&lt;/p&gt;&lt;p&gt;L’idée est très simple : le système entraînable est constitué d’une série de modules, chacun représentant une étape de traitement. Chaque module est entraînable, comportant des paramètres ajustables similaires aux poids des classifieurs linéaires. Le système est entraîné de bout en bout : à chaque exemple, tous les paramètres de tous les modules sont ajustés de manière à rapprocher la sortie produite par le système de la sortie désirée. Le qualificatif &lt;em&gt;profond&lt;/em&gt; vient de l’arrangement de ces modules en couches successives.&lt;/p&gt;&lt;p&gt;Pour pouvoir entraîner le système de cette manière, il faut savoir dans quelle direction et de combien ajuster chaque paramètre de chaque module. Pour cela il faut calculer un &lt;em&gt;gradient&lt;/em&gt;, c’est-à-dire pour chaque paramètre ajustable, la quantité par laquelle l’erreur en sortie augmentera ou diminuera lorsqu’on modifiera le paramètre d’une quantité donnée. Le calcul de ce gradient se fait par la méthode de &lt;em&gt;rétropropagation&lt;/em&gt;, pratiquée depuis le milieu des années 1980.&lt;/p&gt;&lt;p&gt;Dans sa réalisation la plus commune, une architecture profonde peut être vue comme un réseau multicouche d’éléments simples, similaires aux classifieurs linéaires, interconnectés par des poids entraînables. C’est ce qu’on appelle un réseau neuronal multicouche.&lt;/p&gt;&lt;p&gt;Pourquoi neuronal ? Un modèle extrêmement simplifié des neurones du cerveau les voit comme calculant une somme pondérée et activant leur sortie lorsque celle-ci dépasse un seuil. L’apprentissage modifie les efficacités des &lt;em&gt;synapses&lt;/em&gt;, les poids des connexions entre neurones. Un réseau neuronal n’est pas un modèle précis des circuits du cerveau, mais est plutôt vu comme un modèle conceptuel ou fonctionnel. Le réseau neuronal est inspiré du cerveau un peu comme l’avion est inspiré de l’oiseau.&lt;/p&gt;&lt;p&gt;Ce qui fait l’avantage des architectures profondes, &lt;em&gt;c’est leur capacité d’apprendre à représenter le monde de manière hiérarchique&lt;/em&gt;. Comme toutes les couches sont entraînables, nul besoin de construire un extracteur de caractéristiques à la main. L’entraînement s’en chargera. De plus, les premières couches extrairont des caractéristiques simples (présence de contours) que les couches suivantes combineront pour former des concepts de plus en plus complexes et abstraits : assemblages de contours en motifs, de motifs en parties d’objets, de parties d’objets en objets, etc.&lt;/p&gt;&lt;h2&gt;Réseaux convolutifs, réseaux récurrents&lt;/h2&gt;&lt;p&gt;Une architecture profonde particulièrement répandue est le &lt;em&gt;réseau convolutif&lt;/em&gt;. C’est un peu mon invention. J’ai développé les premières versions en 1988-1989 d’abord à l’Université de Toronto où j’étais post-doctorant avec Geoffrey Hinton (qui travaille maintenant chez Google), puis aux Bell Laboratories, qui était à l’époque le prestigieux labo de recherche de la compagnie&lt;br /&gt;de télécommunication AT&amp;amp;T.&lt;/p&gt;&lt;p&gt;&lt;img style=&quot;float: right;&quot; title=&quot;asamples.&quot; src=&quot;upload/docs/image/gif/2016-02/asamples.gif&quot; alt=&quot;asamples&quot; width=&quot;320&quot; height=&quot;200&quot; /&gt;Les réseaux convolutifs sont une forme particulière de réseau neuronal multicouche dont l’architecture des connexions est inspirée de celle du cortex visuel des mammifères. Par exemple, chaque élément n’est connecté qu’à un petit nombre d’éléments voisins dans la couche précédente. J’ai d’abord utilisé les réseaux convolutifs pour la reconnaissance de caractères (ci-à droite, un exemple de réseau convolutif conçu pour la reconnaissance de caractères manuscrits et imprimés). Mes collègues et moi avons développé un système automatique de lecture de chèques qui a été déployé largement dans le monde dès 1996, y compris en France dans les distributeurs de billets du Crédit Mutuel de Bretagne. À la fin des années 1990, ce système lisait entre 10 et 20 % de tous les chèques émis aux États-Unis. Mais ces méthodes étaient plutôt difficiles à mettre en œuvre avec les ordinateurs de l’époque, et malgré ce succès, les réseaux convolutifs — et les réseaux neuronaux plus généralement — ont été délaissés par la communauté de la recherche entre 1997 et 2012.&lt;/p&gt;&lt;p&gt;En 2003, Geoffrey Hinton (de l’Université de Toronto), Yoshua Bengio (de l’Université de Montréal) et moi-même à NYU (l’Université de New York), décidions de démarrer un programme de recherche pour remettre au goût du jour les réseaux neuronaux, et pour améliorer leurs performances afin de raviver l’intérêt de la communauté. Ce programme a été financé en partie par la fondation CIFAR (l’Institut Canadien de Recherches Avancées), je l’appelle parfois « la conspiration de l’apprentissage profond ».&lt;/p&gt;&lt;p&gt;En 2011-2012, trois événements ont soudainement changé la donne. Tout d’abord, les &lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/Processeur_graphique&quot; target=&quot;_blank&quot;&gt;&lt;span class=&quot;lienExterne&quot;&gt;GPU&lt;/span&gt;s&lt;/a&gt; (&lt;em&gt;Graphical Processing Units&lt;/em&gt;) capables de plus de mille milliards d’opérations par seconde sont devenus disponibles pour moins de 1000 euros la carte. Ces puissants processeurs spécialisés, initialement conçus pour le rendu graphique des jeux vidéo, se sont avérés être très performants pour les calculs des réseaux neuronaux. Deuxièmement, des expériences menées simultanément à Microsoft, Google et IBM avec l’aide du laboratoire de Geoff Hinton ont montré que les réseaux profonds pouvaient diminuer de moitié les taux d’erreurs des systèmes de reconnaissance vocale. Troisièmement, plusieurs records en reconnaissance d’image ont été battus par des réseaux convolutifs. L’événement le plus marquant a été la victoire éclatante de l’équipe de Toronto dans la compétition de reconnaissance d’objets « &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.image-net.org/&quot; target=&quot;_blank&quot;&gt;ImageNet&lt;/a&gt; ». La diminution des taux d’erreurs était telle qu’une véritable révolution d’une rapidité inouïe s’est déroulée. Du jour au lendemain, la majorité des équipes de recherche en parole et en vision ont abandonné leurs méthodes préférées et sont passées aux réseaux convolutifs et autres réseaux neuronaux.&lt;/p&gt;&lt;p&gt;L’industrie d’Internet a immédiatement saisi l’opportunité et a commencé à investir massivement dans des équipes de recherche et développement en apprentissage profond. L’apprentissage profond ouvre une porte vers des progrès significatifs en intelligence artificielle. C’est la cause première du récent renouveau d’intérêt pour l’IA.&lt;/p&gt;&lt;p&gt;Une autre classe d’architecture, les réseaux récurrents, est aussi revenue au goût du jour. Ces architectures sont particulièrement adaptées au traitement de signaux séquentiels, tel que le texte. Les progrès sont rapides, mais il y a encore du chemin à parcourir pour produire des systèmes de compréhension de texte et de traduction.&lt;/p&gt;&lt;h2&gt;L’intelligence artificielle aujourd’hui. Ses enjeux&lt;/h2&gt;&lt;p&gt;Les opportunités sont telles que l’IA, particulièrement l’apprentissage profond, est vue comme des technologies d’importance stratégique pour l’avenir.&lt;/p&gt;&lt;p&gt;Les progrès en vision par ordinateur ouvrent la voie aux voitures sans chauffeur, et à des systèmes automatisés d’analyse d’imagerie médicale. D’ores et déjà, certaines voitures haut de gamme utilisent le système de vision de la compagnie israélienne MobilEye qui utilise un réseau convolutif pour l’assistance à la conduite. Des systèmes d’analyse d’images médicales détectent&lt;br /&gt;des mélanomes et autres tumeurs de manière plus fiable que des radiologues expérimentés. Chez Facebook, Google et Microsoft, des systèmes de reconnaissance d’image permettent la recherche et l’organisation des photos et le filtrage d’images violentes ou pornographiques.&lt;/p&gt;&lt;p&gt;Depuis plusieurs années déjà, tous les moteurs de reconnaissance vocale sur smartphone utilisent l’apprentissage profond.&lt;/p&gt;&lt;p&gt;Des efforts considérables de R&amp;amp;D sont consacrés au traitement du langage naturel : la compréhension de texte, les systèmes de question-réponse, les systèmes de dialogue pour les agents virtuels, et la traduction automatique. Dans ce domaine, la révolution de l’apprentissage profond a été annoncée, mais n’est pas encore achevée. Néanmoins, on assiste à des progrès rapides. Dans la dernière compétition internationale de traduction automatique, le gagnant utilisait un réseau récurrent.&lt;/p&gt;&lt;h2&gt;La recherche en intelligence artificielle et les obstacles au progrès&lt;/h2&gt;&lt;p&gt;Malgré tous ces progrès, nous sommes encore bien loin de produire des machines aussi intelligentes que l’humain, ni même aussi intelligentes qu’un rat.&lt;/p&gt;&lt;p&gt;Bien sûr, nous avons des systèmes qui peuvent conduire une voiture, jouer aux échecs et au Go, et accomplir d’autres tâches difficiles de manière plus fiable et rapide que la plupart des humains (sans parler des rats). Mais ces systèmes sont très spécialisés. Un gadget à 30 euros nous bat à plate couture aux échecs, mais il ne peut faire rien d’autre.&lt;/p&gt;&lt;p&gt;Ce qui manque aussi aux machines, c’est la capacité à apprendre des tâches qui impliquent non seulement d’apprendre à représenter le monde, mais aussi à se remémorer, à raisonner, à prédire, et à planifier. Beaucoup de travaux actuels à &lt;a class=&quot;lienExterne&quot; href=&quot;https://research.facebook.com/ai&quot; target=&quot;_blank&quot;&gt;&lt;span class=&quot;lienExterne&quot;&gt;Facebook AI Research&lt;/span&gt;&lt;/a&gt; et à DeepMind sont focalisés sur cette question. Une nouvelle classe de réseaux neuronaux, les &lt;em&gt;Memory-Augmented Recurrent Neural Nets&lt;/em&gt; (réseaux récurrents à mémoire) est utilisée de manière expérimentale pour la traduction, la production de légendes pour les images, et les systèmes de dialogues.&lt;/p&gt;&lt;p&gt;Mais ce qui manque principalement aux machines, c’est le sens commun, et la capacité à &lt;em&gt;l’intelligence générale&lt;/em&gt; qui permet d’acquérir de nouvelles compétences, quel qu’en soit le domaine. Mon opinion, qui n’est partagée que par certains de mes collègues, est que l’acquisition du sens commun passe par &lt;em&gt;l’apprentissage non supervisé&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;Qu’il soit naturel ou artificiel, il y a trois formes principales d’apprentissage. Nous avons déjà parlé de l’apprentissage supervisé. Les deux autres formes sont l’apprentissage par renforcement, et l’apprentissage non supervisé.&lt;/p&gt;&lt;p&gt;L’apprentissage par renforcement désigne la situation où la machine ne reçoit qu’un simple signal, une sorte de récompense, indiquant si la réponse produite était correcte ou pas. Le scénario est similaire à l’entraînement d’un animal de cirque à qui l’on donne une friandise lorsqu’il exécute l’action désirée. Cette forme d’apprentissage nécessite de très nombreux essais, et est utilisée principalement pour entraîner les machines à jouer à des jeux (par exemple les jeux vidéo ou le jeu de Go), ou à opérer dans des environnements simulés. On a assisté à un succès éclatant de l’apprentissage par renforcement combiné à l’apprentissage profond lors de la victoire récente du programme de Go &lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/AlphaGo&quot; target=&quot;_blank&quot;&gt;AlphaGo&lt;/a&gt; de DeepMind face au champion européen.&lt;/p&gt;&lt;p&gt;L’apprentissage non supervisé, quant à lui, est le mode principal d’apprentissage des animaux et des humains. C’est l’apprentissage que nous faisons par nous-mêmes en observant le monde et en agissant. C’est en observant le monde que nous apprenons qu’il a trois dimensions, que des objets peuvent en cacher d’autres, que certains objets peuvent être déplacés, qu’un objet sans support tombe, qu’un objet ne peut pas être à deux endroits en même temps, etc.&lt;/p&gt;&lt;p&gt;C’est grâce à l’apprentissage non supervisé que nous pouvons interpréter une phrase simple comme « Jean prend son portable et sort de la pièce ». On peut inférer que Jean et son portable ne sont plus dans la pièce, que le portable en question est un téléphone, que Jean s’est levé, qu’il a étendu sa main pour attraper son portable, qu’il a marché vers la porte. Il n’a pas volé, il n’est pas passé à travers le mur. Nous pouvons faire cette inférence, car nous savons comment le monde fonctionne. C’est le sens commun.&lt;/p&gt;&lt;p&gt;Comment acquérir ce sens commun ? Une hypothèse possible est &lt;em&gt;l’apprentissage prédictif&lt;/em&gt;. Si l’on entraîne une machine à prédire le futur, elle ne peut y arriver qu’en élaborant une bonne représentation du monde et de ses contraintes physiques. Dans un scénario d’apprentissage prédictif, on montre à la machine un segment de vidéo, et on lui demande de prédire quelques images suivantes. Malheureusement, le futur est impossible à prédire exactement et la machine s’en tient à produire une image floue, une mixture de tous les futurs possibles.&lt;/p&gt;&lt;p&gt;Si l’intelligence est un gâteau au chocolat, le gâteau lui-même est l’apprentissage non supervisé, le glaçage est l’apprentissage supervisé, et la cerise sur le gâteau est l’apprentissage par renforcement. Les chercheurs en IA sont dans la même situation embarrassante que les physiciens : 95 % de la masse de l’univers est de nature complètement inconnue : matière noire et énergie noire. La matière noire de l’AI est la génoise au chocolat de l’apprentissage non supervisé.&lt;/p&gt;&lt;p&gt;Tant que le problème de l’apprentissage non supervisé ne sera pas résolu, nous n’aurons pas de machine vraiment intelligente. C’est une question fondamentale scientifique et mathématique, pas une question de technologie. Résoudre ce problème pourra prendre de nombreuses années ou plusieurs décennies. En vérité, nous n’en savons rien.&lt;/p&gt;&lt;h2&gt;À quoi ressembleront les machines intelligentes de demain ?&lt;/h2&gt;&lt;p&gt;Si nous arrivons à concevoir des techniques d’apprentissage machine aussi générales et performantes que celle de la nature, à quoi ressembleront les machines intelligentes de demain ?&lt;/p&gt;&lt;p&gt;Il est très difficile d’imaginer une entité intelligente qui n’ait pas toutes les qualités et les défauts des humains, car l’humain est notre seul exemple d’entité intelligente. Comme tous les animaux, les humains ont des pulsions et des instincts gravés dans notre cerveau reptilien par l’évolution pour la survie de l’espèce. Nous avons l’instinct de préservation, nous pouvons devenir violents lorsque nous sommes menacés, nous désirons l’accès aux ressources pour ne pas mourir de faim, ce qui peut nous rendre jaloux, etc. Nos instincts d’animaux sociaux nous conduisent aussi à rechercher la compagnie d’autres humains. Mais les machines intelligentes n’auront aucune raison de posséder ces pulsions et instincts. Pour qu’elles les aient, il faudrait que leurs concepteurs les construisent explicitement.&lt;/p&gt;&lt;p&gt;Les machines intelligentes du futur auront des sentiments, des plaisirs, des peurs, et des valeurs morales. Ces valeurs seront une combinaison de comportements, d’instinct et de pulsions programmés avec des comportements appris.&lt;/p&gt;&lt;p&gt;Dans quelques décennies, quand nous pourrons peut-être penser à concevoir des machines réellement intelligentes, nous devrons répondre à la question de comment aligner les valeurs des machines avec les valeurs morales humaines.&lt;/p&gt;&lt;p&gt;Mais c’est un futur lointain où l’on pourra donner de l’autonomie aux machines. D’ici là, les machines seront certes intelligentes, mais pas autonomes. Elles ne seront pas à même de définir leurs propres buts et motivations. L’ordinateur de votre voiture s’en tiendra à conduire votre voiture en toute sécurité. L’IA sera un amplificateur de notre intelligence, et non un substitut pour celle-ci.&lt;/p&gt;&lt;p&gt;Malgré les déclarations de certaines personnalités, le scénario à la &lt;em&gt;Terminator&lt;/em&gt; est immensément improbable. Tout d’abord, il faut garder à l’esprit que l’apparition de l’IA ne sera pas un événement singulier, ni le fait d’un groupe isolé. Le progrès de l’IA sera progressif et ouvert. Comprendre l’intelligence est une des grandes questions scientifiques de notre temps. Aucune organisation, si puissante soit-elle, ne peut résoudre ce problème en isolation. La conception de machines intelligentes nécessitera la collaboration ouverte de la communauté de la recherche entière.&lt;/p&gt;&lt;h2&gt;Faut-il avoir peur de l’intelligence artificielle ?&lt;/h2&gt;&lt;p&gt;L’IA n’éliminera donc pas l’humanité de sa propre initiative.&lt;/p&gt;&lt;p&gt;Mais comme toute technologie puissante, l’IA peut être utilisée pour le bénéfice de l’humanité entière ou pour le bénéfice d’un petit nombre aux dépens du plus grand nombre.&lt;/p&gt;&lt;p&gt;L’émergence de l’AI va sans doute déplacer des métiers. Mais elle va aussi sauver des vies (par la sécurité routière et la médecine). Elle va très probablement s’accompagner d’une croissance de la production de richesses par habitant. La question pour les instances dirigeantes est comment distribuer ces nouvelles richesses, et comment former les travailleurs déplacés aux nouveaux métiers créés par le progrès technologique. C’est une question politique et non technologique. C’est une question qui n’est pas nouvelle : l’effet du progrès technologique sur le marché du travail existe depuis la révolution industrielle. L’émergence de l’IA n’est qu’un symptôme de l’accélération du progrès technologique.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='imagette'>upload/docs/image/jpeg/2016-02/ai115.jpg</field>
    <field name='encarts'>
    </field>
    <field name='auteurs'>
      <item id='p_89080' class='generated.Auteur'>LeCun</item>
    </field>
    <field name='moissonnable'>false</field>
    <field name='motsCles'>
    </field>
    <field name='indiceDewey'>
    </field>
    <field name='publicVise'>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88989' url='https://interstices.info/jcms/p_88989/marvin-minsky750'>
    <field name='title'>marvin-minsky750</field>
    <field name='pdate' time='1455200798734'>2016-02-11T15:26:38+01:00</field>
    <field name='udate' time='1455200798735'>2016-02-11T15:26:38+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1455200798735'>2016-02-11T15:26:38+01:00</field>
    <field name='mdate' time='1455200798735'>2016-02-11T15:26:38+01:00</field>
    <field name='filename' mtime='1455200799000' size='47783' ticket='Eu1bYIAz7OZ3x5vGaPu0/g=='>upload/docs/image/jpeg/2016-02/marvin-minsky750.jpg</field>
    <field name='originalFilename'>marvin-minsky750.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1455200798735'>2016-02-11T15:26:38+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>260</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>260 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88993' url='https://interstices.info/jcms/p_88993/minsky-marvin-societyofmindcover'>
    <field name='title'>Minsky-Marvin-SocietyofMindCover</field>
    <field name='pdate' time='1455204381957'>2016-02-11T16:26:21+01:00</field>
    <field name='udate' time='1455204381958'>2016-02-11T16:26:21+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1455204381958'>2016-02-11T16:26:21+01:00</field>
    <field name='mdate' time='1455204381958'>2016-02-11T16:26:21+01:00</field>
    <field name='filename' mtime='1455204383000' size='141950' ticket='GXQCrBMEbWZGV5McyKzyrw=='>upload/docs/image/jpeg/2016-02/minsky-marvin-societyofmindcover.jpg</field>
    <field name='originalFilename'>Minsky-Marvin-SocietyofMindCover.JPG</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1455204381958'>2016-02-11T16:26:21+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>793</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.Date/Time</key>
        <value>2012:05:08 11:07:44</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.Make</key>
        <value>Epson           </value>
      </entry>
      <entry>
        <key>image.Exif IFD0.Model</key>
        <value>Perfection4990  </value>
      </entry>
      <entry>
        <key>image.Exif IFD0.Orientation</key>
        <value>Top, left side (Horizontal / normal)</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.ResolutionUnit</key>
        <value>Inch</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.Software</key>
        <value>ACD Systems Digital Imaging</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.XResolution</key>
        <value>300 dots per inch</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.YCbCrPositioning</key>
        <value>Center of pixel array</value>
      </entry>
      <entry>
        <key>image.Exif IFD0.YResolution</key>
        <value>300 dots per inch</value>
      </entry>
      <entry>
        <key>image.Exif SubIFD.ColorSpace</key>
        <value>Unknown</value>
      </entry>
      <entry>
        <key>image.Exif SubIFD.Date/TimeDigitized</key>
        <value>2006:09:03 12:32:29</value>
      </entry>
      <entry>
        <key>image.Exif SubIFD.ExifImageHeight</key>
        <value>793 pixels</value>
      </entry>
      <entry>
        <key>image.Exif SubIFD.ExifImageWidth</key>
        <value>600 pixels</value>
      </entry>
      <entry>
        <key>image.Exif SubIFD.Sub-SecTime</key>
        <value>570</value>
      </entry>
      <entry>
        <key>image.Exif SubIFD.Sub-SecTimeDigitized</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.ICC Profile.BlueColorant</key>
        <value>(0.14918518, 0.06321716, 0.7445679)</value>
      </entry>
      <entry>
        <key>image.ICC Profile.BlueTRC</key>
        <value>0.0085908</value>
      </entry>
      <entry>
        <key>image.ICC Profile.CMMType</key>
        <value>ADBE</value>
      </entry>
      <entry>
        <key>image.ICC Profile.Class</key>
        <value>Display Device</value>
      </entry>
      <entry>
        <key>image.ICC Profile.Colorspace</key>
        <value>RGB </value>
      </entry>
      <entry>
        <key>image.ICC Profile.Copyright</key>
        <value>(c) 2000 Adobe Systems Inc.</value>
      </entry>
      <entry>
        <key>image.ICC Profile.Devicemanufacturer</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.ICC Profile.GreenColorant</key>
        <value>(0.20527649, 0.6256714, 0.06086731)</value>
      </entry>
      <entry>
        <key>image.ICC Profile.GreenTRC</key>
        <value>0.0085908</value>
      </entry>
      <entry>
        <key>image.ICC Profile.MediaBlackPoint</key>
        <value>(0.0, 0.0, 0.0)</value>
      </entry>
      <entry>
        <key>image.ICC Profile.MediaWhitePoint</key>
        <value>(0.9504547, 1.0, 1.0890503)</value>
      </entry>
      <entry>
        <key>image.ICC Profile.PrimaryPlatform</key>
        <value>Microsoft Corporation</value>
      </entry>
      <entry>
        <key>image.ICC Profile.ProfileConnectionSpace</key>
        <value>XYZ </value>
      </entry>
      <entry>
        <key>image.ICC Profile.ProfileDate/Time</key>
        <value>Wed May 10 12:00:00 CEST 2000</value>
      </entry>
      <entry>
        <key>image.ICC Profile.ProfileDescription</key>
        <value>Adobe RGB (1998)</value>
      </entry>
      <entry>
        <key>image.ICC Profile.ProfileSize</key>
        <value>544</value>
      </entry>
      <entry>
        <key>image.ICC Profile.RedColorant</key>
        <value>(0.6097412, 0.31111145, 0.019470215)</value>
      </entry>
      <entry>
        <key>image.ICC Profile.RedTRC</key>
        <value>0.0085908</value>
      </entry>
      <entry>
        <key>image.ICC Profile.Signature</key>
        <value>acsp</value>
      </entry>
      <entry>
        <key>image.ICC Profile.TagCount</key>
        <value>10</value>
      </entry>
      <entry>
        <key>image.ICC Profile.Version</key>
        <value>2.1.0</value>
      </entry>
      <entry>
        <key>image.ICC Profile.XYZvalues</key>
        <value>0.9642029 1.0 0.8249054</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/2 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>793 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>600 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.Photoshop.IPTC-NAARecord</key>
        <value>6 bytes binary data</value>
      </entry>
      <entry>
        <key>image.Xmp.Date/TimeDigitized</key>
        <value>Sun Sep 03 22:32:29 CEST 2006</value>
      </entry>
      <entry>
        <key>image.Xmp.Make</key>
        <value>Epson           </value>
      </entry>
      <entry>
        <key>image.Xmp.Model</key>
        <value>Perfection4990  </value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>600</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89300' url='https://interstices.info/jcms/p_89300/perceptrons-1st-300'>
    <field name='title'>perceptrons-1st-300</field>
    <field name='pdate' time='1456408750897'>2016-02-25T14:59:10+01:00</field>
    <field name='udate' time='1456408750898'>2016-02-25T14:59:10+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1456408750899'>2016-02-25T14:59:10+01:00</field>
    <field name='mdate' time='1456408750899'>2016-02-25T14:59:10+01:00</field>
    <field name='filename' mtime='1456408751000' size='38933' ticket='qpuek9UFnMW2o4d6GJBtBA=='>upload/docs/image/jpeg/2016-02/perceptrons-1st-300.jpg</field>
    <field name='originalFilename'>perceptrons-1st-300.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1456408750899'>2016-02-25T14:59:10+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>471</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>471 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>300 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>300</value>
      </entry>
    </field>
  </data>
  <data class='generated.DocumentInterstices' id='p_88809' url='https://interstices.info/jcms/p_88809/marvin-minsky-un-pere-visionnaire-de-l-intelligence-artificielle'>
    <field name='title'>Marvin Minsky, un père visionnaire de l&apos;intelligence artificielle</field>
    <field name='categories'>
      <item id='jalios_5002' class='com.jalios.jcms.Category'>Navigation/Rubriques/Itinéraires</item>
      <item id='mf_46787' class='com.jalios.jcms.Category'>Tags/Intelligence</item>
      <item id='mf_46800' class='com.jalios.jcms.Category'>Tags/Histoire</item>
      <item id='i_62034' class='com.jalios.jcms.Category'>CatTemporaire</item>
    </field>
    <field name='pdate' time='1456736400000'>2016-02-29T10:00:00+01:00</field>
    <field name='udate' time='1454494127145'>2016-02-03T11:08:47+01:00</field>
    <field name='version' major='1' minor='79'>1.79</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>full.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_26560' class='com.jalios.jcms.Member' login='marie-odile'>Marie-Odile Cordier</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1454494127145'>2016-02-03T11:08:47+01:00</field>
    <field name='mdate' time='1462881456183'>2016-05-10T13:57:36+02:00</field>
    <field name='resume' abstract='true'>Marvin Minsky est mort le 24 janvier dernier. Ceux qui connaissent un peu l’histoire de l&apos;intelligence artificielle associent son nom à la création de ce vaste domaine de recherche. </field>
    <field name='imageChapeau'>upload/docs/image/jpeg/2016-02/marvin-minsky750.jpg</field>
    <field name='legendeImageChapeau'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Photo © Massachusetts Institute of Technology (MIT). Source : &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.computerhistory.org/revolution/artificial-intelligence-robotics/13/293/1274&quot; target=&quot;_blank&quot;&gt;Computer History Museum&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</field>
    <field name='soustitre'>
    </field>
    <field name='texte'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;&lt;br /&gt;Marvin Minsky est mort le 24 janvier dernier à Boston d’une hémorragie cérébrale. Né le 9 août 1927, il avait 88 ans. Ceux qui connaissent un peu l’histoire de l&apos;intelligence artificielle (IA) associent son nom à la création de ce vaste domaine de recherche. Il est sans doute utile de rappeler tout d’abord dans quelles circonstances l’IA est née, le rôle que Marvin Minsky y a joué, avant de donner une idée de ses contributions principales, sans pour autant prétendre à l’exhaustivité.&lt;br /&gt;&lt;br /&gt;L’acte de naissance de l’IA correspond à un programme de recherche ayant donné lieu à une série de réunions, entre 10 participants, organisées à Dartmouth College (Hanover, New Hampshire, Etats-Unis) au cours de l’été de 1956. La demande d’obtention d’un soutien financier, écrite l’été précédent, s’intitulait &lt;em&gt;A proposal for the Dartmouth summer research &lt;/em&gt;&lt;em&gt;project on artificial intelligence. &lt;/em&gt;Le nom du nouveau domaine de recherche y fait sans doute sa première apparition. Cette demande était signée par &lt;span class=&quot;lienExterne&quot;&gt;John McCarthy&lt;/span&gt; (1927-2011), à qui on attribue la proposition du terme « &lt;em&gt;Artificial Intelligence&lt;/em&gt; », Marvin Minsky (1927-2016), Nathaniel Rochester (1919-2001) et Claude Shannon (1916-2001). Alors que les deux premiers n’avaient pas encore 30 ans, les deux aînés cautionnaient le projet : Rochester avait conçu l’ordinateur IBM 701 sorti en 1952 pour le calcul scientifique et écrit le premier programme en &lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/Assembleur&quot; target=&quot;_blank&quot;&gt;langage assembleur&lt;/a&gt;, tandis que Claude Shannon avait contribué aux fondements de la &lt;a href=&quot;jcms/c_37274/theories-et-theorie-de-l-information&quot; target=&quot;_self&quot;&gt;théorie de l’information&lt;/a&gt;, après des travaux pionniers sur l’utilisation de l’&lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/Alg%C3%A8bre_de_Boole_%28logique%29&quot; target=&quot;_blank&quot;&gt;algèbre de Boole&lt;/a&gt; pour décrire des machines à relais dans sa thèse de mastère de 1937, et s’intéressait aux principes de base de la programmation du jeu d’échec.&lt;br /&gt;&lt;br /&gt;En plus des quatre signataires du projet figurant sur la demande, il y avait donc six autres participants avec des formations et des préoccupations assez différentes. Parmi eux, deux psychologues, Allen Newell (1927-1992) et le futur prix Nobel d’économie Herbert A. Simon (1916-2001). Ils venaient de proposer, en collaboration avec John Cliff Shaw (1922-1991), un premier programme d’ordinateur, le « &lt;em&gt;Logic Theorist&lt;/em&gt; », capable de démontrer des théorèmes en logique tels que ceux apparaissant dans les &lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/Principia_Mathematica&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;Principia Mathematica&lt;/em&gt;&lt;/a&gt; de Whitehead et Russell. Quant à Oliver Selfridge (1926-2008), il est un des pères de la reconnaissance des formes, à l’origine des idées de filtrage (« &lt;em&gt;pattern matching&lt;/em&gt; ») et de « démon » qui permet d’associer des mécanismes opératoires au processus de filtrage. Arthur Samuel (1901-1990) est un pionnier des programmes de jeux de dames et d’échec, et père de la méthode d’&lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/%C3%89lagage_alpha-b%C3%AAta&quot; target=&quot;_blank&quot;&gt;élagage alpha-bêta&lt;/a&gt;. Enfin, il y avait aussi Ray Solomonoff (1926-2009), pionnier de l’apprentissage probabiliste, et Trenchard More, le plus jeune et maintenant le seul survivant travaillant alors sur les systèmes de déduction logique proches de ceux du logicien Gerhard Gentzen (1909-1945). On voit donc que dès ses débuts, l’IA apparaissait diverse dans ses préoccupations et ses méthodes. Le nom était cependant loin de faire l’unanimité parmi les chercheurs présents, certains ne voyant là que du traitement complexe d’informations...&lt;br /&gt;&lt;br /&gt;Marvin Minsky était donc, avec John McCarthy, l’un des deux jeunes chercheurs à l’initiative de ces rencontres qui, dans des registres différents, allaient ensuite fortement marquer le développement de la discipline : le premier privilégiant l’usage de représentations structurées (‘&lt;em&gt;frames&lt;/em&gt;’ en anglais) de stéréotypes de situations pouvant inclure différents types d’information ; le second défendant une vision purement logique de la représentation des connaissances.&lt;br /&gt;&lt;br /&gt;&lt;img style=&quot;float: right;&quot; title=&quot;perceptrons-1st-300.&quot; src=&quot;upload/docs/image/jpeg/2016-02/perceptrons-1st-300.jpg&quot; alt=&quot;perceptrons-1st-300&quot; width=&quot;250&quot; height=&quot;393&quot; /&gt;Déjà en 1951, inspiré par Warren McCulloch (1898-1969) et Walter Pitts (1923-1969), Marvin Minsky, en équipe avec Dean Edmonds (un jeune diplomé en physique), avait construit le premier réseau de 40 neurones artificiels qui simulait un rat cherchant sa nourriture dans un labyrinthe : le SNARC (« &lt;em&gt;Stochastic Neural Analog Reinforcement Computer&lt;/em&gt; »), avec des synapses capables d’ajuster leur pondération en présence de succès ou d’échecs. Puis il se mit à étudier les perceptrons — le type le plus simple de réseau de neurones formels — inventés en 1957 par Frank Rosenblatt (1928-1971) qu’il connaissait depuis l’adolescence. Marvin Minsky, en collaboration avec le mathématicien Seymour Papert (né en 1928), féru de psychologie et père du langage de programmation Logo, mit alors en évidence des limitations des perceptrons.  Ils mirent entre autres en question la possibilité d’une représentation de certains connecteurs logiques comme le ‘ou exclusif’, ou la capacité de vérifier si une figure labyrinthique, comme celle reproduite sur la couverture du livre &lt;em&gt;«&lt;/em&gt;&lt;em&gt; Perceptrons&lt;/em&gt;&lt;em&gt; »&lt;/em&gt;, est bien connexe. Leurs observations induisirent pour plus d’une décennie une mise à l&apos;écart de l’&lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/Connexionnisme&quot; target=&quot;_blank&quot;&gt;approche connexionniste&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;br /&gt;En 1959, Marvin Minsky et John McCarthy fondèrent le M.I.T. Artificial Intelligence Project qui deviendra plus tard le &lt;a class=&quot;lienExterne&quot; href=&quot;https://www.csail.mit.edu/&quot; target=&quot;_blank&quot;&gt;MIT Computer Science and &lt;span class=&quot;lienExterne&quot;&gt;Artificial Intelligence Laboratory&lt;/span&gt;&lt;/a&gt;. Pour Marvin Minsky, la réalisation d’intelligences artificielles excède les capacités d’une seule forme de modélisation logique ou autre, et requiert l’interaction de multiples unités spécialisées dans des tâches différentes. Sa curiosité débordera souvent des questions classiques de l’IA, il s’intéressera notamment à la mémoire, à la conscience, à l’inconscient, aux émotions. Il argumentera toujours en faveur de l’idée qu’à terme, la machine pourrait supplanter l’intelligence humaine.&lt;/p&gt;&lt;p&gt;&lt;img style=&quot;float: right;&quot; title=&quot;Minsky-Marvin-SocietyofMindCover&quot; src=&quot;upload/docs/image/jpeg/2016-02/minsky-marvin-societyofmindcover.jpg&quot; alt=&quot;Minsky-Marvin-SocietyofMindCover&quot; width=&quot;250&quot; height=&quot;330&quot; /&gt;Tout au long de sa carrière, Marvin Minsky défendra une vision du fonctionnement du cerveau basée sur l’interaction entre une multiplicité d’agents, hiérarchisés, la combinaison des agents de base devant permettre des agencements capables d’opérations complexes. Il développera d&apos;ailleurs cette idée dans son livre &lt;em&gt;« The society of mind »&lt;/em&gt;. Toute son œuvre est marquée par une pensée non conventionnelle, comme pouvait l’être aussi sa manière de s’habiller. Mentionnons aussi son incursion réussie dans le monde de la science-fiction en compagnie de l’écrivain Harry Harrison (1925-2012), avec leur livre &lt;em&gt;«&lt;/em&gt;&lt;em&gt; The Turing option &lt;em&gt;»&lt;/em&gt;&lt;/em&gt;.&lt;br /&gt;&lt;br /&gt;Marvin Minsky recevra de nombreuses distinctions dont le &lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/Prix_Turing&quot; target=&quot;_blank&quot;&gt;prix Turing&lt;/a&gt; en 1969, et l&apos;&lt;span class=&quot;st&quot;&gt;&lt;em&gt;&lt;a class=&quot;lienExterne&quot; href=&quot;http://ijcai.org/&quot; target=&quot;_blank&quot;&gt;IJCAI&lt;/a&gt;&lt;span class=&quot;lienExterne&quot;&gt; Research Excellence Award &lt;/span&gt;&lt;/em&gt;&lt;/span&gt;en 1991. Sa pensée à l’écart des courants dominants du moment, en apparence simple et novatrice, devrait longtemps rester une source d’inspiration pour les recherches en IA et en sciences cognitives. Terminons par deux citations de Marvin Minsky écrites à 40 années d&apos;intervalle, extraites des avant-propos de deux de ses livres, qui montrent la constance de sa pensée toujours tendue dans la même direction :&lt;/p&gt;&lt;p style=&quot;padding-left: 60px; text-align: justify;&quot;&gt;&lt;em&gt;« It would indeed be reassuring to have a book that categorically and systematically described what all these machines can do and what they cannot do, giving sound theoretical or practical grounds for each judgment. However, although some books have purported to do this, it cannot be done for the following reasons : a) Computer-like devices are utterly unlike anything which science has ever considered — we still lack the tools necessary to fully analyze, synthesize, or even think about them ; and b) The methods discovered so far are effective in certain areas, but are developing much too rapidly to allow a useful interpretation and interpolation of results. The abstract theory — as described in this book — tells us in no uncertain terms that the machines’ potential range is enormous, and that its theoretical limitations are of the subtlest and most elusive sort. There is no reason to suppose machines have any limitations not shared by man. »&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;padding-left: 60px; text-align: right;&quot;&gt;(Extrait de &lt;em&gt;Computation : Finite and Infinite Machines&lt;/em&gt;. Prentice Hall, 1967)&lt;/p&gt;&lt;p style=&quot;padding-left: 60px; text-align: justify;&quot;&gt;&lt;em&gt;« So naturally, psychologists tried to imitate physicists — by searching for compact sets of laws to explain what happens inside our brains. However, this book will argue that this quest will fail because no simple such set of laws exists, because every brain has hundreds of parts, each of which evolved to do certain particular kinds of jobs ; some of them recognize situations, others tell muscles to execute actions, others formulate goals and plans, and yet others accumulate and use enormous bodies of knowledge. And though we don’t yet know much about how each of those hundreds of brain-centers works, we do know that their construction is based on information that is contained in tens of thousands of inherited genes — so that each brain-part works in a way that depends on a somewhat different set of laws. »&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;padding-left: 60px; text-align: right;&quot;&gt;(Extrait de &lt;em&gt;The Emotion Machine : Commonsense Thinking, Artificial Intelligence, and the Future of the Human Mind&lt;/em&gt;. Simon &amp;amp; Schuster, 2007)&lt;em&gt;&lt;br /&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Pour en savoir plus, voir l&apos;ensemble des &lt;a class=&quot;lienPlus&quot; href=&quot;javascript:ouvreEncart(1,%20600,%20500%20);&quot;&gt;références citées&lt;/a&gt; dans cet article.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='imagette'>upload/docs/image/jpeg/2016-02/marvin-minsky-imgt.jpg</field>
    <field name='encarts'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Références :&lt;br /&gt;&lt;br /&gt;[1] D. Crevier. The Tumultuous History of the Search for Artificial Intelligence.&lt;br /&gt;Basic Books, Harper Collins Publ., New York, 1993. Trad. française : A la&lt;br /&gt;Recherche de l’Intelligence Artificielle, Champs, Flammarion, 1997.&lt;br /&gt;&lt;br /&gt;[2] H. Harrison and M. Minsky. Le problème de Turing. Trad. de The Turing&lt;br /&gt;Option, 1992 ; préface de G. Klein, Le Livre de Poche, Laffont, 1994.&lt;br /&gt;&lt;br /&gt;[3] J. McCarthy, M. Minsky, N. Rochester, C. E. Shannon. A proposal for the&lt;br /&gt;Dartmouth summer research project on artificial intelligence, August 31,&lt;br /&gt;1955. The AI Magazine, 27 (4), 12-14, 2006.&lt;br /&gt;&lt;br /&gt;[4] M. Minsky. Computation : Finite and Infinite Machines. Prentice Hall, 1967.&lt;br /&gt;&lt;br /&gt;[5] M. Minsky and S. Papert. Perceptrons : An Introduction to Computational&lt;br /&gt;Geometry. The MIT Press, Cambridge, Ma, 1969 (2nd éd. corrigée, 1972, Expanded edition, 1987).&lt;br /&gt;&lt;br /&gt;[6] M. Minsky. A framework for representing knowledge. MIT-AI Laboratory&lt;br /&gt;Memo 306, 120 p., June, 1974. Reprinted in The Psychology of Computer&lt;br /&gt;Vision, (P. Winston, ed.), McGraw-Hill, 1975.&lt;br /&gt;&lt;br /&gt;[7] M. Minsky. Minsky’s frame system theory. Proc. of the 1975 Workshop on&lt;br /&gt;Theoretical Issues in Natural Language Processing (TINLAP ’75), Association&lt;br /&gt;for Computational Linguistics, Cambridge, Ma, 104-116, 1975 (l’article&lt;br /&gt;fut originellement publié sans nom d’auteur, d’où son titre).&lt;br /&gt;&lt;br /&gt;[8] M. Minsky. K-lines. A theory of memory. Cognitive Science, 4 (2), 117-133,&lt;br /&gt;1980.&lt;br /&gt;&lt;br /&gt;[9] M. Minsky. Jokes and the logic of the cognitive unconscious. In : Cognitive&lt;br /&gt;Constraints on Communication, (L. M. Vaina and J. Hintikka, eds.), D.&lt;br /&gt;Reidel, 1981.&lt;br /&gt;&lt;br /&gt;[10] M. Minsky. Why people think computers can’t. AI Magazine, 3 (4) : 3-15,&lt;br /&gt;1982.&lt;br /&gt;&lt;br /&gt;[11] M. Minsky. The Society of Mind. Simon &amp;amp; Schuster, Inc.1986, Trad. J.&lt;br /&gt;Henry, La Société de l’Esprit, Interéditions, Paris, 1988.&lt;br /&gt;&lt;br /&gt;[12] M. Minsky. Logical versus analogical or symbolic versus connectionist or&lt;br /&gt;neat versus scruffy. AI Magazine, 12 (2) : 34-51, 1991.&lt;br /&gt;&lt;br /&gt;[13] M. Minsky, P. Singh, A. Sloman. The St. Thomas Common Sense Symposium&lt;br /&gt;: Designing Architectures for Human-Level Intelligence. AI Magazine&lt;br /&gt;25 (2), 113-124, 2004.&lt;br /&gt;&lt;br /&gt;[14] M. Minsky. The Emotion Machine : Commonsense Thinking, Artificial Intelligence,&lt;br /&gt;and the Future of the Human Mind. Simon &amp;amp; Schuster, 2007.&lt;br /&gt;&lt;br /&gt;[15] J. Moor. The Dartmouth College Artificial Intelligence Conference : The&lt;br /&gt;Next Fifty Years. AI Magazine 27 (4) : 87-91, 2006.&lt;br /&gt;&lt;br /&gt;[16] P. Marquis, O. Papini, H. Prade. Eléments pour une histoire de l’intelligence&lt;br /&gt;artificielle. In : Panorama de l’Intelligence Artificielle. Vol. 1, Représentation&lt;br /&gt;des Connaissances et Formalisation des Raisonnements, (P. Marquis, O. Papini,&lt;br /&gt;H. Prade, eds.), Cépaduès Editions, 1-39, 2014.&lt;br /&gt;&lt;br /&gt;[17] P. Marquis, O. Papini, H. Prade. Quelques éléments pour une préhistoire de&lt;br /&gt;l’intelligence artificielle dans les quatre derniers siècles. Actes des Huitièmes&lt;br /&gt;Journées de l’Intelligence Artificielle Fondamentale (&lt;a class=&quot;lienExterne&quot; href=&quot;http://jiaf2014.univ-angers.fr/&quot; target=&quot;_blank&quot;&gt;IAF’14&lt;/a&gt;), Angers, 11-&lt;br /&gt;13 juin, 148-157, 2014.&lt;br /&gt;&lt;br /&gt;[18] F. Rosenblatt. Principles of Neurodynamics : Perceptrons and the Theory of&lt;br /&gt;Brain Mechanisms. Spartan Books, 1962.&lt;br /&gt;&lt;br /&gt;[19] C. E. Shannon. Programming a computer for playing chess. Pré à la National&lt;br /&gt;Institute of Radio Engineers Convention le 9 Mars 1949, New York,&lt;br /&gt;Philosophical Magazine (7th series), XLI (314), 256-275, 1950.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='auteurs'>
      <item id='p_88916' class='generated.Auteur'>Prade</item>
    </field>
    <field name='moissonnable'>false</field>
    <field name='motsCles'>
    </field>
    <field name='indiceDewey'>
    </field>
    <field name='publicVise'>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89020' url='https://interstices.info/jcms/p_89020/deambulateurabc'>
    <field name='title'>deambulateurabc</field>
    <field name='pdate' time='1455534489545'>2016-02-15T12:08:09+01:00</field>
    <field name='udate' time='1455534489547'>2016-02-15T12:08:09+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1455534489547'>2016-02-15T12:08:09+01:00</field>
    <field name='mdate' time='1455534489547'>2016-02-15T12:08:09+01:00</field>
    <field name='filename' mtime='1455534490000' size='52292' ticket='jND8UrO2CoXaNOPAkp8ByA=='>upload/docs/image/jpeg/2016-02/deambulateurabc.jpg</field>
    <field name='originalFilename'>deambulateurabc.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1455534489547'>2016-02-15T12:08:09+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>245</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>245 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89026' url='https://interstices.info/jcms/p_89026/marionet-assist600'>
    <field name='title'>marionet-assist600</field>
    <field name='pdate' time='1455541904723'>2016-02-15T14:11:44+01:00</field>
    <field name='udate' time='1455541904724'>2016-02-15T14:11:44+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1455541904724'>2016-02-15T14:11:44+01:00</field>
    <field name='mdate' time='1455541904724'>2016-02-15T14:11:44+01:00</field>
    <field name='filename' mtime='1455541905000' size='62276' ticket='upy2GfAbp/34ljxEmAvjeA=='>upload/docs/image/jpeg/2016-02/marionet-assist600.jpg</field>
    <field name='originalFilename'>marionet-assist600.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1455541904724'>2016-02-15T14:11:44+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>365</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>365 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>600 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>600</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89030' url='https://interstices.info/jcms/p_89030/nao460'>
    <field name='title'>nao460</field>
    <field name='pdate' time='1455542964042'>2016-02-15T14:29:24+01:00</field>
    <field name='udate' time='1455542964043'>2016-02-15T14:29:24+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1455542964043'>2016-02-15T14:29:24+01:00</field>
    <field name='mdate' time='1455542964043'>2016-02-15T14:29:24+01:00</field>
    <field name='filename' mtime='1455542965000' size='20522' ticket='pqBriQctDcoMR01n0jB0Vg=='>upload/docs/image/jpeg/2016-02/nao460.jpg</field>
    <field name='originalFilename'>nao460.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1455542964043'>2016-02-15T14:29:24+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>306</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>306 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>460 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>460</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_89089' url='https://interstices.info/jcms/p_89089/personnes-fragiles750'>
    <field name='title'>personnes-fragiles750</field>
    <field name='pdate' time='1455807595796'>2016-02-18T15:59:55+01:00</field>
    <field name='udate' time='1455807595797'>2016-02-18T15:59:55+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1455807595797'>2016-02-18T15:59:55+01:00</field>
    <field name='mdate' time='1455807595797'>2016-02-18T15:59:55+01:00</field>
    <field name='filename' mtime='1455807596000' size='34822' ticket='NJwZoxTOg0PA4kTvmKwwLQ=='>upload/docs/image/jpeg/2016-02/personnes-fragiles750.jpg</field>
    <field name='originalFilename'>personnes-fragiles750.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1455807595797'>2016-02-18T15:59:55+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>300</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>300 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='generated.DocumentInterstices' id='p_88360' url='https://interstices.info/jcms/p_88360/au-service-des-personnes-fragiles'>
    <field name='title'>Au service des personnes fragiles</field>
    <field name='categories'>
      <item id='jalios_5001' class='com.jalios.jcms.Category'>Navigation/Rubriques/Découvrir</item>
      <item id='mf_46782' class='com.jalios.jcms.Category'>Tags/Robot</item>
      <item id='mf_46802' class='com.jalios.jcms.Category'>Tags/Utilisateur</item>
      <item id='i_62034' class='com.jalios.jcms.Category'>CatTemporaire</item>
    </field>
    <field name='pdate' time='1455886800000'>2016-02-19T14:00:00+01:00</field>
    <field name='udate' time='1452696482179'>2016-01-13T15:48:02+01:00</field>
    <field name='version' major='1' minor='46'>1.46</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>full.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1452696482179'>2016-01-13T15:48:02+01:00</field>
    <field name='mdate' time='1462881478575'>2016-05-10T13:57:58+02:00</field>
    <field name='resume' abstract='true'>Les robots seront-ils essentiels à la sauvegarde de l&apos;autonomie des personnes fragiles ? Pour ce faire, un engin humanoïde multitâche serait moins efficace qu&apos;une flottille d&apos;appareils spécifiques travaillant en équipe...</field>
    <field name='chapo'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Les robots seront-ils essentiels à la sauvegarde de l&apos;autonomie des personnes fragiles ? Probablement, mais pour ce faire, un engin humanoïde multitâche serait moins efficace qu&apos;une flottille d&apos;appareils spécifiques travaillant en équipe. Même un robot aspirateur peut jouer un rôle important !&lt;/p&gt;&lt;/div&gt;</field>
    <field name='imageChapeau'>upload/docs/image/jpeg/2016-02/personnes-fragiles750.jpg</field>
    <field name='legendeImageChapeau'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;© Fotolia - Auteur : &lt;a title=&quot;Voir le portfolio de Photographee.eu&quot; href=&quot;https://fr.fotolia.com/p/200793652&quot;&gt;Photographee.eu &lt;/a&gt;/ K. Bialasiewicz&lt;/p&gt;&lt;/div&gt;</field>
    <field name='soustitre'>
    </field>
    <field name='texte'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;&lt;em&gt;&lt;em&gt;Une première version de cet article est parue dans le dossier n°87 &lt;strong&gt; Les robots en quête d&apos;humanité &lt;/strong&gt; de la revue &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.pourlascience.com/index.php&quot; target=&quot;_blank&quot;&gt;Pour la Science&lt;/a&gt;, numéro de avril/juin 2015.&lt;br /&gt;&lt;/em&gt;&lt;/em&gt;&lt;br /&gt;Selon l’INSEE, la France de 2035 comptera 20,9 millions de personnes âgées de plus de 60 ans (soit un tiers de la population totale) contre 12,6 millions en 2005. Cet accroissement, qui correspond à une hausse de 66 % en 30 ans, traduira l’arrivée à ces âges des générations issues du baby-boom, nées entre 1946 et 1975. La France n’est pas un cas isolé. Selon certaines projections, en 2050, les plus de 65 ans représenteront 28 % de la population en Europe (contre 15 % en 2004), 22 % en Amérique du Nord (contre 12 %), 18 % en Asie (contre 7 %)... Une forte majorité de cette population souhaitera — et désire déjà — continuer à vivre dans son domicile, même avec une autonomie diminuée. Comment le lui permettre ?&lt;/p&gt;&lt;h2&gt;De l’usine au foyer&lt;/h2&gt;&lt;p&gt;L’effort public consacré à la compensation des pertes d’autonomie des personnes âgées était estimé en 2008 à près de 21 milliards d’euros. Ce budget ne fera qu’augmenter, ce qui posera certainement des problèmes d’équilibres sociaux. Il convient donc d’examiner comment des aides techniques appropriées pourraient limiter ces dépenses tout en apportant une meilleure sécurité. C’est dans ce contexte d’un mieux vivre que les robots d’assistance entrent en scène pour le bénéfice des personnes âgées ou handicapées, mais aussi, nous le verrons, celui d’autres publics. Examinons d’abord comment les robots sont passés de l’usine à nos foyers.&lt;br /&gt;Jusque dans les années 1990, la robotique se déployait surtout dans le domaine industriel où elle excluait, à de très rares exceptions, l’homme de son champ d’action. L’exemple typique est le robot manipulateur d’une usine, isolé matériellement de tout humain, souvent placé dans un enclos grillagé avec une seule porte dont l’ouverture déclenchait l’arrêt immédiat du robot. Cet isolement se justifiait par la dangerosité de l’engin ou du milieu où il évoluait.&lt;br /&gt;Cet état de fait a changé dans les années 2000 quand la robotique de service est apparue. Qu’est-ce qu’un robot de service ? C’est un robot qui opère de façon autonome, ou semi-autonome, pour fournir des services utiles au bien-être des humains ou au bon fonctionnement d’équipements, en excluant les opérations manufacturières. Cette robotique supprime donc la barrière entre le robot et l’homme. C’est ainsi qu’est apparu le robot médical, certes contrôlé par un humain, mais dont on utilise la grande dextérité, parfois supérieure à celle de l’opérateur, pour intervenir directement sur un autre humain.&lt;/p&gt;&lt;h2&gt;Y’a de la &lt;em&gt;Roomba&lt;/em&gt; dans l’air&lt;/h2&gt;&lt;p&gt;Ce bouleversement se justifie partiellement par l’apparition d’une nouvelle informatique qui a rendu disponibles des ordinateurs de taille réduite, consommant peu d’énergie et que l’on peut facilement associer avec les capteurs et actionneurs des robots. Parallèlement, la diversité de ces derniers a explosé en même temps que les coûts ne cessaient de descendre. Par exemple, un microcontrôleur de type &lt;em&gt;Arduino&lt;/em&gt;, à moins de 30 euros aujourd’hui, permet de contrôler six moteurs et une dizaine de capteurs. L’équivalent aurait coûté plusieurs milliers d’euros dans les années 1990. Reste la mécanique et les actionneurs, mais ils ont une influence relativement marginale sur le coût des robots de faible puissance.&lt;/p&gt;&lt;p&gt;C’est ainsi que l’on a vu apparaître en 2002 une forme de robotique de service avec le premier robot aspirateur &lt;em&gt;Roomba&lt;/em&gt;, de la société &lt;em&gt;IRobot&lt;/em&gt;, qui offre des performances intéressantes à un prix abordable. Le cas d’&lt;em&gt;IRobot&lt;/em&gt; est intéressant, car il est symptomatique de différents aspects de la robotique d’assistance. Cette société était initialement une petite start-up installée à la lisière d’un marché occupé par des géants industriels. En fait, un de ces mastodontes, &lt;em&gt;Electrolux&lt;/em&gt;, avait lui aussi développé un robot aspirateur semblable à celui d’&lt;em&gt;IRobot&lt;/em&gt;. La différence de succès s’est jouée sur les stratégies de vente. &lt;em&gt;IRobot&lt;/em&gt; a choisi un prix de vente directement dérivé du coût de la machine, soit quelques centaines d’euros, alors que son concurrent a estimé que seuls les amateurs de gadgets high-tech allaient acheter le produit et être prêts à débourser plusieurs milliers d’euros. Résultats : &lt;em&gt;Electrolux&lt;/em&gt; a vendu une poignée de ses robots, alors qu’&lt;em&gt;IRobot&lt;/em&gt; en a vendu des millions...&lt;br /&gt;Dès que les coûts du matériel permettent d’envisager des robots bien au-delà du cadre purement industriel, militaire ou de celui des machines d’exception, tels les robots spatiaux, le marché devient colossal. La &lt;em&gt;Japan Robotics Association&lt;/em&gt; a estimé qu’à l’horizon 2025, le marché de la robotique de service pèserait cinq fois plus que la robotique industrielle. Et la robotique d’assistance aux personnes fragiles, en particulier les seniors et les handicapés, pèsera lourd dans cet essor. Cependant, l’offre doit être adaptée.&lt;/p&gt;&lt;p&gt;Pour identifier les besoins ainsi que les lignes directrices qui devaient guider nos développements, nous nous sommes entretenus pendant plus de deux années avec des individus concernés. Nous avons interrogé en premier chef les personnes âgées ou handicapées, mais aussi leurs associations et leurs aidants (famille, infirmière à domicile...), des personnes de maisons de retraite, des médecins, des responsables de collectivités territoriales et des assureurs.&lt;/p&gt;&lt;p&gt;Parmi les priorités qui se sont dégagées, mentionnons l’assistance à la mobilité et la sécurité. Par exemple, un problème crucial est la chute : on estime qu’en France, chaque année, 10 000 personnes âgées meurent des suites directes d’une chute. C’est trois fois plus que le nombre de morts dus aux accidents de la route.&lt;/p&gt;&lt;p&gt;Autres aspects essentiels, les relations sociales et le suivi médical. Les médecins se plaignent de ne pas disposer d’assez d’informations sur l’état de santé de leurs patients alors que leurs trajectoires de vie évoluent rapidement. Un suivi au plus près de la vie quotidienne leur permettrait notamment de détecter plus facilement des pathologies émergentes.&lt;br /&gt;Quant aux lignes directrices, il ressort de nos enquêtes que nous devons proposer des systèmes peu intrusifs, voire invisibles, qui ne se déploient qu’à la demande ou en cas d’urgence. Idéalement, les systèmes seront quasi autonomes et ne nécessiteront aucune intervention de la part du bénéficiaire.&lt;/p&gt;&lt;p&gt;Les systèmes doivent s’adapter à l’utilisateur et à son environnement afin, sauf cas particulier, de ne pas modifier le cadre de vie. Une assistance ne signifie pas une substitution. En d’autres termes, le système doit trouver un compromis entre l’aide apportée et le maintien du niveau d’activité à son maximum. Une aide technique doit faciliter les relations sociales, pas les remplacer.&lt;br /&gt;Les interfaces de contrôle doivent être variées afin de répondre au mieux aux aptitudes physiques et cognitives des utilisateurs et à leur évolution dans le temps. De même, les individus bénéficiaires de l’assistance, ainsi que leur entourage (aidants, médecins...), doivent être mis très tôt dans la boucle de conception du système pour en faciliter l’acceptation.&lt;/p&gt;&lt;p&gt;L’aspect économique est aussi important. Les dispositifs doivent être bon marché, faciles à installer et à entretenir. Ils doivent également être économes en énergie. Enfin, les données recueillies resteront impérativement confidentielles.&lt;/p&gt;&lt;h2&gt;Universel ou spécialisé ?&lt;/h2&gt;&lt;p&gt;Les options pour remplir ce cahier des charges se déclinent en deux extrêmes : un outil universel qui satisfait toutes les contraintes ou bien un ensemble d’aides techniques très spécialisées.&lt;br /&gt;Une partie de la recherche en robotique se concentre sur la première option, celle de l’outil universel, le plus souvent sous la forme d’un robot humanoïde. C’est un sujet d’étude très riche de par la complexité du robot à concevoir. Son physique anthropomorphe laisse imaginer qu’effectivement il sera adapté à la majorité des tâches d’assistance, dont celles liées aux relations sociales : les robots compagnons sont censés exhiber des émotions, comprendre celles des humains et réagir « intelligemment » pour adapter leur comportement. Ces rôles soulèvent la question des &lt;a href=&quot;jcms/ni_79855/des-robots-et-des-humains&quot;&gt;relations de l’homme avec les machines&lt;/a&gt; et de leur acceptation, les mécanismes de celle-ci étant parfois complexes et surprenants. On trouve sur Internet des vêtements et autres gadgets pour des robots aspirateurs (des cylindres plats) qui sont donc considérés bien plus que des machines !&lt;br /&gt;À l’inverse, on observe parfois un rejet immédiat, total et quasi irréversible de la machine. Par ailleurs, on peut se laisser abuser par certaines attitudes du robot : elles semblent très émotionnelles, mais elles sont en fait purement mécaniques et sans intelligence aucune. Les réactions du public lors des représentations de la pièce &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.blancali.com/fr/event/99/robot&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;Robot&lt;/em&gt;&lt;/a&gt; de la danseuse et chorégraphe Blanca Li, où sont utilisés des robots &lt;em&gt;Nao&lt;/em&gt;, suffisent à s’en convaincre.&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;nao460.&quot; src=&quot;upload/docs/image/jpeg/2016-02/nao460.jpg&quot; alt=&quot;nao460&quot; width=&quot;460&quot; height=&quot;306&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Le robot Nao, un humanoïde de 57 cm de hauteur. Une telle machine est-elle la mieux&lt;br /&gt;indiquée pour prêter assistance aux personnes âgées ?&lt;br /&gt;© Inria / Photo H. Raguet&lt;/p&gt;&lt;p style=&quot;text-align: justify;&quot;&gt;Cependant, on peut opposer quelques objections de fond à l’utilisation d’humanoïdes pour l’assistance. D’abord, le prix peut être un frein. Le robot Nao coûte quelque 15 000 euros, cette somme augmentant très vite avec la taille du robot, jusqu’à atteindre plusieurs centaines de milliers d’euros. Qui plus est, on ne peut guère espérer de baisse des prix significative, car ces robots sont élaborés avec des composants standards, produits en masse. Ces prix élevés se justifient par la complexité intrinsèque de l’humanoïde qui nécessite plusieurs dizaines d’actionneurs et de capteurs, ainsi qu’une informatique puissante. La physique est le second élément qui pénalise l’option humanoïde. Nous avons dit qu’une part importante de l’assistance consiste à faciliter la mobilité des personnes âgées. Or les lois de la mécanique indiquent que cette fonction requiert une énergie importante, d’autant plus que le rendement des robots humanoïdes est médiocre. Cette difficulté va de pair avec le problème de l’énergie. Pour l’illustrer, rappelons que Asimo, le célèbre robot de Honda, a une autonomie... d’une vingtaine de minutes ! En ce qui concerne les émotions, le message doit être clair. Dans l’état actuel des technologies, aucun robot n’est doté de la moindre caractéristique d’une intelligence (au sens commun du terme), même très modérée. Ce sont juste des machines qui, dans certains cas, peuvent avoir des performances supérieures à celle de l’homme, mais dont les capacités d’adaptation à une situation nouvelle restent très faibles. À moins d’une révolution fondamentale de l’informatique, la perspective de robots « intelligents » reste très lointaine.&lt;/p&gt;&lt;p style=&quot;text-align: justify;&quot;&gt;Au regard de ces inconvénients, la deuxième option semble plus réaliste. Elle consiste à réunir un ensemble de dispositifs d’aide efficaces dans un nombre limité d’actions et conçus pour collaborer pour des tâches plus complexes. De tels dispositifs existent déjà, mais leur conception souffre de certains manques.&lt;br /&gt;Prenons le cas des colliers de téléalarme : en cas de problème, par exemple une chute, l’individu appuie sur un bouton qui alerte les secours. Dans le principe, ce système est efficace, mais il est rarement demandé par la personne qui le porte. L’instigateur est plutôt la famille qui, avec des intentions louables, transmet tout de même un message très négatif au sujet. En conséquence, le dispositif est rarement porté (volontairement ou non), comme l’atteste le taux de retour du produit au bout d’un an, à savoir 85 %. De plus, on retrouve dans ces systèmes le modèle économique des robots aspirateurs d’&lt;em&gt;Electrolux&lt;/em&gt;. Le prix n’obéit pas au modèle industriel (le coût de revient ici est faible), mais est plutôt indexé sur les capacités de financement des aidants ou des systèmes de sécurité sociale, ce qui conduit souvent à des prix incompatibles avec une diffusion de masse. Toutefois, on peut trouver des systèmes conçus en fonction des priorités et des lignes directrices qui ont été identifiées. Donnons quelques exemples.&lt;/p&gt;&lt;h2&gt;Un déambulateur connecté&lt;/h2&gt;&lt;p&gt;Pour l’aide à la mobilité, une solution souvent préconisée après l’apparition des premiers problèmes de motricité est le déambulateur, un appareil qui est de plus en plus accepté. Nous avons transformé la version classique de cet engin en une aide technique robotisée à fonctions multiples. Pour ce faire, nous avons placé un capteur dans chacune des roues arrière afin d’en mesurer la rotation. Un modèle mathématique aide à reconstituer la trajectoire du déambulateur, donc la marche de son utilisateur. Or les médecins estiment que la marche fournit des indications précieuses sur le statut fonctionnel et cognitif des personnes âgées. Ainsi, par une instrumentation simple, le déambulateur devient un outil de monitoring médical disponible en permanence et fournissant des informations objectives sur l’état de santé du sujet.&lt;/p&gt;&lt;p&gt;Ajoutons maintenant un accéléromètre, un émetteur GSM, une liaison sans fil et un capteur qui repère la présence du sujet derrière le déambulateur. L’accéléromètre détecte les vitesses et les accélérations anormales, typiques d’une chute. Dans un tel cas, quand, en plus, le détecteur de présence ne « voit » plus l’utilisateur, on peut suspecter une chute et émettre une alerte via le GSM et vers les autres aides techniques du voisinage. Un GPS additionnel améliorerait l’alerte en indiquant l’endroit de la chute. Ce GPS aiderait aussi à naviguer dans un environnement inconnu. La prudence s’impose néanmoins, car des études cliniques ont montré que les utilisateurs n’apprécient pas les systèmes de navigation « autoritaires ». De fait, ces équipements peuvent donner le sentiment de dépouiller l’individu de son autonomie de décision.&lt;/p&gt;&lt;p&gt;On peut concevoir la navigation autrement. L’accéléromètre renseigne aussi sur la pente du trottoir où circule l’utilisateur, sur la qualité du revêtement et détecte automatiquement les dépressions des trottoirs (les « bateaux »). Toutes ces informations sont géolocalisées grâce au GPS. Imaginons alors, dans une ville donnée, une flotte de déambulateurs dont les informations sont intégrées dans un système cartographique. Un utilisateur de déambulateur ou de fauteuil roulant ne connaissant pas la ville pourrait obtenir du système un itinéraire adapté à ses particularités, tel que « traverser les rues uniquement à des bateaux » ou « ne pas prendre des trottoirs trop pentus ».&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;deambulateurabc.&quot; src=&quot;upload/docs/image/jpeg/2016-02/deambulateurabc.jpg&quot; alt=&quot;deambulateurabc&quot; width=&quot;750&quot; height=&quot;245&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Le déambulateur ANG (à gauche) a été équipé d&apos;instruments (accéléromètre, émetteur GSM, GPS...) qui permettent de suivre les trajectoires. Par exemple, sur une distance de dix mètres en ligne droite, on se rend compte que celles des sujets âgés (figure de droite, courbes en bleu) oscillent plus que celles des individus jeunes (en rouge). Cet appareil aide aussi à cartographier un territoire, tel le site Inria basé à Sophia-Antipolis (voir schéma au milieu : la pente des trottoirs augmente du vert au rouge ; les points noirs sont les bateaux).&lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;© Inria / Photo C. Tourniaire - © Inria / HEPHAÏSTOS&lt;/p&gt;&lt;p&gt;Ces principes ont été mis en application avec notre déambulateur ANG pour un surcoût modeste (voir la figure ci-dessus). Notons que cet appareil a une autonomie énergétique raisonnable (de l’ordre de quatre jours) et que nous comptons l’étendre en installant des dynamos dans les roues. Ainsi instrumenté, le classique déambulateur devient une aide technique pouvant assurer un support, un monitoring médical et augmenter la sécurité des utilisateurs. Toujours dans le domaine de la mobilité, nous avons réfléchi au problème des déplacements en intérieur. Nous avons placé dans le plafond de notre appartement témoin un robot de type particulier, un robot parallèle à câbles, nommé &lt;em&gt;Marionet-Assist&lt;/em&gt;. Des treuils placés au plafond enroulent ou déroulent quatre câbles reliés à une plate-forme (voir la figure ci-dessous). Grâce à un contrôle approprié des longueurs des câbles, on déplace la plate-forme en n’importe quel point de la pièce. Ce robot peut soulever une personne placée dans un harnais ou bien l’aider à se déplacer quand elle s’accroche à la plate-forme. Le dispositif est discret : inutilisé, il peut disparaître dans le plafond. De plus, la plate-forme est équipée d’accéléromètres qui permettent d’analyser la marche de l’utilisateur. Simple à utiliser, le robot aide les individus les plus atteints à passer seuls de leur lit à leur chaise roulante, ou bien à aller seuls aux toilettes. On améliore ainsi l’autonomie des bénéficiaires en réduisant la fatigue physique du personnel aidant.&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img style=&quot;vertical-align: baseline;&quot; title=&quot;marionet-assist600.&quot; src=&quot;upload/docs/image/jpeg/2016-02/marionet-assist600.jpg&quot; alt=&quot;marionet-assist600&quot; width=&quot;600&quot; height=&quot;365&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot; style=&quot;text-align: center;&quot;&gt;MARIONET-ASSIST, un robot parallèle à câbles, aide à transférer un individu (ici, un mannequin) de son fauteuil à son lit.&lt;br /&gt;© Inria / Photo H. Raguet&lt;/p&gt;&lt;p&gt;Le robot n’est composé que d’éléments standards, ce qui en fait un système bon marché par rapport aux solutions actuelles de rails placés au plafond, autrement plus intrusifs. En outre, nous avons travaillé sur le problème de l’adaptation à l’environnement : où placer les treuils, dont la puissance est limitée, de façon à couvrir au mieux la pièce tout en assurant que l’on pourra soulever intégralement l’individu ? On tient également compte du fait que l’installateur n’est pas un expert et donc qu’il ne s’approchera qu’approximativement de la solution idéale. Ce problème peut se traduire mathématiquement et, avec un outil, l’analyse par intervalles, on peut calculer à partir de la géométrie de la pièce l’ensemble des placements possibles des treuils sous la forme de régions pour chacun. On donne ici à l’installateur une grande flexibilité tout en garantissant les performances voulues.&lt;/p&gt;&lt;h2&gt;Quand la flottille se déploie&lt;/h2&gt;&lt;p&gt;Dès lors, on peut imaginer un scénario réaliste d’une situation d’urgence où des aides techniques connectées réagissent ensemble. L’utilisateur, derrière le déambulateur ANG, se dirige vers la porte, trébuche et tombe. Grâce à ses instruments embarqués, l’appareil détecte une situation anormale sans être sûr qu’il s’agit bien d’une chute. Le déambulateur transmet simplement une alerte à l’ordinateur coordinateur qui demande à un robot aspirateur connecté, muni d’une caméra et téléopérable via le web, de se diriger vers le point où a eu lieu la probable chute. Là, l’engin vérifie avec son système de vision si le sujet est au sol. Quand c’est le cas, le robot &lt;em&gt;Marionet-Assist&lt;/em&gt; vient alors se placer au-dessus de la personne afin de lui apporter son aide. Lorsque c’est insuffisant, le coordinateur alerte le voisinage tout en déverrouillant les accès à l’appartement. Faute de réaction, le coordinateur contacte un centre de secours et passe le contrôle du robot aspirateur au sauveteur qui peut alors échanger avec le sujet à terre.&lt;/p&gt;&lt;p&gt;On peut pousser ce scénario un cran plus loin. Avec sa caméra, le robot aspirateur peut détecter un saignement abondant. Cette information est transmise au coordinateur qui active alors un second robot mobile dont la fonction est d’appliquer une compresse. Ces exemples montrent qu’une flottille d’aides techniques connectées est apte à gérer au mieux une situation compliquée en travaillant de conserve, de façon collaborative, tout en étant peu intrusive dans un mode normal.&lt;/p&gt;&lt;h2&gt;Sur tous les fronts !&lt;/h2&gt;&lt;p&gt;On peut toutefois relever un point faible dans ce scénario : la détection de la chute. Que se passe-t-il quand la personne n’est pas derrière le déambulateur ? Pour combler cette lacune, nous avons développé une veste instrumentée qui assure à la fois la détection de chute et un monitoring médical. L’apparition de nouveaux textiles techniques dotés de capteurs permet d’imaginer des vêtements qui mesureront des paramètres biologiques et détecteront diverses activités, notamment des situations anormales comme la chute.&lt;/p&gt;&lt;p&gt;Dans un tout autre domaine, mentionnons l’utilisation thérapeutique d’un jouet robotique, le phoque &lt;em&gt;Paro&lt;/em&gt;, qui exprime du contentement lorsqu’il est caressé. Placé dans des institutions accueillant des personnes souffrant de dépression ou de démence, ce jouet réduirait sensiblement leur agressivité en donnant aux personnes une motivation collective. Ainsi, la robotique jouera sans doute un rôle dans le bien-être des personnes fragiles et simplifiera par ailleurs la tâche du personnel aidant et de la communauté médicale. Des travaux scientifiques de longue haleine sont encore nécessaires, impliquant aussi les sciences humaines, par exemple pour travailler sur l’apparence et l’acceptation de ces dispositifs. De plus, la science s’intéresse ici à des problèmes de société, un domaine dont la dynamique est souvent très lente. La pénétration des solutions robotiques sera probablement progressive alors même que la technologie et la science pourraient provoquer une rupture.&lt;/p&gt;&lt;p&gt;Ces aides techniques posent aussi des problèmes éthiques. Elles concernent des personnes fragiles, mais souvent à fort pouvoir d’achat, un entourage prêt à faire de gros sacrifices. Ce type de consommateurs éloigne les coûts pratiqués des réalités industrielles. En outre, des dispositifs sont potentiellement très intrusifs quant à la vie privée. D’autres problèmes sont d’ordre légal. En effet, les aides techniques ne seront jamais fiables à 100 %. Qui sera responsable en cas de dysfonctionnement ? L’arsenal juridique est muet à ce sujet. On le voit, l’arrivée des robots d’assistance se prépare sur de multiples fronts !&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;lienPlus&quot; href=&quot;javascript:ouvreEncart(0,%20600,%20500%20)&quot;&gt;Références bibliographiques&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='imagette'>upload/docs/image/jpeg/2016-02/senior-imgt.jpg</field>
    <field name='encarts'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Quelques références bibliographiques :&lt;/p&gt;&lt;ul&gt;&lt;li&gt;T. WANG et al., Walking analysis of young-elderly people by using an intelligent walker ANG, in Robotics and Autonomous Systems, prépublication en ligne, 2014.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;J.-P. MERLET, The forward kinematics of cable-driven parallel robots with sagging cables. in 2nd Int. Conf. on cable-driven parallel robots (CableCon), pp. 3-16, Duisburg, 2014.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;M. CARRICATO et J. P. MERLET, Stability analysis of underconstrained cable-driven parallel robots, in IEEE Trans. on Robotics, vol. 29, pp. 288–296, 2013.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</item>
    </field>
    <field name='auteurs'>
      <item id='c_13361' class='generated.Auteur'>Merlet</item>
    </field>
    <field name='moissonnable'>false</field>
    <field name='motsCles'>
    </field>
    <field name='indiceDewey'>
    </field>
    <field name='publicVise'>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88514' url='https://interstices.info/jcms/p_88514/885-domassist-vlongue-vf-inria-h264-800x450-1mbit'>
    <field name='title'>885 DomAssist vLongue VF-Inria H264 800x450 1Mbit</field>
    <field name='pdate' time='1453304807448'>2016-01-20T16:46:47+01:00</field>
    <field name='udate' time='1453372539536'>2016-01-21T11:35:39+01:00</field>
    <field name='version' major='3' minor='0'>3.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1453304807449'>2016-01-20T16:46:47+01:00</field>
    <field name='mdate' time='1453372539540'>2016-01-21T11:35:39+01:00</field>
    <field name='filename' mtime='1453372540000' size='38353674' ticket='Edfirg7njNPwoMZdMidEAg=='>upload/docs/video/mp4/2016-01/885_domassist_vlongue_vf-inria_h264_800x450_1mbit.mp4</field>
    <field name='originalFilename'>885_DomAssist_vLongue_VF-Inria_H264_800x450_1Mbit.mp4</field>
    <field name='contentType'>video/mp4</field>
    <field name='uploadDate' time='1453372539529'>2016-01-21T11:35:39+01:00</field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88793' url='https://interstices.info/jcms/p_88793/schema1'>
    <field name='title'>schema1</field>
    <field name='pdate' time='1454427140633'>2016-02-02T16:32:20+01:00</field>
    <field name='udate' time='1454427140634'>2016-02-02T16:32:20+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1454427140634'>2016-02-02T16:32:20+01:00</field>
    <field name='mdate' time='1454427140634'>2016-02-02T16:32:20+01:00</field>
    <field name='filename' mtime='1454427141000' size='63423' ticket='ctDKf0UD2eyOQBWogAUIRA=='>upload/docs/image/jpeg/2016-02/schema1.jpg</field>
    <field name='originalFilename'>schema1.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1454427140634'>2016-02-02T16:32:20+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>436</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>436 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88795' url='https://interstices.info/jcms/p_88795/schema3'>
    <field name='title'>schema3</field>
    <field name='pdate' time='1454427140646'>2016-02-02T16:32:20+01:00</field>
    <field name='udate' time='1454427140647'>2016-02-02T16:32:20+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1454427140647'>2016-02-02T16:32:20+01:00</field>
    <field name='mdate' time='1454427140647'>2016-02-02T16:32:20+01:00</field>
    <field name='filename' mtime='1454427141000' size='19702' ticket='fU/qtyuEFS2w8YmgLMo0hg=='>upload/docs/image/jpeg/2016-02/schema3.jpg</field>
    <field name='originalFilename'>schema3.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1454427140647'>2016-02-02T16:32:20+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>503</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>503 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>300 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>300</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88796' url='https://interstices.info/jcms/p_88796/schema4'>
    <field name='title'>schema4</field>
    <field name='pdate' time='1454427140655'>2016-02-02T16:32:20+01:00</field>
    <field name='udate' time='1454427140656'>2016-02-02T16:32:20+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1454427140656'>2016-02-02T16:32:20+01:00</field>
    <field name='mdate' time='1454427140656'>2016-02-02T16:32:20+01:00</field>
    <field name='filename' mtime='1454427141000' size='27966' ticket='b4kH+PCdGEQURC8n5p6JIw=='>upload/docs/image/jpeg/2016-02/schema4.jpg</field>
    <field name='originalFilename'>schema4.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1454427140656'>2016-02-02T16:32:20+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>290</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>290 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>539 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>539</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88797' url='https://interstices.info/jcms/p_88797/schema5'>
    <field name='title'>schema5</field>
    <field name='pdate' time='1454427140660'>2016-02-02T16:32:20+01:00</field>
    <field name='udate' time='1454427140661'>2016-02-02T16:32:20+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1454427140661'>2016-02-02T16:32:20+01:00</field>
    <field name='mdate' time='1454427140661'>2016-02-02T16:32:20+01:00</field>
    <field name='filename' mtime='1454427141000' size='26181' ticket='3mACsUG4//r6Q14igCYrsw=='>upload/docs/image/jpeg/2016-02/schema5.jpg</field>
    <field name='originalFilename'>schema5.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1454427140661'>2016-02-02T16:32:20+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>434</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>434 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>650 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>650</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88798' url='https://interstices.info/jcms/p_88798/schema6'>
    <field name='title'>schema6</field>
    <field name='pdate' time='1454427140668'>2016-02-02T16:32:20+01:00</field>
    <field name='udate' time='1454427140669'>2016-02-02T16:32:20+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1454427140669'>2016-02-02T16:32:20+01:00</field>
    <field name='mdate' time='1454427140669'>2016-02-02T16:32:20+01:00</field>
    <field name='filename' mtime='1454427141000' size='64070' ticket='gjmKsGZKBmr8jEtIKq4MZQ=='>upload/docs/image/jpeg/2016-02/schema6.jpg</field>
    <field name='originalFilename'>schema6.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1454427140669'>2016-02-02T16:32:20+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>574</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>574 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>742 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>742</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88799' url='https://interstices.info/jcms/p_88799/schema7'>
    <field name='title'>schema7</field>
    <field name='pdate' time='1454427151083'>2016-02-02T16:32:31+01:00</field>
    <field name='udate' time='1454427151084'>2016-02-02T16:32:31+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1454427151084'>2016-02-02T16:32:31+01:00</field>
    <field name='mdate' time='1454427151084'>2016-02-02T16:32:31+01:00</field>
    <field name='filename' mtime='1454427152000' size='28602' ticket='cSlpJm0yAJoPg8fRWwBkxw=='>upload/docs/image/jpeg/2016-02/schema7.jpg</field>
    <field name='originalFilename'>schema7.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1454427151084'>2016-02-02T16:32:31+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>364</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>364 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88800' url='https://interstices.info/jcms/p_88800/schema8'>
    <field name='title'>schema8</field>
    <field name='pdate' time='1454427151090'>2016-02-02T16:32:31+01:00</field>
    <field name='udate' time='1454427151091'>2016-02-02T16:32:31+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1454427151091'>2016-02-02T16:32:31+01:00</field>
    <field name='mdate' time='1454427151091'>2016-02-02T16:32:31+01:00</field>
    <field name='filename' mtime='1454427152000' size='36780' ticket='aNnoGAtwzySQctA0G71m5g=='>upload/docs/image/jpeg/2016-02/schema8.jpg</field>
    <field name='originalFilename'>schema8.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1454427151091'>2016-02-02T16:32:31+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>410</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>410 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88801' url='https://interstices.info/jcms/p_88801/schema9'>
    <field name='title'>schema9</field>
    <field name='pdate' time='1454427151096'>2016-02-02T16:32:31+01:00</field>
    <field name='udate' time='1454427151097'>2016-02-02T16:32:31+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1454427151097'>2016-02-02T16:32:31+01:00</field>
    <field name='mdate' time='1454427151097'>2016-02-02T16:32:31+01:00</field>
    <field name='filename' mtime='1454427152000' size='56873' ticket='SRxqmzIuAmYd7A6gs4X1Kg=='>upload/docs/image/jpeg/2016-02/schema9.jpg</field>
    <field name='originalFilename'>schema9.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1454427151097'>2016-02-02T16:32:31+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>536</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>536 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88880' url='https://interstices.info/jcms/p_88880/appart'>
    <field name='title'>appart</field>
    <field name='pdate' time='1454938872607'>2016-02-08T14:41:12+01:00</field>
    <field name='udate' time='1454938872609'>2016-02-08T14:41:12+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1454938872609'>2016-02-08T14:41:12+01:00</field>
    <field name='mdate' time='1454938872609'>2016-02-08T14:41:12+01:00</field>
    <field name='filename' mtime='1454938873000' size='41212' ticket='rrADsdyHwu7NuNz7bUqTOQ=='>upload/docs/image/jpeg/2016-02/appart.jpg</field>
    <field name='originalFilename'>appart.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1454938872609'>2016-02-08T14:41:12+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>590</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>590 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>700 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>700</value>
      </entry>
    </field>
  </data>
  <data class='generated.DocumentInterstices' id='p_82365' url='https://interstices.info/jcms/p_82365/une-assistance-numerique-pour-les-personnes-agees-le-projet-domassist'>
    <field name='title'>Une assistance numérique pour les personnes âgées : le projet DomAssist</field>
    <field name='categories'>
      <item id='jalios_5000' class='com.jalios.jcms.Category'>Navigation/Rubriques/De la recherche</item>
      <item id='mf_46790' class='com.jalios.jcms.Category'>Tags/Technologie</item>
      <item id='mf_46802' class='com.jalios.jcms.Category'>Tags/Utilisateur</item>
      <item id='new_47665' class='com.jalios.jcms.Category'>Navigation/Médias/Vidéos</item>
      <item id='i_62034' class='com.jalios.jcms.Category'>CatTemporaire</item>
      <item id='p_89678' class='com.jalios.jcms.Category'>Navigation/Spécial/Optimalité : choix, contraintes, hasard (TIPE 2016-2017)</item>
    </field>
    <field name='pdate' time='1455703200000'>2016-02-17T11:00:00+01:00</field>
    <field name='udate' time='1424705810432'>2015-02-23T16:36:50+01:00</field>
    <field name='version' major='1' minor='67'>1.67</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>full.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='n_52355' class='com.jalios.jcms.Member' login='jocelyne'>Jocelyne Erhel</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1424705810432'>2015-02-23T16:36:50+01:00</field>
    <field name='mdate' time='1462881503544'>2016-05-10T13:58:23+02:00</field>
    <field name='resume' abstract='true'>Apporter une aide numérique pour maintenir à domicile les personnes âgées en perte d’autonomie et accompagner leurs aidants : c’est l’objectif de la plateforme DomAssist.</field>
    <field name='chapo'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Apporter une aide numérique pour maintenir à domicile les personnes âgées en perte d’autonomie et accompagner leurs aidants : c’est l’objectif de la plateforme DomAssist.&lt;/p&gt;&lt;/div&gt;</field>
    <field name='texte'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;h2&gt;&lt;video width=&quot;800&quot; height=&quot;450&quot; src=&quot;upload/docs/video/mp4/2016-01/885_domassist_vlongue_vf-inria_h264_800x450_1mbit.mp4&quot; preload=&quot;auto&quot; controls=&quot;controls&quot;&gt;&lt;object width=&quot;800&quot; height=&quot;450&quot; data=&quot;js/tiny_mce/plugins/media/moxieplayer.swf&quot; type=&quot;application/x-shockwave-flash&quot;&gt;&lt;param name=&quot;src&quot; value=&quot;js/tiny_mce/plugins/media/moxieplayer.swf&quot; /&gt;&lt;param name=&quot;flashvars&quot; value=&quot;url=/upload/docs/video/mp4/2016-01/885_domassist_vlongue_vf-inria_h264_800x450_1mbit.mp4&amp;amp;poster=/&quot; /&gt;&lt;param name=&quot;WMode&quot; value=&quot;opaque&quot; /&gt;&lt;param name=&quot;allowfullscreen&quot; value=&quot;true&quot; /&gt;&lt;param name=&quot;allowscriptaccess&quot; value=&quot;true&quot; /&gt;&lt;/object&gt;&lt;/video&gt;&lt;/h2&gt;&lt;p class=&quot;legende&quot;&gt;DomAssist : L&apos;assistance numérique à la personne - Réalisation : Pierre-Olivier Gaumin - Durée 5 min 28.&lt;/p&gt;&lt;h2&gt;Enjeux sociétaux&lt;/h2&gt;&lt;p&gt;Le vieillissement démographique et ses enjeux sociétaux sont connus et largement argumentés aujourd’hui. En particulier, concernant la perte d’autonomie, les projections sociodémographiques prévoient d’ici 2040 en France presque 2 millions de personnes âgées dépendantes au lieu des 1 million actuelles. Si ces projections reflètent une augmentation de la longévité due notamment aux progrès de la médecine, elles obligent à repenser les capacités d’accueil en établissement spécialisé ou à réinventer les conditions de maintien à domicile des personnes âgées. La première solution étant financièrement hors d’atteinte pour les pouvoirs publics, la deuxième solution est donc considérée comme la voie à privilégier pour l’avenir. Cependant, vieillir au domicile peut être compromis du fait d’une part, des pertes d’autonomie associées au vieillissement  et d’autre part, de la charge des aidants, notamment les risques psychosociaux encourus par l’entourage ou les professionnels beaucoup trop ou mal sollicités dans leurs missions d’accompagnement de la personne âgée en perte d’autonomie. Dans ce contexte, les gérontechnologies sont attendues comme des solutions prometteuses de support au prolongement du maintien à domicile des personnes âgées, mêmes dépendantes, voire comme le terreau fertile d’une nouvelle économie appelée la &lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/Silver_%C3%A9conomie&quot; target=&quot;_blank&quot;&gt;Silver Economie&lt;/a&gt;. Les technologies numériques ont le potentiel d’améliorer la vie quotidienne des personnes âgées et de leur famille dans de nombreux domaines, tels que la santé, la mobilité, les activités domestiques, ou encore la communication et les activités de loisirs. Cependant, comme en témoignent les études sur les usages des technologies, il reste encore un long chemin à parcourir pour que les gérontechnologies soient réellement accessibles et adoptées par les personnes âgées.&lt;/p&gt;&lt;h2&gt;Enjeux scientifiques&lt;/h2&gt;&lt;p&gt;Les enjeux scientifiques liés à ces nouvelles technologies pour l’assistance sont nombreux. Ils concernent principalement quatre grands domaines.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;em&gt;Les sciences du numérique&lt;/em&gt;. Les enjeux liés aux technologies de l’informatique ubiquitaire, sensibles au profil de la personne, à ses activités et à leur contexte, lancent des défis loin d’être résolus, qui relèvent de la &lt;a href=&quot;jcms/ni_79380/la-securite-des-systemes-informatiques-ubiquitaires&quot;&gt;fiabilité des systèmes&lt;/a&gt;, de leur certification, et du respect de la vie privée des personnes.&lt;/li&gt;&lt;li&gt;&lt;em&gt;La santé&lt;/em&gt;. Les enjeux liés à la &lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/Rem%C3%A9diation&quot; target=&quot;_blank&quot;&gt;remédiation&lt;/a&gt; et la réhabilitation sont importants. Par exemple, comment les systèmes d’assistance peuvent-ils soutenir l’autonomie des personnes et améliorer leur santé tout en respectant leur liberté d’agir et d’autodétermination ?&lt;/li&gt;&lt;li&gt;&lt;em&gt;L’ergonomie et les facteurs humains.&lt;/em&gt; Les enjeux sont à l’interface des deux domaines précédents. Une analyse et une prise en compte exacte des besoins et des attentes des personnes sont nécessaires pour rendre efficaces les systèmes, mais aussi les rendre accessibles et acceptables à un public peu technophile, pour une adoption à long terme.&lt;/li&gt;&lt;li&gt;&lt;em&gt;Le transfert technologique&lt;/em&gt;. Une réelle efficacité des systèmes au niveau de la société ne sera observée que si le passage à l’échelle de ces technologies est possible. Un transfert technologique nécessite par ailleurs de faire émerger de nouveaux écosystèmes de l’assistance et de nouveaux métiers alliant accompagnement humain et accompagnement technologique.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;C’est dans ce contexte que le &lt;a class=&quot;lienPlus&quot; href=&quot;javascript:ouvreEncart(1,%20600,%20500%20);&quot;&gt;projet de recherche DomAssist&lt;/a&gt; a vu le jour. Son originalité est d’associer des compétences scientifiques et professionnelles multi-domaines, en accord avec les enjeux scientifiques décrits ci-dessus, afin d’élaborer un assistant dédié aux besoins spécifiques des personnes âgées au domicile.&lt;/p&gt;&lt;h2&gt;Objectif et méthode&lt;/h2&gt;&lt;p&gt;Ce projet vise à concevoir et à valider l’efficacité d’une technologie d’assistance domiciliaire, appelée DomAssist. Celle-ci doit être accessible au plus grand nombre, que ce soit en termes de coût financier, de localisation rurale ou urbaine, de type de logement, ou encore d’aptitudes technologiques.&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;schema1.&quot; src=&quot;upload/docs/image/jpeg/2016-02/schema1.jpg&quot; alt=&quot;schema1&quot; width=&quot;750&quot; height=&quot;436&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Étapes du projet DomAssist.&lt;/p&gt;&lt;p&gt;La conception de la technologie DomAssist repose sur une démarche centrée utilisateur, c’est-à-dire dirigée par les besoins des futurs utilisateurs, les personnes âgées, et de leur entourage social, un aidant formel et un aidant familial. Cette démarche comprend les quatre étapes suivantes :&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;em&gt;Étape 1 : &lt;/em&gt;&lt;em&gt;Analyse des besoins&lt;/em&gt; dans les domaines sensibles aux effets du vieillissement (activités quotidiennes, sécurité de la personne et du domicile, lien social) et diagnostic des capacités en présence (aptitudes cognitives, physiques, technologiques, etc.) ;&lt;/li&gt;&lt;li&gt;&lt;em&gt;Étape 2&lt;/em&gt;&lt;em&gt; : Rédaction d’un cahier des charges&lt;/em&gt;. Identification des objectifs désirés et des stratégies compensatoires ou d’assistance à mettre en œuvre, inspirées directement des recherches cliniques ;&lt;/li&gt;&lt;li&gt;&lt;em&gt;Étape 3&lt;/em&gt;&lt;em&gt; : Développement des applications d’assistance&lt;/em&gt;. Un catalogue d’applications personnalisables selon les profils des utilisateurs (en fonction de leur niveau d’autonomie) et les besoins relatifs aux missions des aidants. Ce catalogue contient un ensemble d’applications accessibles, dans l’esprit des « Stores » dédiés aux smartphones. Il est alimenté par un atelier de création d’applications qui permet de développer rapidement des services d’assistance sans limitation &lt;em&gt;a priori&lt;/em&gt; de leur nombre. Le développement logiciel est conforme aux normes ergonomiques d’accessibilité propres aux personnes âgées et à l’évaluation de la technologie auprès d’utilisateurs âgés grâce à des mesures d’acceptabilité et d’utilisabilité ;&lt;/li&gt;&lt;li&gt;&lt;em&gt;Étape 4 : Évaluation des bénéfices &lt;/em&gt;pour la personne, son entourage et la société selon des critères de réussite préalablement définis (nombre de jours d’hospitalisation, bien-être et autonomie de la personne et de ses aidants, etc.).&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Technologie DomAssist&lt;/h2&gt;&lt;p&gt;La  plateforme DomAssist assure l’orchestration logicielle d’objets communicants placés au domicile de la personne. Ces objets matériels et logiciels comprennent :&lt;/p&gt;&lt;ol&gt;&lt;li&gt;des capteurs-actionneurs sans fil disponibles en grande surface à bas coût (détecteur de mouvement, de contact, contrôleur de prise électrique, etc.)&lt;/li&gt;&lt;li&gt;des services logiciels (agenda partagé, ressources Internet)&lt;/li&gt;&lt;li&gt;deux tablettes numériques tactiles.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt; La première tablette, stationnaire, est placée à un endroit central de la maison, pour servir soit de tableau de bord où l’utilisateur recevra les services d’assistance en cas de besoin détecté par le système, soit de cadre numérique de partage de photos avec l’entourage proche. La seconde tablette, mobile, sert aux activités sociales et de loisir de la personne.&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;appart.&quot; src=&quot;upload/docs/image/jpeg/2016-02/appart.jpg&quot; alt=&quot;appart&quot; width=&quot;700&quot; height=&quot;590&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Exemple de déploiement des objets connectés au domicile d&apos;un participant.&lt;/p&gt;&lt;p&gt;L’analyse des besoins pour la vie domiciliaire autonome recueillis auprès de 525 personnes âgées vivant au domicile ainsi que l’étude des besoins exprimés en termes de technologies d’assistance désirées par 100 personnes âgées et aidants, conduites lors de la première étape du projet, ont permis de définir le périmètre à couvrir par les assistances de la technologie DomAssist. Ainsi, DomAssist propose des services d&apos;assistance dans trois grands domaines :&lt;/p&gt;&lt;ul&gt;&lt;li&gt;les &lt;strong&gt;activités quotidiennes&lt;/strong&gt; avec une surveillance de la réalisation d’activités (prise de repas, toilette, habillage, lever-coucher, etc.), un rappel de rendez-vous et un bilan personnalisé des activités réalisées dans la journée ;&lt;/li&gt;&lt;li&gt;la &lt;strong&gt;sécurité&lt;/strong&gt; de la personne et de son domicile avec, par exemple, la disposition d’un chemin lumineux, d’une surveillance de la cuisinière, et une alerte à un aidant en cas de situation inhabituelle ou préoccupante ;&lt;/li&gt;&lt;li&gt;la &lt;strong&gt;participation sociale&lt;/strong&gt; à travers les activités de communication et de loisirs, en proposant un service simplifié de courriels, une application d’appel en visio-conférence et des applications de loisirs personnalisés en fonction des préférences des utilisateurs (applications de cuisine, bibliothèque multimédia, jeux solitaires ou collaboratifs, etc.).&lt;ins cite=&quot;mailto:Charles%20Consel&quot; datetime=&quot;2015-10-26T15:49&quot;&gt;&lt;/ins&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Les applications d’assistance sont toutes conçues selon une approche centrée utilisateur et prennent en compte les spécificités de chaque personne, ses capacités, ses besoins, ses attentes.&lt;/p&gt;&lt;p&gt;Par exemple, certaines des applications sont basées sur les activités que la personne réalise tout au long de la journée à son domicile. Dans le cadre de l’assistance pour le prolongement de la vie au domicile, il est important de pouvoir surveiller ces activités, car il s&apos;agit d&apos;aptitudes qui reflètent le statut fonctionnel d’un individu. Vérifier que ces activités sont effectivement réalisées est notamment un facteur décisif pour déterminer le type et le niveau d’assistance dont la personne a besoin.&lt;/p&gt;&lt;p&gt;&lt;img style=&quot;float: left;&quot; title=&quot;schema3.&quot; src=&quot;upload/docs/image/jpeg/2016-02/schema3.jpg&quot; alt=&quot;schema3&quot; width=&quot;173&quot; height=&quot;290&quot; /&gt;&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;schema4.&quot; src=&quot;upload/docs/image/jpeg/2016-02/schema4.jpg&quot; alt=&quot;schema4&quot; width=&quot;539&quot; height=&quot;290&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Exemples d&apos;applications proposées pour l&apos;aide au maintien à domicile des personnes âgées.&lt;/p&gt;&lt;p&gt;Dans cette optique, nous avons développé et validé expérimentalement une approche originale intégrant les savoirs acquis sur le fonctionnement quotidien de la personne âgée et les technologies ubiquitaires à base de capteurs visant la reconnaissance d’activités. Précisément, notre approche s’appuie sur le fait qu’avec la sénescence, plus une personne subit des pertes associées au vieillissement, plus ses activités de la vie quotidienne deviennent routinières afin d’optimiser son fonctionnement quotidien. Par conséquent, ses activités n’ont pas besoin d’être reconnues de manière exacte ou inférées (comme dans les approches classiques de détection du signal dites « dirigées par les données »), mais peuvent être vérifiées de manière approximative en termes de conformité avec la routine déclarée par l’individu (approches dites « dirigées par les connaissances sur les utilisateurs »). Nous avons pu démontrer que notre approche automatique de vérification d’activités était aussi fiable que celle exécutée par un ergonome.&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;schema5.&quot; src=&quot;upload/docs/image/jpeg/2016-02/schema5.jpg&quot; alt=&quot;schema5&quot; width=&quot;650&quot; height=&quot;434&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Détections des activités « petit-déjeuner », « toilette », « habillage » pour un participant sur une période de 5 jours.&lt;/p&gt;&lt;p&gt;La figure ci-dessus illustre la détection des activités quotidiennes d’un participant sur une période de 5 jours.  Sur ce graphique, nous pouvons observer que la détection des activités de petit-déjeuner et de toilette sont optimales, mais que l’activité d’habillage est détectée de manière moins précise. Cet effet peut être expliqué par le nombre de capteurs utilisés. En effet, la reconnaissance des activités de petit-déjeuner et de toilette est dépendante de 2 capteurs ou plus, alors que l’activité d&apos;habillage n’est liée qu’à un seul capteur de contact posé sur la porte du dressing ou de l&apos;armoire.&lt;/p&gt;&lt;p&gt;&lt;br /&gt;Les déviations d’activité peuvent alors être interprétées comme des signaux d’alerte de dégradation fonctionnelle de la personne, qui peuvent être notifiés à la personne assistée ou envoyés à l’aidant.&lt;/p&gt;&lt;h2&gt;Évaluation expérimentale de DomAssist&lt;/h2&gt;&lt;p&gt;Pour mesurer la valeur ajoutée de la technologie DomAssist, une méthodologie d’évaluation a été mise en place auprès de 48 participants âgés de plus de 80 ans et globalement cognitivement préservés, c&apos;est-à-dire avec un score à l&apos;évaluation &lt;a class=&quot;lienDef&quot; href=&quot;jcms/p_88865/mmse&quot; target=&quot;_blank&quot;&gt;MMSE&lt;/a&gt; supérieur à 24. &lt;a title=&quot;&quot; name=&quot;_ftnref1&quot; href=&quot;#_ftn1&quot;&gt;&lt;/a&gt;Afin d’obtenir des résultats généralisables au plus grand nombre et d’asseoir l’accessibilité du système DomAssist, les 48 personnes ont été sélectionnées selon les critères suivants : lieu de résidence sur trois secteurs girondins (urbain, semi-urbain et rural) et un niveau léger à modéré de perte d’autonomie (score &lt;a class=&quot;lienDef&quot; href=&quot;jcms/p_88866/gir&quot; target=&quot;_blank&quot;&gt;GIR&lt;/a&gt; entre 6 et 4). Pour l’essentiel, la méthodologie adoptée compare sur une période de 9 mois 24 personnes utilisant la technologie à 24 autres en « situation courante » (qui n’utilisent pas DomAssist). Des &lt;a class=&quot;lienPlus&quot; href=&quot;javascript:ouvreEncart(2,%20600,%20500%20);&quot;&gt;règles d&apos;éthique&lt;/a&gt; ont été définies, en particulier concernant les données personnelles.&lt;/p&gt;&lt;p&gt;Les critères de réussite du projet sont les gains apportés par DomAssist à 6 et 9 mois d’utilisation, en termes de bien-être et de santé (psychologique, nutritionnelle, hygiène de sommeil, etc.), ainsi que de fonctionnement quotidien (autonomie domiciliaire, activités sociales, sentiment de sécurité). De plus, des mesures évaluant l’acceptabilité et l’utilisabilité de la technologie sont également récoltées durant l’étude. Les données recueillies sont issues de mesures subjectives, qui mesurent le ressenti des personnes face à la technologie au travers d&apos;entretiens et de questionnaires, mais aussi de mesures objectives sur les utilisations et les interactions effectives avec la technologie.&lt;/p&gt;&lt;p&gt;Cette étude a pris fin en décembre 2015. Elle a déjà donné lieu à des résultats démontrant l’utilité, l’utilisabilité et l’acceptabilité de DomAssist ainsi que les bénéfices en termes d’autonomie domiciliaire et de santé. Les données de 15 participants équipés depuis plus de 6 mois ont déjà fait l’objet d’une analyse complète. Ces participants, 12 femmes et 3 hommes, veufs en majorité, ont en moyenne 81 ans, un score de 28 au MMSE et un score GIR allant de 6 à 4.&lt;/p&gt;&lt;h2&gt;Utilisabilité et acceptabilité de la plateforme&lt;/h2&gt;&lt;p&gt;Les données concernant l’acceptabilité et l’utilisabilité de la technologie sont collectées périodiquement au cours de l’expérimentation. De là, nous avons pu étayer qu’un système d’assistance basé sur des interactions simples multimodales (c&apos;est-à-dire visuelles et auditives), rendant l’apprentissage facilité pour les personnes âgées, était bien compris et rapidement appris.&lt;/p&gt;&lt;p&gt;Nous avons construit un système de notification d’assistance dispensé par la tablette stationnaire. En situation habituelle, cette tablette sert le lien social via ses fonctions de cadre numérique partagé avec la famille. En cas de détection d’une situation anormale ou non désirée (selon les déclarations de l’utilisateur), des notifications d’assistance lui sont délivrées. Ces notifications reposent sur une distinction simple entre « événement critique » et  « événement non critique » quel que soit le domaine de besoins (activités quotidiennes, lien social, sécurité). La criticité de l’événement est déterminée selon la conséquence de la situation ou de la défaillance de l’utilisateur. Une alerte critique est associée à une sonnerie continue qui ne peut être ignorée (de nature aigüe et de volume élevé), à un cadre d’affichage spécifique (carré et orange) et à un maintien continu du message d’assistance jusqu’à ce que l’utilisateur interagisse avec le système et réagisse face à cette situation critique. À l&apos;inverse, les notifications non critiques sont associées à une sonnerie brève et discrète, à un cadre d’affichage spécifique très différent (rond et vert) et à un maintien temporaire du message (quelques minutes, selon les préférences de l’utilisateur). Le contenu de ce message pourra être consulté librement par un clic sur le bouton d’alerte situé en haut à droite du cadre numérique, qui active la liste des notifications et leur contenu.&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;schema6.&quot; src=&quot;upload/docs/image/jpeg/2016-02/schema6.jpg&quot; alt=&quot;schema6&quot; width=&quot;742&quot; height=&quot;574&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Captures d&apos;écran de la tablette stationnaire d&apos;assistance au domicile.&lt;/p&gt;&lt;p&gt;Ce système de notification est testé par des scénarios d’usage dans les trois domaines (activités quotidiennes, lien social et sécurité) induisant des notifications critiques et non-critiques, et ceci tous les mois et demi sur 6 mois.&lt;/p&gt;&lt;p&gt;La performance de la personne âgée est cotée en termes d’efficacité (exécution du comportement attendu et réussite de l’échange avec le système allant de 0 à 3) et d’efficience (rapidité d’exécution du comportement attendu chronométrée en secondes). Les résultats de cette étude révèlent qu&apos;en début d’utilisation du système, les utilisateurs âgés ont des comportements moins efficaces et plus lents pour les notifications critiques comparées aux notifications non critiques. Ces résultats peuvent être expliqués par le fait qu’une notification critique (par exemple, la porte est ouverte sans surveillance) nécessite de réaliser une action (ici, aller fermer la porte), alors qu’une notification non-critique (par exemple, le rappel d’un rendez-vous) affiche uniquement une information qui ne nécessite pas une action. Cependant, on peut observer que l’efficacité devient maximale à partir de 4 mois et demi, quelle que soit la criticité du message. Ainsi, les participants utilisent les services efficacement dès le début, jusqu’à atteindre une utilisation experte (réponse quasi–automatique et sans erreur) à 4 mois et demi, quel que soit le type de notification. Notons que la différence d’efficacité de départ (selon la criticité de la notification) atteste de la bonne distinction par l’utilisateur des notifications critiques et non-critiques.&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;schema7.&quot; src=&quot;upload/docs/image/jpeg/2016-02/schema7.jpg&quot; alt=&quot;schema7&quot; width=&quot;750&quot; height=&quot;364&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Moyenne, sur les 15 participants étudiés, des scores d&apos;utilisabilité et de rapidité d&apos;apprentissage des comportements d&apos;interaction avec le système d&apos;assistance.&lt;/p&gt;&lt;p&gt;Par ailleurs, tous les mois et demi, un questionnaire évaluant l’expérience utilisateur globale et dimensionnelle (ergonomie, plaisir d’utilisation, attrait, sécurité et valorisation sociale) était renseigné par les participants. Les résultats ont montré que l’acceptabilité globale de DomAssist, la qualité ergonomique et le sentiment de sécurité sont d’entrée positifs et augmentent au cours du temps pour la plupart des participants. En effet, 93,3 % ont jugé de manière positive la qualité ergonomique de la solution et ont aussi perçu  les services comme utiles, plaisants, attrayants, non stigmatisants socialement (voire valorisants) et renforçant leur sentiment de sécurité (100 %).&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;schema8.&quot; src=&quot;upload/docs/image/jpeg/2016-02/schema8.jpg&quot; alt=&quot;schema8&quot; width=&quot;750&quot; height=&quot;410&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Moyenne, sur les 15 participants étudiés, des scores d&apos;acceptabilité globale et de l&apos;expérience utilisateur sur 5 dimensions du système (ergonomie, plaisir, attrait, sécurité et valorisation sociale). Le questionnaire proposait pour chaque dimension, 6 items constitués de 2 mots antonymes, par exemple : « Utiliser la technologie DomAssist vous rend : nerveuse – détendue », cotés de -3 (totalement nerveuse) à 3 (totalement détendue). Le score pour chaque dimension correspond à la moyenne des différents items.&lt;/p&gt;&lt;p&gt;Nous avons étudié les liens entre les mesures d’acceptabilité du système et certaines caractéristiques physiques et cognitives des utilisateurs âgés, à l’aide d’outils cliniques standards (échelles évaluant le fonctionnement cognitif, échelle évaluant les capacités physiques comme par exemple la mobilité ou les capacités perceptives). Nos résultats ont montré une relation entre l’acceptabilité du système, le déclin cognitif et les capacités physiques des personnes : une plus grande acceptabilité est observée quand les utilisateurs ont un déclin cognitif et des capacités physiques moyennes, validant ainsi le système pour les personnes âgées avec déclin cognitif.&lt;/p&gt;&lt;h2&gt;Efficacité de la plateforme&lt;/h2&gt;&lt;p&gt;L’analyse des premières données (collectées pour les 15 participants cités plus haut) est très prometteuse en ce qui concerne l&apos;efficacité. Elle conforte l’idée que DomAssist est efficace pour soutenir l’autonomie domiciliaire et améliorer le bien-être à domicile des personnes âgées. Aussi, comparés au groupe de contrôle non équipé de la solution, les participants équipés perçoivent comme significativement augmentées leur autonomie quotidienne, leurs capacités à s’adapter et à contrôler leur environnement.&lt;/p&gt;&lt;p&gt;À titre d’illustration, nous nous sommes intéressés au sentiment d’autodétermination des participants, c’est-à-dire à la perception qu’a un individu de sa capacité à faire des choix et prendre des décisions dans sa vie en conformité avec ses propres aspirations. Peu exploré dans le domaine des gérontechnologies, ce sentiment est bien connu en psychologie du vieillissement et renvoie à une théorie portant sur les processus motivationnels d’un individu à se déterminer librement : plus ce sentiment est élevé chez la personne âgée plus sa santé et son bien-être sont de qualité. &lt;br /&gt;&lt;br /&gt;Ce sentiment est renforcé chez la personne lorsqu’elle réussit à mener des actions autodéterminées, c’est-à-dire des actions servant aux 4 dimensions de l’autodétermination :&lt;/p&gt;&lt;ol&gt;&lt;li&gt;l’autonomie comportementale (la personne mène des activités choisies selon ses préférences, intérêts et capacités) ;&lt;/li&gt;&lt;li&gt;l’autoréalisation (la personne connaît ses forces et ses faiblesses et agit en conséquence) ;&lt;/li&gt;&lt;li&gt;l’autorégulation (la personne choisit ses propres ajustements ou moyens de compensation pour faire face aux évènements de vie, afin de conserver sa capacité à anticiper l’avenir) ; &lt;/li&gt;&lt;li&gt;la capacitation psychologique (la personne est confiante en son pouvoir d’agir et de contrôler son environnement).  &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Si la solution DomAssist est efficace à soutenir l’autonomie de la personne et respecte ses stratégies pour faire face aux difficultés de son quotidien, alors le sentiment d’autodétermination dans ses quatre dimensions, comme témoin de l’amélioration de sa santé et de son bien-être, devrait progresser avec l’utilisation de DomAssist.&lt;/p&gt;&lt;p&gt;Nous avons  évalué à l’aide d’une échelle spécifique l’évolution à 6 mois des 4 dimensions d’autodétermination de nos participants équipés comparés aux participants du groupe de contrôle (non-équipés de DomAssist). Les résultats sont unanimes : les participants équipés présentent tous des améliorations sur les 4 dimensions de l’autodétermination, en particulier pour l’autonomie comportementale, l’autorégulation, et la capacitation psychologique. En d’autres termes, les personnes âgées bénéficiant de DomAssist présentent une autodétermination augmentée grâce au soutien de leur autonomie dans les activités quotidiennes, au respect de leurs stratégies d’adaptation à la vie domiciliaire et au renforcement de leur sentiment de contrôle sur leur environnement.&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;schema9.&quot; src=&quot;upload/docs/image/jpeg/2016-02/schema9.jpg&quot; alt=&quot;schema9&quot; width=&quot;750&quot; height=&quot;536&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Impact de DomAssist sur l’autodétermination des personnes âgées : scores moyens sur les 15 participants équipés et 15 participants contrôles à 0 et 6 mois d’expérimentation. L&apos;échelle est cotée pour chaque dimension sous la forme de pourcentages par rapport au score maximum, un pourcentage élevé étant le reflet d’une perception élevée par le participant de son autodétermination.&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Les premiers résultats montrent globalement la bonne acceptabilité de DomAssist chez les participants, l’efficacité des participants à utiliser la technologie installée à leur domicile, ainsi que la facilité d’apprentissage de l’interaction avec la tablette et les services qui y sont associés. Et plus important encore, les résultats révèlent que les bénéficiaires de DomAssist voient leur autodétermination augmentée, signe de l’amélioration de leur autonomie et de leur bien-être au domicile. Ces premiers résultats sont particulièrement prometteurs et encourageants. Ils suggèrent qu’une adoption à long terme de DomAssist par les personnes équipées est possible.&lt;/p&gt;&lt;p&gt;Ces résultats devront être confirmés par l’analyse des mêmes indicateurs présentés ici recueillis non plus à 6 mois mais à 9 mois d’utilisation consécutive de DomAssist. Cette confirmation semble être en bonne voie puisque certains bénéficiaires de DomAssist, après plus de 9 mois d’utilisation, ont exprimé unanimement, avec leurs aidants, leur désir de conserver DomAssist à l’issue de l’étude.&lt;/p&gt;&lt;p&gt;Le succès de DomAssist crée une forte dynamique chez les chercheurs et les partenaires du projet pour passer à l’étape supérieure en réalisant un déploiement de grande taille de la plateforme DomAssist. Les objectifs d’un tel déploiement sont multiples. D’un point de vue informatique, il permet d’éprouver la technologie et de définir des outils capables de gérer un grand nombre d’utilisateurs.  D’un point de vue psychologie du vieillissement, il ouvre une nouvelle voie permettant une étude à grande échelle, à l’instar des études de santé, sur une vaste population de personnes âgées sans critères de sélection préalables. Cette étude visera à démontrer de manière plus robuste statistiquement l’efficacité de la solution DomAssist.&lt;/p&gt;&lt;p&gt;Un nouveau projet, baptisé DomAssist500, concernera 1000 personnes âgées  vivant en Aquitaine, dont 500 seront équipées de la solution DomAssist. Ce projet ambitieux soutenu et financé par l’Europe (Fonds FEDER), sera mené en partenariat avec l’Institut de Santé Publique d’Epidémiologie et de Développement (ISPED).&lt;/p&gt;&lt;p&gt;Par cette étude d’envergure, l’équipe de recherche souhaite promouvoir un cadre scientifique pour l’évaluation des technologies d’assistance à la personne intégrant d’une part l’utilisabilité et l’acceptabilité des assistances (domaine des interactions homme-machine et de l’ergonomie) et d’autre part les bénéfices thérapeutiques (domaine de la santé). Une telle approche permettra d’étayer les allégations de santé associées à ces technologies pour apporter des garanties à leurs utilisateurs et futurs prescripteurs.&lt;/p&gt;&lt;p&gt;Pour en savoir plus, nous vous proposons une &lt;a class=&quot;lienPlus&quot; href=&quot;javascript:ouvreEncart(3,%20600,%20500%20);&quot;&gt;bibliographie&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='imagette'>upload/docs/image/jpeg/2016-02/domassist115.jpg</field>
    <field name='encarts'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;h3&gt;Partenariats du projet DomAssist&lt;/h3&gt;&lt;p&gt; &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a class=&quot;lienExterne&quot; href=&quot;http://www.rpdad.fr&quot; target=&quot;_blank&quot;&gt;Réseau Public Départemental des Aides à Domicile&lt;/a&gt;, dépendant de l’Union Départementale des Centres Communaux d’Action Sociale (UDCCAS) de Gironde &lt;/li&gt;&lt;li&gt;&lt;a class=&quot;lienExterne&quot; href=&quot;http://www.aquitaine.fr&quot; target=&quot;_blank&quot;&gt;Conseil Régional d’Aquitaine&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;lienExterne&quot; href=&quot;http://www.gironde.fr&quot; target=&quot;_blank&quot;&gt;Conseil Départemental de Gironde&lt;/a&gt; (Missions « Aménagement du territoire numérique » et « Personnes Agées &amp;amp; Handicap »)&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;lienExterne&quot; href=&quot;http://www.cm-bordeaux.fr&quot; target=&quot;_blank&quot;&gt;Chambre des Métiers et de l’Artisanat d’Aquitaine&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Caisse Nationale pour la Solidarité et l’Autonomie (&lt;a class=&quot;lienExterne&quot; href=&quot;http://www.cnsa.fr&quot; target=&quot;_blank&quot;&gt;CNSA&lt;/a&gt;)&lt;/li&gt;&lt;li&gt;Caisse d’Assurance Retraite et de la Santé au Travail (&lt;a class=&quot;lienExterne&quot; href=&quot;http://www.carsat-aquitaine.fr&quot; target=&quot;_blank&quot;&gt;CARSAT&lt;/a&gt;) Aquitaine&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;lienExterne&quot; href=&quot;http://www.ars.aquitaine-sante.fr&quot; target=&quot;_blank&quot;&gt;Agence Régionale de Santé d’Aquitaine&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;lienExterne&quot; href=&quot;http://cluster-tic-sante-aquitain.com&quot; target=&quot;_blank&quot;&gt;Cluster TIC Santé Aquitaine&lt;/a&gt; et la Silver Aquitaine&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;lienExterne&quot; href=&quot;http://www.gironde.fr/jcms/c_16879/les-clic-gironde-service-garanti&quot; target=&quot;_blank&quot;&gt;CLIC Gironde&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</item>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;h3&gt;Règles d’éthique et respect des données personnelles&lt;/h3&gt;&lt;p&gt;&lt;br /&gt;Le projet a été approuvé par le Comité de Protection des Personnes d’Aquitaine et par le comité d’éthique de l’Inria (COERLE). le dispositif DomAssist a également fait l’objet d’une déclaration à la CNIL.&lt;br /&gt;À ce titre, les objectifs de recherche et le traitement des données sont présentés à chaque participant afin de recueillir son consentement éclairé (par un formulaire de consentement éclairé).&lt;br /&gt;Précisément, les données collectées (données d’utilisation de la tablette mobile « lien social », données issues de la tablette stationnaire et des capteurs) sont transférées sur un serveur dédié via Internet depuis le domicile du bénéficiaire. Ces données sont codées afin de les anonymiser et d’assurer leur confidentialité.&lt;br /&gt;Par ailleurs, DomAssist dans sa conception prévoit le contrôle par l’utilisateur des notifications envoyées par la tablette principale à l’aide d’un bouton « pause » pour une période choisie par l’utilisateur. Cette fonction permet à l’utilisateur de ne pas être exposé à une possible situation d’assistance  qu’il pourrait juger comme stigmatisante pour les personnes qu’il accueille à son domicile.&lt;/p&gt;&lt;/div&gt;</item>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;h3&gt;Bibliographie&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Aguilova, L., Sauzéon, H., Balland, E., Consel, C., et N’Kaoua, B. « Grille AGGIR et aide à la spécification des besoins des personnes âgées en perte d’autonomie ». &lt;em&gt;Revue Neurologique&lt;/em&gt; 170, 3 (2014), 216–221.&lt;/li&gt;&lt;li&gt;Caroux, L., Consel, C., Dupuy, L. et  Sauzéon, H. (2014) « Verification of daily activities of Older Adults: A simple, Non-Intrusive, Low-Cost Approach », &lt;em&gt;ACM ASSETS’14&lt;/em&gt;, 20-22 oct, Rochester, NY, USA&lt;/li&gt;&lt;li&gt;Consel, C., Dupuy, L. et Sauzéon, H. (2015) « A Unifying Notification System to Scale up Assistive Services », &lt;em&gt;ACM ASSETS’15&lt;/em&gt;, 26-28 oct, Lisbon, Portugal&lt;/li&gt;&lt;li&gt;Dupuy, L., Sauzéon, H. et Consel, C. (soumis) « Self-Determination-Based Design to Achieve Acceptance of Assisted Living Technologies for Older Adults », 2015.&lt;/li&gt;&lt;li&gt;Dupuy, L., Sauzéon, H. et Consel, C. (2015) « Perceived Needs for Assistive Technologies in Older Adults and their Caregivers », &lt;em&gt;ACM WomENcourage’15&lt;/em&gt;, 24-26 sept, Uppsala, Sweden&lt;/li&gt;&lt;li&gt;Ekelund, C., &amp;amp; Eklund, K. (2015). « Longitudinal effects on self-determination in the RCT “Continuum of care for frail elderly people” ». &lt;em&gt;Quality in Ageing and Older Adults&lt;/em&gt;, 16(3).&lt;/li&gt;&lt;li&gt;Folstein, M. F., Folstein, S. E., and McHugh, P. R. « Mini-mental state: a practical method for grading the cognitive state of patients for the clinician ». &lt;em&gt;Journal of psychiatric research&lt;/em&gt; 12 , 3 (1975), 189–198.&lt;/li&gt;&lt;li&gt;Wehmeyer, M. L. « Self-determination and individuals with severe disabilities: Re-examining meanings and misinterpretations ». &lt;em&gt;Research and Practice for Persons with Severe Disabilities&lt;/em&gt; 30 , 3 (2005), 113–120.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</item>
    </field>
    <field name='auteurs'>
      <item id='p_88523' class='generated.Auteur'>Dupuy</item>
      <item id='p_88524' class='generated.Auteur'>Consel</item>
      <item id='p_88525' class='generated.Auteur'>Sauzéon</item>
    </field>
    <field name='moissonnable'>false</field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88536' url='https://interstices.info/jcms/p_88536/decrypter-les-signaux-du-cerveau'>
    <field name='title'>Décrypter les signaux du cerveau</field>
    <field name='categories'>
      <item id='c_34623' class='com.jalios.jcms.Category'>Podcasts</item>
      <item id='c_34624' class='com.jalios.jcms.Category'>Podcasts/Catégorie des Podcasts</item>
      <item id='c_34625' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes</item>
      <item id='c_34673' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes/Sciences et médecine</item>
    </field>
    <field name='pdate' time='1454085900000'>2016-01-29T17:45:00+01:00</field>
    <field name='udate' time='1453801334420'>2016-01-26T10:42:14+01:00</field>
    <field name='version' major='3' minor='2'>3.2</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1453391530841'>2016-01-21T16:52:10+01:00</field>
    <field name='mdate' time='1454106086775'>2016-01-29T23:21:26+01:00</field>
    <field name='filename' mtime='1453801335000' size='15746526' ticket='wL2yF6GMnt8Q9pC5ulGSVA=='>upload/docs/audio/mpeg/2016-01/decrypter_les_signaux_du_cerveau.mp3</field>
    <field name='originalFilename'>Décrypter les signaux du cerveau.mp3</field>
    <field name='contentType'>audio/mpeg</field>
    <field name='uploadDate' time='1453801334416'>2016-01-26T10:42:14+01:00</field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88572' url='https://interstices.info/jcms/p_88572/signaux-cerveau750'>
    <field name='title'>signaux-cerveau750</field>
    <field name='pdate' time='1453800996662'>2016-01-26T10:36:36+01:00</field>
    <field name='udate' time='1453800996663'>2016-01-26T10:36:36+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1453800996663'>2016-01-26T10:36:36+01:00</field>
    <field name='mdate' time='1453800996663'>2016-01-26T10:36:36+01:00</field>
    <field name='filename' mtime='1453800997000' size='28895' ticket='x+KKVBKfZxnDM6WFLn6waQ=='>upload/docs/image/jpeg/2016-01/signaux-cerveau750_2016-01-26_10-36-36_661.jpg</field>
    <field name='originalFilename'>signaux-cerveau750.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1453800996663'>2016-01-26T10:36:36+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>260</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>260 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='generated.DocumentInterstices' id='p_88298' url='https://interstices.info/jcms/p_88298/decrypter-les-signaux-du-cerveau'>
    <field name='title'>Décrypter les signaux du cerveau</field>
    <field name='categories'>
      <item id='jalios_5000' class='com.jalios.jcms.Category'>Navigation/Rubriques/De la recherche</item>
      <item id='c_34623' class='com.jalios.jcms.Category'>Podcasts</item>
      <item id='c_34624' class='com.jalios.jcms.Category'>Podcasts/Catégorie des Podcasts</item>
      <item id='c_34625' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes</item>
      <item id='c_34673' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes/Sciences et médecine</item>
      <item id='c_34687' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes/Technologies</item>
      <item id='new_47667' class='com.jalios.jcms.Category'>Navigation/Médias/Podcast</item>
      <item id='i_62034' class='com.jalios.jcms.Category'>CatTemporaire</item>
      <item id='nn_72675' class='com.jalios.jcms.Category'>Tags/Cerveau</item>
      <item id='ni_75079' class='com.jalios.jcms.Category'>Tags/Signal</item>
    </field>
    <field name='pdate' time='1454085900000'>2016-01-29T17:45:00+01:00</field>
    <field name='udate' time='1452596013921'>2016-01-12T11:53:33+01:00</field>
    <field name='version' major='1' minor='29'>1.29</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>full.pod</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1452596013921'>2016-01-12T11:53:33+01:00</field>
    <field name='mdate' time='1462881533252'>2016-05-10T13:58:53+02:00</field>
    <field name='resume' abstract='true'>Décrypter les signaux émis par le cerveau afin de mieux le comprendre, tel est le défi que s’est lancé le chercheur Alexandre Gramfort. Il nous en parle dans cet épisode du podcast audio. </field>
    <field name='chapo'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Décrypter les signaux émis par le cerveau afin de mieux le comprendre, tel est le défi que s’est lancé le chercheur Alexandre Gramfort. Il nous en parle dans cet épisode du podcast audio.&lt;/p&gt;&lt;/div&gt;</field>
    <field name='imageChapeau'>upload/docs/image/jpeg/2016-01/signaux-cerveau750_2016-01-26_10-36-36_661.jpg</field>
    <field name='legendeImageChapeau'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Mesures (MEG et EEG) et la localisation de leur origine dans le cerveau (tache rouge).&lt;/p&gt;&lt;/div&gt;</field>
    <field name='soustitre'>
    </field>
    <field name='texte'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Chaque jour, de nouveaux projets scientifiques se donnent pour objectif de faire progresser les connaissances acquises sur le cerveau humain. Les évolutions techniques ont joué un rôle important dans l&apos;enrichissement de nos connaissances sur cet organe. Grâce à l&apos;observation et aux techniques d&apos;imagerie médicale, les scientifiques ont déjà pu faire des avancées considérables, mais de nombreux pans du fonctionnement du cerveau ou de sa structure restent encore méconnus. Comment les mathématiques contribuent-elles à l&apos;exploration non invasive du cerveau humain ?&lt;/p&gt;&lt;p&gt;Alexandre Gramfort, spécialisé dans le domaine du traitement du signal, entend par exemple décrypter certains signaux émis par les cerveaux sains ou malades. Par quels moyens ? Grâce à des outils mathématiques permettant de mieux extraire, analyser et visualiser les signaux obtenus en imagerie cérébrale, notamment à partir d’électro-encéphalogrammes (EEG) et de magnéto-encéphalogrammes (MEG). Quelle est la particularité de ces signaux ? Que vont-ils nous apprendre du fonctionnement du cerveau ?  Nous faisons le point sur ces questions avec le chercheur.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='imagette'>upload/docs/image/jpeg/2016-01/signaux-cerveau115.jpg</field>
    <field name='encarts'>
    </field>
    <field name='auteurs'>
      <item id='p_88410' class='generated.Auteur'>Gramfort</item>
      <item id='c_24368' class='generated.Auteur'>Jongwane</item>
    </field>
    <field name='podcastItem' id='p_88536' class='com.jalios.jcms.FileDocument'>upload/docs/audio/mpeg/2016-01/decrypter_les_signaux_du_cerveau.mp3</field>
    <field name='moissonnable'>false</field>
    <field name='motsCles'>
    </field>
    <field name='indiceDewey'>
    </field>
    <field name='publicVise'>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88432' url='https://interstices.info/jcms/p_88432/stftexemple'>
    <field name='title'>STFTexemple</field>
    <field name='pdate' time='1453129598412'>2016-01-18T16:06:38+01:00</field>
    <field name='udate' time='1453129598413'>2016-01-18T16:06:38+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1453129598413'>2016-01-18T16:06:38+01:00</field>
    <field name='mdate' time='1453129598413'>2016-01-18T16:06:38+01:00</field>
    <field name='filename' mtime='1453129599000' size='165503' ticket='PbtMwzrcBHt7tb3+dZ6c6w=='>upload/docs/image/jpeg/2016-01/stftexemple.jpg</field>
    <field name='originalFilename'>STFTexemple.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1453129598413'>2016-01-18T16:06:38+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>458</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Iptc.ApplicationRecordVersion</key>
        <value>2</value>
      </entry>
      <entry>
        <key>image.Iptc.CodedCharacterSet</key>
        <value>%G</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>458 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.Photoshop.CaptionDigest</key>
        <value>-4 -31 31 -119 -56 -73 -55 120 47 52 98 52 7 88 119 -21</value>
      </entry>
      <entry>
        <key>image.Photoshop.IPTC-NAARecord</key>
        <value>15 bytes binary data</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88434' url='https://interstices.info/jcms/p_88434/intro'>
    <field name='title'>intro</field>
    <field name='pdate' time='1453130145840'>2016-01-18T16:15:45+01:00</field>
    <field name='udate' time='1453130145841'>2016-01-18T16:15:45+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1453130145841'>2016-01-18T16:15:45+01:00</field>
    <field name='mdate' time='1453130145841'>2016-01-18T16:15:45+01:00</field>
    <field name='filename' mtime='1453130146000' size='46538' ticket='HJaIs+ZQp5zb+JG8Oro30g=='>upload/docs/image/jpeg/2016-01/intro.jpg</field>
    <field name='originalFilename'>intro.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1453130145841'>2016-01-18T16:15:45+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>315</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Iptc.ApplicationRecordVersion</key>
        <value>2</value>
      </entry>
      <entry>
        <key>image.Iptc.CodedCharacterSet</key>
        <value>%G</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>315 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>740 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.Photoshop.CaptionDigest</key>
        <value>-4 -31 31 -119 -56 -73 -55 120 47 52 98 52 7 88 119 -21</value>
      </entry>
      <entry>
        <key>image.Photoshop.IPTC-NAARecord</key>
        <value>15 bytes binary data</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>740</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88436' url='https://interstices.info/jcms/p_88436/notationsstft'>
    <field name='title'>notationsSTFT</field>
    <field name='pdate' time='1453130763676'>2016-01-18T16:26:03+01:00</field>
    <field name='udate' time='1453130763678'>2016-01-18T16:26:03+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1453130763678'>2016-01-18T16:26:03+01:00</field>
    <field name='mdate' time='1453130763678'>2016-01-18T16:26:03+01:00</field>
    <field name='filename' mtime='1453130764000' size='33043' ticket='1O9Bl2N66tD0WMp6joDhgw=='>upload/docs/image/jpeg/2016-01/notationsstft.jpg</field>
    <field name='originalFilename'>notationsSTFT.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1453130763678'>2016-01-18T16:26:03+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>425</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Iptc.ApplicationRecordVersion</key>
        <value>2</value>
      </entry>
      <entry>
        <key>image.Iptc.CodedCharacterSet</key>
        <value>%G</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>425 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>740 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.Photoshop.CaptionDigest</key>
        <value>-4 -31 31 -119 -56 -73 -55 120 47 52 98 52 7 88 119 -21</value>
      </entry>
      <entry>
        <key>image.Photoshop.IPTC-NAARecord</key>
        <value>15 bytes binary data</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>740</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88438' url='https://interstices.info/jcms/p_88438/masque'>
    <field name='title'>masque</field>
    <field name='pdate' time='1453131155586'>2016-01-18T16:32:35+01:00</field>
    <field name='udate' time='1453131155586'>2016-01-18T16:32:35+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1453131155586'>2016-01-18T16:32:35+01:00</field>
    <field name='mdate' time='1453131155586'>2016-01-18T16:32:35+01:00</field>
    <field name='filename' mtime='1453131156000' size='13359' ticket='Nr54OY4lyWIN+Rm/lYFriQ=='>upload/docs/image/jpeg/2016-01/masque.jpg</field>
    <field name='originalFilename'>masque.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1453131155586'>2016-01-18T16:32:35+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>138</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Iptc.ApplicationRecordVersion</key>
        <value>2</value>
      </entry>
      <entry>
        <key>image.Iptc.CodedCharacterSet</key>
        <value>%G</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>138 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>740 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.Photoshop.CaptionDigest</key>
        <value>-4 -31 31 -119 -56 -73 -55 120 47 52 98 52 7 88 119 -21</value>
      </entry>
      <entry>
        <key>image.Photoshop.IPTC-NAARecord</key>
        <value>15 bytes binary data</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>740</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88439' url='https://interstices.info/jcms/p_88439/hp'>
    <field name='title'>hp</field>
    <field name='pdate' time='1453131301904'>2016-01-18T16:35:01+01:00</field>
    <field name='udate' time='1453131301905'>2016-01-18T16:35:01+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1453131301905'>2016-01-18T16:35:01+01:00</field>
    <field name='mdate' time='1453131301905'>2016-01-18T16:35:01+01:00</field>
    <field name='filename' mtime='1453131302000' size='110351' ticket='6XEyXpFcokOdgsIyjHnQ5Q=='>upload/docs/image/jpeg/2016-01/hp.jpg</field>
    <field name='originalFilename'>hp.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1453131301905'>2016-01-18T16:35:01+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>307</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Iptc.ApplicationRecordVersion</key>
        <value>2</value>
      </entry>
      <entry>
        <key>image.Iptc.CodedCharacterSet</key>
        <value>%G</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>307 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.Photoshop.CaptionDigest</key>
        <value>-4 -31 31 -119 -56 -73 -55 120 47 52 98 52 7 88 119 -21</value>
      </entry>
      <entry>
        <key>image.Photoshop.IPTC-NAARecord</key>
        <value>15 bytes binary data</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88669' url='https://interstices.info/jcms/p_88669/15187598339-c7ccd4da50-k-750'>
    <field name='title'>15187598339 c7ccd4da50 k 750</field>
    <field name='pdate' time='1454084238506'>2016-01-29T17:17:18+01:00</field>
    <field name='udate' time='1454084238507'>2016-01-29T17:17:18+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1454084238507'>2016-01-29T17:17:18+01:00</field>
    <field name='mdate' time='1454084238507'>2016-01-29T17:17:18+01:00</field>
    <field name='filename' mtime='1454084239000' size='41667' ticket='2PZMlDcTh9vLb8kzzFW9bg=='>upload/docs/image/jpeg/2016-01/15187598339_c7ccd4da50_k_750.jpg</field>
    <field name='originalFilename'>15187598339_c7ccd4da50_k_750.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1454084238507'>2016-01-29T17:17:18+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>260</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>260 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='generated.DocumentInterstices' id='p_84088' url='https://interstices.info/jcms/p_84088/demixer-la-musique'>
    <field name='title'>Démixer la musique</field>
    <field name='categories'>
      <item id='jalios_5000' class='com.jalios.jcms.Category'>Navigation/Rubriques/De la recherche</item>
      <item id='mf_46807' class='com.jalios.jcms.Category'>Tags/Musique</item>
      <item id='i_62034' class='com.jalios.jcms.Category'>CatTemporaire</item>
      <item id='ni_75079' class='com.jalios.jcms.Category'>Tags/Signal</item>
      <item id='p_89787' class='com.jalios.jcms.Category'>Classification UNIT/Télécommunications/16.08 Communications acoustiques</item>
    </field>
    <field name='pdate' time='1454085180000'>2016-01-29T17:33:00+01:00</field>
    <field name='udate' time='1432647866587'>2015-05-26T15:44:26+02:00</field>
    <field name='version' major='1' minor='90'>1.90</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>full.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='int_64630' class='com.jalios.jcms.Member' login='maxime'>Maxime Amblard</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1432647866587'>2015-05-26T15:44:26+02:00</field>
    <field name='mdate' time='1462881579548'>2016-05-10T13:59:39+02:00</field>
    <field name='resume' abstract='true'>Lors du mixage, un morceau de musique est produit à partir du son séparé des différents instruments. La séparation de sources audio cherche à inverser cette étape.</field>
    <field name='chapo'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Lors du mixage, un morceau de musique est produit à partir du son séparé des différents instruments. La séparation de sources audio cherche à inverser cette étape.&lt;/p&gt;&lt;/div&gt;</field>
    <field name='imageChapeau'>upload/docs/image/jpeg/2016-01/15187598339_c7ccd4da50_k_750.jpg</field>
    <field name='altImageChapeau'>20 Hz - 20 000 Hz Photo Adrien Hebert via Flickr</field>
    <field name='legendeImageChapeau'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p id=&quot;yui_3_16_0_1_1454081180885_143250&quot; class=&quot; meta-field photo-title &quot;&gt;20 Hz - 20 000 Hz - Photo : Adrien Hebert / &lt;a class=&quot;lienExterne&quot; href=&quot;https://flic.kr/p/p95pRM&quot; target=&quot;_blank&quot;&gt;Flickr&lt;/a&gt; - Licence Creative Commons BY-NC-ND 2.0.&lt;/p&gt;&lt;/div&gt;</field>
    <field name='texte'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;&lt;/script&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;La séparation de sources consiste à récupérer plusieurs signaux à partir de l&apos;observation de leur mélange. Dans le domaine du son, cette problématique est souvent introduite en évoquant l&apos;effet &lt;em&gt;cocktail party&lt;/em&gt;. Lors d&apos;une réception, de nombreuses voix simultanées parviennent à mes oreilles. Pourtant, je suis capable si je le souhaite de ne porter mon attention que sur l&apos;une d&apos;entre elles. Ce faisant, j&apos;ai réduit l&apos;influence des autres voix dans la compréhension de ce qui m&apos;intéresse. Pour cela, mon cerveau a séparé certains sons des autres.&lt;/p&gt;&lt;p&gt;De la même manière, en écoutant une chanson, je peux me concentrer sur l&apos;un des instruments, en l&apos;isolant ainsi mentalement des autres. Cette capacité, si elle pouvait être imitée par une machine, permettrait l&apos;extraction ou la suppression à l&apos;envi de n&apos;importe quel son d&apos;un enregistrement audio. Par exemple, nous pourrions enlever automatiquement la voix d&apos;un morceau pour en faire une version karaoké, ou bien au contraire l&apos;isoler pour l&apos;utiliser dans un nouveau morceau. En focalisant sur la voix dans un environnement bruité, nous pourrions aussi améliorer le fonctionnement des aides auditives ou la compréhension automatique des mots prononcés. Il est donc légitime qu&apos;une large communauté de chercheurs en traitement du signal audio se soit penchée sur le problème.&lt;/p&gt;&lt;h2&gt;Masquage temps-fréquence&lt;/h2&gt;&lt;p&gt;Considérons le cas d&apos;un morceau de musique stéréo. Il est composé d&apos;un canal gauche et d&apos;un canal droit. Nous appellerons ce signal le mélange, parce qu&apos;il est la superposition des différents sons que nous cherchons à séparer, appelés sources. Le son produit par chaque instrument s&apos;entend à la fois à gauche et à droite, en même temps que les autres instruments. En effet, un ingénieur du son a travaillé pour fabriquer un mélange qui soit agréable à écouter, dans lequel tous les instruments s&apos;entendent. Ici, notre objectif est de réaliser l&apos;opération inverse, il s&apos;agit en quelque sorte de démixer la musique, dans le but d&apos;isoler les sons des différents instruments.&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;intro.&quot; src=&quot;upload/docs/image/jpeg/2016-01/intro.jpg&quot; alt=&quot;intro&quot; width=&quot;740&quot; height=&quot;315&quot; /&gt;&lt;/p&gt;&lt;p&gt;La séparation est habituellement comprise comme une opération de filtrage, ce qui signifie que pour récupérer le son d&apos;un seul instrument, on va supprimer du mélange tout ce qui ne lui correspond pas.&lt;/p&gt;&lt;p&gt;Un filtre peut être compris comme un égaliseur, semblable à celui des autoradios, qui va atténuer ou amplifier certaines fréquences. La plage de fréquences des CD musicaux est de 0 à 22.05 kHz. Si notre objectif est par exemple d&apos;extraire la basse, une solution pourrait être de simplement supprimer tous les aigus du mélange. Cette approche peut marcher à la condition que, dans toutes les fréquences que nous gardons, seul le son cible soit présent. En pratique, il est nécessaire de considérer environ un millier de bandes de fréquences, de manière à avoir une précision suffisante pour que dans chacune il n&apos;y ait qu&apos;un seul instrument présent à la fois. Ensuite, l&apos;essentiel de notre travail consiste à choisir quelles bandes il nous faut atténuer ou conserver, dans le but d&apos;isoler un instrument donné. Pour compliquer les choses, nous sommes obligés de changer ce choix très régulièrement, parce que le morceau change constamment. La séparation de sources audio consiste ainsi à définir quelles fréquences garder ou supprimer, et à faire ce choix pour environ 1000 bandes de fréquences, toutes les 20 ms.&lt;/p&gt;&lt;p&gt;D&apos;un point de vue technique, l&apos;opération de séparation requiert une représentation temps-fréquence du son, qui est souvent la Transformée de Fourier à Court Terme (TFCT). Son principe est de découper le son en petits bouts appelés trames, qui correspondent au son pendant de petits intervalles de temps. Chaque trame est alors décomposée en une somme de sons purs, sinusoïdaux, par une Transformée de Fourier. N&apos;importe quel son peut être représenté de cette manière. Dans la suite de cet article, nous appellerons &lt;em&gt;x(f, t)&lt;/em&gt; la TFCT de notre morceau de musique. Il s&apos;agit de la fonction qui donne la portion du son qui vibre à chaque fréquence &lt;em&gt;f&lt;/em&gt;, à chaque temps &lt;em&gt;t&lt;/em&gt;. Elle contient une information de puissance et de phase : le module et l&apos;argument du nombre complexe &lt;em&gt;x(f,t)&lt;/em&gt;. Si on regarde sa puissance⎮&lt;em&gt;x (f, t)&lt;/em&gt;⎮&lt;sup&gt;2&lt;/sup&gt;, appelée spectrogramme, on obtient une image qui nous informe sur l&apos;évolution au cours du temps du contenu fréquentiel d&apos;un enregistrement sonore. Par exemple, voici le spectrogramme d&apos;un enregistrement de voix chantée.&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;STFTexemple&quot; src=&quot;upload/docs/image/jpeg/2016-01/stftexemple.jpg&quot; alt=&quot;STFTexemple&quot; width=&quot;700&quot; height=&quot;427&quot; /&gt;&lt;/p&gt;&lt;p&gt;Dans une telle représentation, le rouge nous indique que de l&apos;énergie est présente dans le signal. Cette visualisation permet à l&apos;expert d&apos;analyser les sons. Par exemple, dans le cas de la voix, un phonéticien professionnel serait capable de transcrire le son pour deviner quelles sont les paroles du morceau, uniquement en regardant le spectrogramme ! On appelle « point temps-fréquence » chaque pixel d&apos;un tel spectrogramme.&lt;/p&gt;&lt;p&gt;Maintenant, considérons que notre morceau est la somme de &lt;em&gt;J&lt;/em&gt; différents sons à séparer. Pour le cas d&apos;un quatuor, nous avons par exemple &lt;em&gt;J&lt;/em&gt; = 4. Tout comme les ondes qui se propagent à la surface de l&apos;eau, les formes d&apos;ondes sonores s&apos;ajoutent. La Transformée de Fourier du morceau est alors simplement égale à la somme des Transformées de Fourier des sources :&lt;br /&gt;&lt;em&gt;x(f, t)&lt;/em&gt; = &lt;em&gt;s&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt; (&lt;em&gt;f, t) + &lt;em&gt;s&lt;/em&gt;&lt;sub&gt;2&lt;/sub&gt; (&lt;em&gt;f, t) + &lt;em&gt;s&lt;/em&gt;&lt;sub&gt;3&lt;/sub&gt; (&lt;em&gt;f, t) + &lt;em&gt;s&lt;/em&gt;&lt;sub&gt;4&lt;/sub&gt; (&lt;em&gt;f, t)&lt;/em&gt;&lt;/em&gt;&lt;/em&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Dans cette équation, le nombre complexe &lt;em&gt;s&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt; (&lt;em&gt;f, t)&lt;/em&gt; est la TFCT de la source 1, mettons l&apos;accordéon, &lt;em&gt;&lt;em&gt;s&lt;/em&gt;&lt;sub&gt;2&lt;/sub&gt; (&lt;em&gt;f, t)&lt;/em&gt;&lt;/em&gt; celle de la source 2, etc.&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;notationsSTFT.&quot; src=&quot;upload/docs/image/jpeg/2016-01/notationsstft.jpg&quot; alt=&quot;notationsSTFT&quot; width=&quot;740&quot; height=&quot;425&quot; /&gt;&lt;/p&gt;&lt;p&gt;Notre problème est donc de récupérer les TFCT &lt;em&gt;s&lt;sub&gt;j&lt;/sub&gt;&lt;/em&gt; des sources à partir de celle du mélange &lt;em&gt;x&lt;/em&gt;.  Comme nous l&apos;avons suggéré plus haut, cela peut être fait en supprimant ou en conservant certaines fréquences au cours du temps.&lt;/p&gt;&lt;p&gt;À un instant &lt;em&gt;t&lt;/em&gt; et pour une fréquence &lt;em&gt;f&lt;/em&gt; donnés, le signal que nous observons est noté &lt;em&gt;x (f, t)&lt;/em&gt;. Appliquer une égalisation au signal à cette fréquence&lt;em&gt; f &lt;/em&gt;et ce temps&lt;em&gt; t&lt;/em&gt; peut être fait très simplement en multipliant &lt;em&gt;x (f,t)&lt;/em&gt; par une valeur entre 0 et 1, appelée « gain » : si on choisit 0, on atténue totalement cette bande de fréquence, on la garde au contraire intacte si on choisit 1. Ce gain utilisé pour séparer une source dépend à la fois du temps et de la fréquence, nous l&apos;appelons  « masque temps-fréquence » et le notons &lt;em&gt;w&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt; (&lt;em&gt;f, t&lt;/em&gt;) : c&apos;est l&apos;égalisation à appliquer à la TFCT du mélange pour récupérer une bonne estimée de la source 1. On note cette estimée \(\hat{s}_{1}\left(f,t\right)\) (prononcer « &lt;em&gt;s&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt; chapeau »).&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;masque.&quot; src=&quot;upload/docs/image/jpeg/2016-01/masque.jpg&quot; alt=&quot;masque&quot; width=&quot;700&quot; height=&quot;131&quot; /&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;Il est possible de donner directement une valeur à ce gain &lt;em&gt;w&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt; (&lt;em&gt;f, t&lt;/em&gt;) utilisé pour extraire la source 1. Habituellement, on choisit alors une valeur égale à 0 ou à 1, qui revient soit à éliminer ce point, soit à le conserver, pour estimer la source. On dit dans ce cas que le masque temps-fréquence est binaire.&lt;/p&gt;&lt;p&gt;Il est aussi possible de choisir n&apos;importe quelle valeur entre 0 et 1, afin d&apos;obtenir des sons séparés plus agréables à entendre. Dans ce cas, on exploite souvent la notion de spectrogramme de puissance que nous avons vue plus haut. Supposons pour l&apos;heure que nous connaissions les puissances de toutes les sources à chaque fréquence &lt;em&gt;f&lt;/em&gt; et à chaque instant &lt;em&gt;t&lt;/em&gt;, notées &lt;em&gt;v&lt;sub&gt;j&lt;/sub&gt;&lt;/em&gt; (&lt;em&gt;f, t&lt;/em&gt;) ≥ 0. Pour extraire la source 1, on utilise alors souvent un masque qui porte le nom de filtrage de Wiener, en l&apos;honneur de Norbert Wiener (1894-1964) qui l&apos;a proposé pour la première fois. Il revient à choisir pour masque d&apos;une source la proportion de sa puissance par rapport à la somme des puissances de toutes les sources &lt;em&gt;v&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt; + &lt;em&gt;v&lt;/em&gt;&lt;sub&gt;2 &lt;/sub&gt;+ ... + &lt;em&gt;v&lt;/em&gt;&lt;sub&gt;J&lt;/sub&gt; . Cela s&apos;écrit par l&apos;équation suivante :&lt;/p&gt;&lt;p&gt;\[&lt;br /&gt;w_{1}\left(f,t\right)=\frac{v_{1}\left(f,t\right)}{v_{1}\left(f,t\right)+v_{2}\left(f,t\right)+...+v_{J}\left(f,t\right)}&lt;br /&gt;\]&lt;/p&gt;&lt;p&gt;Un tel choix garantit que si &lt;em&gt;v&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt; est très grand devant les autres &lt;em&gt;v&lt;sub&gt;j&lt;/sub&gt;&lt;/em&gt; , le masque aura une valeur proche de 1. Sinon, il aura une valeur proche de 0. Si les puissances sont connues, le son séparé obtenu de cette manière sera très bon. Cependant, les spectrogrammes de puissance des sources sont en pratique inconnus, et nous avons besoin de les « deviner » à partir du mélange.&lt;/p&gt;&lt;h2&gt;Modéliser la musique&lt;/h2&gt;&lt;p&gt;Fabriquer un masque temps-fréquence est une tâche difficile. Le nombre de paramètres à régler est en effet très grand. Dans notre exemple, il est pour chaque source de 1000 bandes de fréquences multipliées par le nombre de trames, habituellement des dizaines de milliers. Bien qu&apos;il soit en théorie possible de le faire à la main, cela nécessiterait un travail laborieux de la part de l&apos;utilisateur, de l&apos;ordre de plusieurs heures pour quelques secondes de son. Plusieurs idées ont ainsi été proposées pour calculer les masques temps-fréquence automatiquement.&lt;/p&gt;&lt;p&gt;Une première méthode se nomme DUET, pour &lt;em&gt;Degenerate Unmixing Estimation Technique&lt;/em&gt;. Elle repose sur l&apos;idée que dans un morceau stéréo, les différents instruments sont souvent placés à différents endroits de l&apos;espace stéréo, c&apos;est-à-dire entre la gauche et la droite. Un utilisateur peut facilement nous donner une telle information, comme « la guitare est à droite » ou « la voix est au centre ». Dans ces conditions, pour une trame et une fréquence donnée, nous pouvons regarder si le son est plus fort à gauche, à droite, ou à peu près égal. Ce critère nous permet de décider à quelle source nous devons associer ce point temps-fréquence. Cette première méthode est dite spatiale, parce qu&apos;elle exploite surtout la position des sources dans l&apos;espace stéréo. Elle fonctionne très bien pour les morceaux de musique qui exploitent pleinement la stéréo, et dont le nombre d&apos;instruments n&apos;est pas trop grand. Ce sera par exemple le cas pour certains enregistrements des années 70, tels ceux des Beatles. DUET fonctionnera mal lorsqu&apos;il y a beaucoup d&apos;instruments, ou bien lorsque leur position dans le plan stéréo n&apos;est pas très précise, comme cela arrive lorsqu&apos;il y a de la réverbération. Des améliorations ont été proposées depuis, où on ne suppose plus qu&apos;un instrument est à une position précise, mais plutôt qu&apos;il présente une certaine corrélation entre la gauche et la droite. Dans le cas où le mélange est très compliqué, notamment en raison de la multiplicité des sources, cela permet de lever les ambiguïtés et d&apos;ainsi obtenir de bien meilleurs résultats.&lt;/p&gt;&lt;p&gt;Le problème d&apos;une telle séparation purement spatiale est qu&apos;elle ne peut pas fonctionner pour séparer des sources qui ont la même position dans le plan stéréo. Par exemple, il est très courant dans la musique populaire de placer la basse, la grosse caisse et la voix au centre. Il est alors impossible de séparer ces sons en utilisant uniquement des critères spatiaux et il devient nécessaire de prendre aussi en compte la nature de ces signaux par des critères spectraux.&lt;/p&gt;&lt;p&gt;Un exemple classique est la séparation harmonique-percussive. Dans un morceau de musique, il s&apos;agit d&apos;isoler les sons impulsifs de la batterie des autres sons du morceau, qui sont dits harmoniques. Pour comprendre ce qui distingue ces sons, il suffit d&apos;en regarder le spectrogramme.&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;hp.&quot; src=&quot;upload/docs/image/jpeg/2016-01/hp.jpg&quot; alt=&quot;hp&quot; width=&quot;750&quot; height=&quot;307&quot; /&gt;&lt;/p&gt;&lt;p&gt;Les sons harmoniques ont un contenu spectral qui évolue peu au cours du temps : on voit des lignes horizontales, qui correspondent aux différentes fréquences qui le composent. Ces fréquences produisent une nette sensation de hauteur lorsque nous écoutons le son. Cette hauteur est ce qu&apos;un musicien appellera une note, et placera sur une partition. Au contraire, les sons impulsifs de la batterie sont très courts, et on voit qu&apos;ils activent toutes les fréquences à la fois. Visuellement, leur spectrogramme présentera de nombreuses lignes verticales. Ainsi, la méthode proposée par D. Fitzgerald  consiste à identifier toutes les lignes horizontales du spectrogramme du mélange comme correspondant à la source harmonique, tandis que les lignes verticales seront rassemblées dans la source percussive. Cette technique très efficace permet d&apos;identifier simplement les spectrogrammes de ces deux sources et de les séparer grâce à un filtre de Wiener. De façon similaire, dans le cas de la voix parlée ou chantée, des techniques plus récentes permettent d&apos;apprendre la forme du spectrogramme des différents sons de la voix et de l&apos;exploiter pour la séparation.&lt;/p&gt;&lt;p&gt;Voici deux exemples à écouter de séparation de la voix et de l&apos;accompagnement instrumental. Le système fonctionne de la même manière que l&apos;exemple harmonique/percussif donné ci-dessus, mais discrimine entre les sons répétitifs de l&apos;accompagnement musical et les sons non-répétitifs  de la voix.&lt;/p&gt;&lt;p&gt;&lt;iframe src=&quot;https://files.inria.fr/interstices/demixer/binarymind-multitrackHTMLPlayer/massilia-et-britney.html&quot; frameborder=&quot;0&quot; width=&quot;700&quot; height=&quot;490&quot;&gt;&lt;/iframe&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Lecteur multipiste HTML par &lt;a class=&quot;lienExterne&quot; href=&quot;https://github.com/binarymind/multitrackHTMLPlayer&quot; target=&quot;_blank&quot;&gt;binarymind&lt;/a&gt;. Voir d&apos;autres exemples sur la &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.loria.fr/~aliutkus/kam/&quot; target=&quot;_blank&quot;&gt;page d&apos;Antoine Liutkus&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Démixer la musique en séparant les sources sonores requiert des systèmes de filtrage sophistiqués qui sont rendus possibles grâce à des connaissances dans le domaine des mathématiques appliquées, de l&apos;informatique et de l&apos;acoustique. Plus généralement, la séparation de sources est un problème difficile qui a des applications dans de nombreux autres domaines, les télécommunications, l&apos;imagerie hyperspectrale ou le traitement des signaux biomédicaux. Dans la plupart des cas, les techniques mises en œuvre compensent une indétermination du problème, qui comprend plus d&apos;inconnues que d&apos;équations, par la prise en compte de connaissances sur la nature des signaux à séparer. Si nous avons vu certains exemples simples de modèles spécifiques à la musique, d&apos;autres champs d&apos;application exploitent des propriétés spécifiques à leur domaine. Ainsi, sans en connaître exactement la forme, on peut savoir par exemple qu&apos;un des signaux à séparer est périodique, ou qu&apos;un autre est lisse, tandis qu&apos;un troisième est un bruit imprévisible.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='imagette'>upload/docs/image/jpeg/2016-01/frequences115.jpg</field>
    <field name='auteurs'>
      <item id='p_86728' class='generated.Auteur'>Liutkus</item>
      <item id='d_80036' class='generated.Auteur'>Vincent</item>
    </field>
    <field name='references'>
      <item id='nn_73045' class='generated.DocumentInterstices'>Quand les sons se séparent</item>
    </field>
    <field name='moissonnable'>true</field>
    <field name='motsCles'>
      <item>musique</item>
      <item>traitement du signal</item>
      <item>séparation de sources</item>
    </field>
    <field name='indiceDewey'>
      <item>621.3822</item>
    </field>
    <field name='publicVise'>
      <item>enseignement supérieur</item>
      <item>enseignement secondaire</item>
      <item>autres</item>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88541' url='https://interstices.info/jcms/p_88541/reve-algorithmes'>
    <field name='title'>reve-algorithmes</field>
    <field name='pdate' time='1453394894275'>2016-01-21T17:48:14+01:00</field>
    <field name='udate' time='1453394894276'>2016-01-21T17:48:14+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1453394894277'>2016-01-21T17:48:14+01:00</field>
    <field name='mdate' time='1453394894277'>2016-01-21T17:48:14+01:00</field>
    <field name='filename' mtime='1453394895000' size='48577' ticket='LCQX6IRGrPaw1DZEQtmzXw=='>upload/docs/image/jpeg/2016-01/reve-algorithmes.jpg</field>
    <field name='originalFilename'>reve-algorithmes.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1453394894277'>2016-01-21T17:48:14+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>260</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>260 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='generated.DocumentInterstices' id='p_87400' url='https://interstices.info/jcms/p_87400/regard-sur-a-quoi-revent-les-algorithmes'>
    <field name='title'>Regard sur « À quoi rêvent les algorithmes »</field>
    <field name='categories'>
      <item id='jalios_5004' class='com.jalios.jcms.Category'>Navigation/Rubriques/Débattre</item>
      <item id='mf_46784' class='com.jalios.jcms.Category'>Tags/Algorithme</item>
      <item id='i_62034' class='com.jalios.jcms.Category'>CatTemporaire</item>
    </field>
    <field name='pdate' time='1453456800000'>2016-01-22T11:00:00+01:00</field>
    <field name='udate' time='1448380258813'>2015-11-24T16:50:58+01:00</field>
    <field name='version' major='1' minor='70'>1.70</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>full.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_26560' class='com.jalios.jcms.Member' login='marie-odile'>Marie-Odile Cordier</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1448380258813'>2015-11-24T16:50:58+01:00</field>
    <field name='mdate' time='1462881604610'>2016-05-10T14:00:04+02:00</field>
    <field name='resume' abstract='true'>À quoi rêvent les algorithmes ? Cette question, à la fois intrigante et empreinte de poésie, a suscité la curiosité d’un chercheur en informatique. Il nous livre ici sa lecture personnelle de l’ouvrage de Dominique Cardon.</field>
    <field name='chapo'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;À quoi rêvent les algorithmes ? Cette question, à la fois intrigante et empreinte de poésie, a suscité la curiosité d’un chercheur en informatique. Il nous livre ici sa lecture personnelle de l’ouvrage de Dominique Cardon.&lt;/p&gt;&lt;/div&gt;</field>
    <field name='imageChapeau'>upload/docs/image/jpeg/2016-01/reve-algorithmes.jpg</field>
    <field name='legendeImageChapeau'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;© Fotolia - iuneWind&lt;/p&gt;&lt;/div&gt;</field>
    <field name='texte'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;&lt;em&gt;À quoi rêvent les algorithmes, Nos vies à l’heure des big data&lt;/em&gt;, Dominique Cardon, &lt;span class=&quot;lienExterne&quot;&gt;La république &lt;/span&gt;&lt;span class=&quot;lienExterne&quot;&gt;des idées - &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.seuil.com/livre-9782021279962.htm&quot; target=&quot;_blank&quot;&gt;Seuil&lt;/a&gt;&lt;/span&gt;, Octobre 2015.&lt;/p&gt;&lt;p&gt;Sociologue spécialisé dans le numérique et Internet, &lt;a class=&quot;lienExterne&quot; href=&quot;https://fr.wikipedia.org/wiki/Dominique_Cardon&quot; target=&quot;_blank&quot;&gt;Dominique Cardon&lt;/a&gt; nous propose de revenir sur les &lt;em&gt;&lt;a class=&quot;lienDef&quot; href=&quot;javascript:ouvreEncart(1,%20600,%20500);&quot;&gt;algorithmes&lt;/a&gt;, &lt;/em&gt;dans son livre &lt;em&gt; À quoi rêvent les algorithmes, Nos vies à l’heure des big data&lt;/em&gt;. La place prise par l’informatique et le calcul dans l’organisation de nos sociétés est une question importante et l’auteur montre la nécessité de réfléchir aux nouveaux usages et possibilités liés aux &lt;em&gt;algorithmes&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;Le travail de Dominique Cardon apparaît à la fois d’une grande nécessité, et souffrant de plusieurs défauts. L’auteur focalise son discours et notre attention sur les &lt;em&gt;algorithmes&lt;/em&gt; sans chercher à donner de définition de ce qu’il considère comme tel. Cette imprécision dans les concepts le conduit à faire des raccourcis qui fragilisent son argumentation.&lt;/p&gt;&lt;p&gt;Ce livre ne parle pas des algorithmes mais d’outils informatiques. Il est vrai que les outils informatiques sont constitués de programmes, qui implémentent des algorithmes. Mais la partie ne fait pas le tout. Le livre &lt;em&gt;À quoi rêvent les algorithmes&lt;/em&gt; pourrait laisser croire que l’analyse proposée vaut pour toute l’informatique, ce qui n’est pas le cas. Ici il s’agit de discuter d’une partie très spécifique relative aux usages de l’informatique, de plus en la réduisant aux interactions sur Internet. Un livre aussi ambitieux ne devrait pas alimenter cette ambiguïté.&lt;/p&gt;&lt;p&gt;L’informatique n’est pas Internet. C’est une science. Et elle ne se réduit pas à la science des usages ou de la donnée. C’est une science qui s’intéresse à la résolution de problèmes par le calcul, avec des aspects aussi divers que la &lt;a href=&quot;jcms/p_86521/mieux-modeliser-le-climat-grace-aux-statistiques&quot; target=&quot;_self&quot;&gt;modélisation mathématique&lt;/a&gt;, la &lt;a href=&quot;jcms/c_23115/preuves-formelles-preuves-calculatoires&quot;&gt;logique &lt;/a&gt;ou encore la &lt;a href=&quot;jcms/p_81141/p-np-elementaire-ma-chere-watson&quot;&gt;complexité des problèmes&lt;/a&gt; sur un versant théorique, ou des réalisations pratiques comme les &lt;a href=&quot;jcms/ni_75926/les-reseaux-pour-le-calcul-haute-performance-facteur-livreur-ou-demenageur&quot;&gt;réseaux&lt;/a&gt;, l’&lt;a href=&quot;jcms/ni_77930/des-logiciels-pour-l-impression-3d&quot;&gt;impression 3D&lt;/a&gt; et la &lt;a href=&quot;jcms/c_43248/cryptographie-du-chiffre-et-des-lettres&quot;&gt;cryptographie&lt;/a&gt;, qui sont basés sur des modèles mathématiques élaborés.&lt;/p&gt;&lt;p&gt;À l’heure où d’importantes discussions sont en cours à propos des programmes à introduire dans l’enseignement secondaire sur l’informatique, il est important de faire entendre cette différence. On retrouvera la &lt;a href=&quot;jcms/c_7125/sciences-et-technologies-de-l-information-et-de-la-communication&quot;&gt;présentation de Gilles Kahn&lt;/a&gt; à l’Académie des sciences sur cette question : il est souvent aisé d’avoir une intuition sur la technologie alors qu’il est difficile de percevoir la question scientifique qui est derrière.&lt;/p&gt;&lt;p&gt;On retrouve ces approximations dans les définitions du livre à propos de &lt;em&gt;machine learning&lt;/em&gt;, d’intelligence artificielle, ou de traitement automatique des langues. Il est vrai qu’il est délicat de proposer des définitions simples de ces concepts, qui sont pourtant au cœur d&apos;importants enjeux politiques. Entretenir la confusion obscurcit le débat plutôt que de le libérer. Le &lt;em&gt;machine learning&lt;/em&gt; n’est pas l’intelligence artificielle qui n’est pas le traitement automatique de la langue.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Le &lt;em&gt;machine learning&lt;/em&gt; est un champ d’étude de l’informatique qui s’intéresse aux algorithmes de reconnaissance de motifs et d’apprentissage. Il s’agit de déterminer la suite d’un algorithme sans qu’elle ait été explicitement donnée, en fonction de résultats numériques obtenus à partir d’un motif.&lt;/li&gt;&lt;li&gt;L’intelligence artificielle est le champ qui définit des algorithmes pour résoudre des tâches au moins aussi bien, voire mieux que ne le font actuellement les humains. Dans ce cas, l’intelligence artificielle peut mettre en oeuvre des techniques de &lt;em&gt;machine learning&lt;/em&gt;, mais pas seulement.&lt;/li&gt;&lt;li&gt;Le traitement automatique des langues se concentre sur la capacité de langage des humains. Il s’agit de comprendre ou de produire automatiquement des textes ou des sons en langue naturelle. À nouveau il est possible de répondre à ces défis par le &lt;em&gt;machine &lt;/em&gt;&lt;em&gt;learning&lt;/em&gt; (mais pas seulement).&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Le &lt;em&gt;machine learning&lt;/em&gt; trouve des cas d’applications à la fois en intelligence artificielle et en traitement automatique des langues. Il peut être vu comme un outil technique pour l’intelligence artificielle tout en restant un objet théorique. Bien sûr que des relations existent entre ces concepts, mais ils n’ont ni les mêmes objets d’études, ni les mêmes paradigmes.&lt;/p&gt;&lt;p&gt;Un autre aspect du livre, très symptomatique de la perception de l’informatique par la société actuelle, est l’abus de vocabulaire anthropocentré. Les algorithmes ne rêvent pas. Les algorithmes ne peuvent pas rêver. Les algorithmes n’ont pas de vie propre. Si l’analogie est sympathique, elle a autant de sens que de se demander à quoi rêve le plus de l’addition. Il ne rêve pas. Derrière les algorithmes il y a des programmeurs, des concepteurs, des théories, des entreprises, des centres de recherche, et eux peuvent avoir des desseins ou des rêves pour les programmes. Et c’est eux qu’il faut questionner, d’autant qu’ils ont la capacité de répondre. C’est aussi l’une des ambiguïtés que l’on retrouve dans le concept d’apprentissage du &lt;em&gt;machine &lt;/em&gt;&lt;em&gt;learning&lt;/em&gt; dont j’ai parlé précédemment. L’algorithme n’apprend pas, ne décide pas, ne se comporte pas. Il fournit un résultat en fonction de son contexte d’utilisation. Au mieux, il nous laisse croire qu’il a appris à réagir dans une situation. D’aucuns vont argumenter sur le fait que cela reste un apprentissage. Je ne le crois pas car l’algorithme n’a pas de modèle conceptuel expliquant les relations qu’il construit entre l’ensemble de ses « apprentissages &lt;em&gt;»&lt;/em&gt; supposés. Un enfant qui apprend à marcher construit sa perception ontologique par son expérience. Un programme exécuté sur un ordinateur collectionne les décisions, les laissant s’influencer avec plus ou moins de hasard. Mais l’algorithme n’a pas appris ou n’a pas transformé son expérience en connaissance. Il reste au niveau de l’information brute.&lt;/p&gt;&lt;p&gt;Ce qui est inquiétant dans cette personnification des algorithmes ou des outils informatiques, c’est qu’il serait possible de les désigner comme responsables des évolutions de la société. Mais un algorithme ne fait rien d’autre que ce qu’on lui demande de faire. Individuellement nous faisons le choix de suivre les prescriptions des algorithmes, même de manière inconsciente, et collectivement nous acceptons qu’ils aient une influence sur notre organisation en société. Un phénomène intéressant est que les &lt;em&gt;algorithmes&lt;/em&gt; prédisent à partir de ce qu’ils ont rencontré par le passé, donc ce qui est considéré comme significatif au départ reste influent, voire central, par une forme d’inertie du système. Ainsi les inégalités intégrées à l’initialisation du processus ont une possibilité de devenir la norme.&lt;/p&gt;&lt;p&gt;Les pratiques actuelles sur Internet, malgré leur manque de structuration permettent aussi à des cultures très spécifiques, souvent à la marge, d’avoir une existence qu’elles ne trouveraient pas en dehors. Cette usine à possibles ainsi proposée est tout à fait enthousiasmante et met en avant un changement profond de mode de fonctionnement, plus &lt;em&gt;bottom-up&lt;/em&gt; (du bas vers le haut). Ces usages permettent à une activité à la marge d’exister grâce à un effet de seuil, mais en la laissant à cette marge.&lt;/p&gt;&lt;p&gt;Une idée intéressante développée par l’auteur est celle introduite autour du concept de loyauté : la nécessité pour un outil informatique de ne faire que ce qu’il est censé faire et de le faire bien. C’est probablement le seul rempart face à une modification de la perception par la société de la science informatique qui conduirait à une diabolisation, du type construction d’un Big Brother capable de tout voir et tout contrôler.&lt;/p&gt;&lt;p&gt;Par ailleurs, ce travail est sous-tendu par un important travail bibliographique provenant de disciplines différentes (science politique, sociologie, économie, etc.) qui donne un éclairage singulier sur ces questions. En particulier sur le rapport que nous entretenons avec les &lt;em&gt;big &lt;/em&gt;&lt;em&gt;data&lt;/em&gt;. Il est vrai que s’attaquer à ces informations va permettre de rapidement faire émerger des résultats, mais sans contextualisation, ces résultats pourraient vite devenir inutilisables car non interprétables, d’autant qu’une grande partie de l’information n’est que du bruit dans lequel nous risquons de nous perdre.&lt;/p&gt;&lt;p&gt;Malgré les réserves que j’ai pu avancer, je crois que l’auteur fait ici une alerte importante. Nous avons urgence à développer une réflexion plus précise tant sur les possibles, les usages et les influences de la science du numérique. Il serait dommage de ne pas entendre cette prescription à cause des imprécisions précédentes et plus encore de ne pas s’en saisir. Comment ne pas porter simultanément une réflexion sur les principes du vote quand on programme un système de vote numérique ?&lt;/p&gt;&lt;p&gt;Le point de vue qui est présenté dans ce livre reste celui d’un non-spécialiste de l’informatique, ce qui me conduit à comprendre les ambiguïtés précédemment pointées. L’informatique est aujourd’hui très diverse dans ses aspirations et ses tensions et il est complexe de l’appréhender dans sa globalité. Dans son livre, Dominique Cardon esquisse des interprétations épistémologiques et sociologiques de l’informatique, en particulier de l’Internet, et c’est certainement pour cela qu’il est nécessaire de lire ce livre : mieux comprendre une partie des enjeux actuels de l’informatique, et mesurer la nécessité de mieux définir l’informatique comme science inscrite dans une histoire et une société. Entre les deux, le chemin sera long et ce livre est un pas.&lt;/p&gt;&lt;h2&gt;Une lecture commentée des chapitres&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;&lt;br /&gt;Chapitre 1. Les algorithmes du Web&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Une classification des &lt;a class=&quot;lienDef&quot; href=&quot;javascript:ouvreEncart(2,%20600,%20500);&quot;&gt;algorithmes du web&lt;/a&gt;, les &lt;em&gt;algorithmes&lt;/em&gt; :&lt;/p&gt;&lt;ul&gt;&lt;li&gt;à côté du web (Google Analytic, Médiamétrie...) qui s’intéressent à la popularité des sites&lt;/li&gt;&lt;li&gt;au dessus du web (PageRank de &lt;a href=&quot;jcms/c_47076/comment-google-classe-les-pages-web&quot;&gt;Google&lt;/a&gt;) qui analysent la structure du web pour inférer de la « méritocratie »&lt;/li&gt;&lt;li&gt;à l’intérieur du web (&lt;a href=&quot;jcms/ni_79095/l-algorithme-edge-rank-ou-le-filtrage-selon-facebook&quot;&gt;FaceBook&lt;/a&gt;, Twitter) qui évaluent l’activité à l’intérieur des réseaux (likes, retweets...)&lt;/li&gt;&lt;li&gt;au dessous du web (Recommandation Amazon...) qui calculent à partir des traces laissées par les utilisateurs&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Chacune de ces positions relatives au web permet de comprendre les enjeux sociétaux et commerciaux des outils proposés. En creux se dessine une perspective épistémologique, de la simple consultation d’une page à une analyse plus complexe basée sur la&lt;br /&gt;navigation.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Chapitre 2. La révolution du Big Data&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;La montée en puissance du traitement et l’explosion de la production de données (les &lt;em&gt;big data&lt;/em&gt;) modifient la relation société / numérique qui a vécu trois changements :&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Le choix des descripteurs d’une activité entraîne une modification du comportement des individus qui cherchent à s’adapter à la mesure. Un exemple est le site &lt;a class=&quot;lienExterne&quot; href=&quot;http://www.nosdeputes.fr/&quot; target=&quot;_blank&quot;&gt;nosdéputés.fr&lt;/a&gt; qui relaie l’activité parlementaire. Son apparition a (naturellement) poussé les élus à améliorer leurs scores, sans que nous puissions constater une augmentation qualitative de l’activité du parlement.&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;&lt;li&gt;L’augmentation de la capacité de mesure permet de se concentrer sur des descripteurs de plus en plus fins, jusqu’à ne contenir qu’un nombre très réduit d’individus. Il devient alors difficile de définir l’appartenance de l’individu à des catégories particulières, ou de les hiérarchiser entre elles. Le risque est alors que chaque expression vale celles des autres.&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;&lt;li&gt;L’application massive des modèles mathématiques (numériques) permet de découvrir (aléatoirement) des corrélations. Mais il ne suffit pas de les interpréter comme des « causes probables », il faut aussi leur donner du sens, en mobilisant des théories et des modèles venus des sciences humaines.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;Chapitre 3. Signaux et traces&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Ce chapitre se concentre sur la définition des signaux (informations explicitement délivrées par l’utilisateur : tweet, commentaire, etc.) et des traces (temps de consultation d’une page, chemin pour parvenir à une information...). Actuellement, les &lt;em&gt;algorithmes &lt;/em&gt;considérés comme les plus performants sont capables de profiter à la fois des traces et des signaux.&lt;/p&gt;&lt;p&gt;Ces systèmes prédisent un comportement par similarité de régularités précédemment observées. La mesure de leur efficacité est difficile. Il faut retenir l’exemple de la publicité où une campagne qui augmente de 100% sa productivité fait passer de 0,01 à 0,02% de clic par page. Mais ici, les &lt;em&gt;algorithmes&lt;/em&gt; se focalisent sur le passé.&lt;/p&gt;&lt;p&gt;L’auteur explique aussi que la peur des &lt;em&gt;algorithmes&lt;/em&gt; est légitime, mais qu’il est bien plus important que nous, en tant que citoyens, demandions aux programmes d’être loyaux. Si un programme est présenté comme réalisant une tâche, il ne doit faire que cela. C’est le seul moyen de ne pas laisser croire que l’informatique est biaisée et assujettie à des intérêts fantasmatiques.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Chapitre 4. La société des calculs&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;La dernière partie du livre ouvre vers une lecture plus politique de la relation aux &lt;em&gt;algorithmes&lt;/em&gt;. L’auteur revient sur la concentration de l’attention sur Internet et aussi sur l’autoreproduction du centre du réseau — plus un utilisateur est au centre d’un réseau, moins il a de chance d’en sortir. Mais le salut vient de la dernière partie de ce chapitre où l’auteur rappelle que les résultats des programmes informatiques ne sont généralement pas considérés comme de très grande qualité, et que les individus aiment à jouer avec de multiples plateformes en même temps, ce qui complexifie d’autant l’étude automatique de leur comportement, voire qu’ils continuent de considérer que leur vie se déploie en dehors des univers virtuels.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='imagette'>upload/docs/image/jpeg/2016-01/reve-algo115.jpg</field>
    <field name='encarts'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Le terme d&apos;algorithme utilisé par l&apos;auteur est à la fois plus large et plus étroit que celui utilisé par les informaticiens. Pour distinguer les usages, algorithme sera marqué en italique lorsqu&apos;il s&apos;entend selon la définition de Dominique Cardon.&lt;/p&gt;&lt;/div&gt;</item>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;L’auteur utilise le terme &lt;em&gt;algorithme&lt;/em&gt; de manière générale, mais il focalise son argumentation sur les &lt;em&gt;algorithmes&lt;/em&gt; du web.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='auteurs'>
      <item id='ni_74166' class='generated.Auteur'>Amblard</item>
    </field>
    <field name='moissonnable'>false</field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_87839' url='https://interstices.info/jcms/p_87839/modeliser-pour-simuler-le-climat'>
    <field name='title'>Modéliser pour simuler le climat</field>
    <field name='categories'>
      <item id='c_34623' class='com.jalios.jcms.Category'>Podcasts</item>
      <item id='c_34624' class='com.jalios.jcms.Category'>Podcasts/Catégorie des Podcasts</item>
      <item id='c_34625' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes</item>
      <item id='c_34673' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes/Sciences et médecine</item>
    </field>
    <field name='pdate' time='1450719000000'>2015-12-21T18:30:00+01:00</field>
    <field name='udate' time='1450707085617'>2015-12-21T15:11:25+01:00</field>
    <field name='version' major='3' minor='2'>3.2</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1450112978949'>2015-12-14T18:09:38+01:00</field>
    <field name='mdate' time='1451988462691'>2016-01-05T11:07:42+01:00</field>
    <field name='filename' mtime='1450707086000' size='15078528' ticket='mfi3+KT7xEfVKDjRGz7R4A=='>upload/docs/audio/mpeg/2015-12/comprendre_la_modelisation_du_climat.mp3</field>
    <field name='originalFilename'>Comprendre la modélisation du climat.mp3</field>
    <field name='contentType'>audio/mpeg</field>
    <field name='uploadDate' time='1450707085578'>2015-12-21T15:11:25+01:00</field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88160' url='https://interstices.info/jcms/p_88160/modele-climat'>
    <field name='title'>modele-climat</field>
    <field name='pdate' time='1450709375441'>2015-12-21T15:49:35+01:00</field>
    <field name='udate' time='1450709375442'>2015-12-21T15:49:35+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1450709375442'>2015-12-21T15:49:35+01:00</field>
    <field name='mdate' time='1450709375442'>2015-12-21T15:49:35+01:00</field>
    <field name='filename' mtime='1450709376000' size='62609' ticket='zgRirNyn5bGTOVJdlJ7k/g=='>upload/docs/image/jpeg/2015-12/modele-climat.jpg</field>
    <field name='originalFilename'>modele-climat.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1450709375442'>2015-12-21T15:49:35+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>300</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>300 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='generated.DocumentInterstices' id='p_87074' url='https://interstices.info/jcms/p_87074/modeliser-pour-simuler-le-climat'>
    <field name='title'>Modéliser pour simuler le climat</field>
    <field name='categories'>
      <item id='jalios_5000' class='com.jalios.jcms.Category'>Navigation/Rubriques/De la recherche</item>
      <item id='c_34624' class='com.jalios.jcms.Category'>Podcasts/Catégorie des Podcasts</item>
      <item id='c_34625' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes</item>
      <item id='c_34673' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes/Sciences et médecine</item>
      <item id='c_34687' class='com.jalios.jcms.Category'>Podcasts/Catégories iTunes/Technologies</item>
      <item id='mf_46778' class='com.jalios.jcms.Category'>Tags/Simulation</item>
      <item id='new_47667' class='com.jalios.jcms.Category'>Navigation/Médias/Podcast</item>
      <item id='i_62034' class='com.jalios.jcms.Category'>CatTemporaire</item>
      <item id='int_68168' class='com.jalios.jcms.Category'>Catégories hors navigation/Mathématiques de la planète Terre</item>
      <item id='p_84938' class='com.jalios.jcms.Category'>Tags/Climat</item>
      <item id='p_85918' class='com.jalios.jcms.Category'>Tags/COP21</item>
      <item id='p_85922' class='com.jalios.jcms.Category'>Tags/Planète</item>
    </field>
    <field name='pdate' time='1450719000000'>2015-12-21T18:30:00+01:00</field>
    <field name='udate' time='1446741751273'>2015-11-05T17:42:31+01:00</field>
    <field name='version' major='1' minor='24'>1.24</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>full.pod</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1446741751273'>2015-11-05T17:42:31+01:00</field>
    <field name='mdate' time='1462881634575'>2016-05-10T14:00:34+02:00</field>
    <field name='resume' abstract='true'>Comprendre les climats du passé et du présent pour prévoir le climat du futur, tel est le défi qui anime la communauté scientifique au sein du Pôle de modélisation du climat de l&apos;IPSL. Marie-Alice Foujols nous présente les enjeux de leurs travaux dans cet épisode du podcast audio. </field>
    <field name='chapo'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Comprendre les climats du passé et du présent pour prévoir le climat du futur, tel est le défi qui anime la communauté scientifique au sein du Pôle de modélisation du climat de l&apos;Institut Pierre-Simon Laplace. Marie-Alice Foujols, directrice adjointe de l&apos;IPSL, nous présentait les enjeux de ces travaux le 25 novembre dernier, à l&apos;occasion de notre série d&apos;entretiens autour de la COP21.&lt;/p&gt;&lt;/div&gt;</field>
    <field name='imageChapeau'>upload/docs/image/jpeg/2015-12/modele-climat.jpg</field>
    <field name='legendeImageChapeau'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Modélisation. © Animea, F. Durillon&lt;/p&gt;&lt;/div&gt;</field>
    <field name='texte'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Les modèles sont des outils essentiels pour pouvoir comprendre et anticiper le climat. Au fil des ans, les modèles climatiques ont gagné en qualité et en précision, de sorte qu&apos;ils permettent de simuler de façon assez réaliste de nombreuses caractéristiques du climat. Aujourd&apos;hui, l&apos;un des enjeux des recherches consiste à combiner plusieurs modèles pour affiner les prévisions.&lt;/p&gt;&lt;p&gt;Le modèle climat de l’IPSL s’appuie sur la modélisation des différents éléments clés du système climatique : l’atmosphère, les surfaces continentales, l’océan, etc. Comme nous l&apos;explique Marie-Alice Foujols, les différentes générations de ce modèle du climat sont utilisées pour les simulations climatiques de différents programmes internationaux et  ont servi de support aux rapports du GIEC. La première génération de ce modèle a été développée dès les années 1990. Les versions suivantes ont intégré, au fur et à mesure, les nombreux progrès scientifiques et techniques accomplis, pour aboutir en 2010 à la 5&lt;sup&gt;e&lt;/sup&gt; génération. Les équipes de l&apos;IPSL travaillent à présent sur la sixième.&lt;/p&gt;&lt;p&gt;Quelle est la différence entre un modèle météorologique et un modèle climatique ? Comment sont développés les modèles de climat ? Quels sont les défis à relever dans ce domaine ? Marie-Alice Foujols nous apporte son éclairage sur ces questions.&lt;/p&gt;&lt;p&gt;Pour en savoir plus, voir aussi cette &lt;a href=&quot;https://youtu.be/iP7hY9mgMHc&quot;&gt;animation vidéo&lt;/a&gt; sur la modélisation climatique réalisée par l&apos;IPSL.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='imagette'>upload/docs/image/jpeg/2015-12/modele-climat115.jpg</field>
    <field name='auteurs'>
      <item id='p_87760' class='generated.Auteur'>Foujols</item>
      <item id='c_24368' class='generated.Auteur'>Jongwane</item>
    </field>
    <field name='podcastItem' id='p_87839' class='com.jalios.jcms.FileDocument'>upload/docs/audio/mpeg/2015-12/comprendre_la_modelisation_du_climat.mp3</field>
    <field name='moissonnable'>false</field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_87801' url='https://interstices.info/jcms/p_87801/fig-x1'>
    <field name='title'>fig-x1</field>
    <field name='pdate' time='1449588293288'>2015-12-08T16:24:53+01:00</field>
    <field name='udate' time='1449588293289'>2015-12-08T16:24:53+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1449588293289'>2015-12-08T16:24:53+01:00</field>
    <field name='mdate' time='1449588293289'>2015-12-08T16:24:53+01:00</field>
    <field name='filename' mtime='1449588294000' size='6473' ticket='NGRRSY6VZhRBs6uzPwX0Gw=='>upload/docs/image/gif/2015-12/fig-x1.gif</field>
    <field name='originalFilename'>fig-x1.gif</field>
    <field name='contentType'>image/gif</field>
    <field name='uploadDate' time='1449588293289'>2015-12-08T16:24:53+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>304</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>8</value>
      </entry>
      <entry>
        <key>image.number-of-images</key>
        <value>1</value>
      </entry>
      <entry>
        <key>width</key>
        <value>500</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_87802' url='https://interstices.info/jcms/p_87802/fig-y2'>
    <field name='title'>fig-y2</field>
    <field name='pdate' time='1449588293296'>2015-12-08T16:24:53+01:00</field>
    <field name='udate' time='1449588293296'>2015-12-08T16:24:53+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1449588293296'>2015-12-08T16:24:53+01:00</field>
    <field name='mdate' time='1449588293296'>2015-12-08T16:24:53+01:00</field>
    <field name='filename' mtime='1449588294000' size='17776' ticket='+IgCMAHAGVqUPGDJJiNXxQ=='>upload/docs/image/gif/2015-12/fig-y2.gif</field>
    <field name='originalFilename'>fig-y2.gif</field>
    <field name='contentType'>image/gif</field>
    <field name='uploadDate' time='1449588293296'>2015-12-08T16:24:53+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>186</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>8</value>
      </entry>
      <entry>
        <key>image.number-of-images</key>
        <value>1</value>
      </entry>
      <entry>
        <key>width</key>
        <value>700</value>
      </entry>
    </field>
  </data>
  <data class='com.jalios.jcms.FileDocument' id='p_88143' url='https://interstices.info/jcms/p_88143/parc-enfants'>
    <field name='title'>parc-enfants</field>
    <field name='pdate' time='1450697872810'>2015-12-21T12:37:52+01:00</field>
    <field name='udate' time='1450697872811'>2015-12-21T12:37:52+01:00</field>
    <field name='version' major='1' minor='0'>1.0</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>box.default</item>
      <item>full.default</item>
      <item>edit.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='opAuthor' id='c_20039' class='com.jalios.jcms.Member' login='joanna'>Joanna Jongwane</field>
    <field name='cdate' time='1450697872811'>2015-12-21T12:37:52+01:00</field>
    <field name='mdate' time='1450697872811'>2015-12-21T12:37:52+01:00</field>
    <field name='filename' mtime='1450697873000' size='109162' ticket='4lVI4vDQAVIKzkgWZQzJdQ=='>upload/docs/image/jpeg/2015-12/parc-enfants.jpg</field>
    <field name='originalFilename'>parc-enfants.jpg</field>
    <field name='contentType'>image/jpeg</field>
    <field name='uploadDate' time='1450697872811'>2015-12-21T12:37:52+01:00</field>
    <field name='metaDataMap'>
      <entry>
        <key>height</key>
        <value>300</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.ColorTransform</key>
        <value>YCbCr</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.DCTEncodeVersion</key>
        <value>1</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags0</key>
        <value>192</value>
      </entry>
      <entry>
        <key>image.Adobe Jpeg.Flags1</key>
        <value>0</value>
      </entry>
      <entry>
        <key>image.Jfif.ResolutionUnits</key>
        <value>none</value>
      </entry>
      <entry>
        <key>image.Jfif.Version</key>
        <value>1.2</value>
      </entry>
      <entry>
        <key>image.Jfif.XResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jfif.YResolution</key>
        <value>100 dots</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component1</key>
        <value>Y component: Quantization table 0, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component2</key>
        <value>Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.Component3</key>
        <value>Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert</value>
      </entry>
      <entry>
        <key>image.Jpeg.CompressionType</key>
        <value>Baseline</value>
      </entry>
      <entry>
        <key>image.Jpeg.DataPrecision</key>
        <value>8 bits</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageHeight</key>
        <value>300 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.ImageWidth</key>
        <value>750 pixels</value>
      </entry>
      <entry>
        <key>image.Jpeg.NumberofComponents</key>
        <value>3</value>
      </entry>
      <entry>
        <key>image.bits-per-pixel</key>
        <value>24</value>
      </entry>
      <entry>
        <key>width</key>
        <value>750</value>
      </entry>
    </field>
  </data>
  <data class='generated.DocumentInterstices' id='ni_78367' url='https://interstices.info/jcms/ni_78367/modeliser-les-interactions-au-fil-du-temps'>
    <field name='title'>Modéliser les interactions au fil du temps</field>
    <field name='categories'>
      <item id='jalios_5001' class='com.jalios.jcms.Category'>Navigation/Rubriques/Découvrir</item>
      <item id='mf_46788' class='com.jalios.jcms.Category'>Tags/Réseau</item>
      <item id='i_62034' class='com.jalios.jcms.Category'>CatTemporaire</item>
    </field>
    <field name='pdate' time='1450710000000'>2015-12-21T16:00:00+01:00</field>
    <field name='udate' time='1399381872383'>2014-05-06T15:11:12+02:00</field>
    <field name='version' major='1' minor='61'>1.61</field>
    <field name='mainLanguage'>fr</field>
    <field name='pstatus'>0</field>
    <field name='workspace' id='j_4' class='com.jalios.jcms.workspace.Workspace'>Interstices</field>
    <field name='templates'>
      <item>full.default</item>
      <item>query.default</item>
    </field>
    <field name='author' id='c_26560' class='com.jalios.jcms.Member' login='marie-odile'>Marie-Odile Cordier</field>
    <field name='opAuthor' id='c_6773' class='com.jalios.jcms.Member' login='christine-a'>Christine Leininger</field>
    <field name='cdate' time='1399381872383'>2014-05-06T15:11:12+02:00</field>
    <field name='mdate' time='1462881660438'>2016-05-10T14:01:00+02:00</field>
    <field name='resume' abstract='true'>Suivis partout, tout le temps : nos téléphones mobiles, nos appareils photos, nos tablettes, nos montres et bientôt nos vêtements, tous ces objets du quotidien sont désormais capables d’enregistrer nos déplacements et nos interactions. Et permettent de les analyser, mais avec quels outils ?</field>
    <field name='chapo'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Suivis partout, tout le temps : nos téléphones mobiles, nos appareils photos, nos tablettes, nos montres et bientôt nos vêtements, tous ces objets du quotidien sont désormais capables d’enregistrer nos déplacements et nos interactions. On peut bien sûr s’inquiéter des dangers encourus par notre vie privée et notre liberté même : entre de mauvaises mains, ces données permettraient de nous surveiller et de nous manipuler. Elles permettent déjà aux scientifiques de mieux comprendre les comportements individuels et la société. Mais avec quels outils ?&lt;/p&gt;&lt;/div&gt;</field>
    <field name='imageChapeau'>upload/docs/image/jpeg/2015-12/parc-enfants.jpg</field>
    <field name='legendeImageChapeau'>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Photo : Julius Singara / &lt;a class=&quot;lienExterne&quot; href=&quot;https://flic.kr/p/4H18MF&quot; target=&quot;_blank&quot;&gt;Flickr&lt;/a&gt;- Licence CC-BY.&lt;/p&gt;&lt;/div&gt;</field>
    <field name='texte'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;// &lt;![CDATA[&#13;&#10;&#13;&#10;// ]]&gt;&lt;/script&gt;&lt;![CDATA[&#13;&#10;&#13;&#10;// ]]&gt;Tout au long de la journée, vous entrez en contact avec de nombreuses personnes. Imaginez que toutes ces interactions soient enregistrées. Le matin, vous emmenez votre fils à l’école à pied. En route, vous rencontrez un de ses amis et sa maman, et finissez le chemin ensemble. Arrivés à l’école, les enfants retrouvent leurs copains. Quant à vous, vous retrouvez certains parents avec lesquels vous sympathisez, et décidez d’aller prendre un café. Une fois votre café pris, vous allez au bureau où vous retrouvez vos collègues. Vous filez à une réunion, après laquelle vous avez rendez-vous avec un collègue pour lui expliquer un projet. Pendant ce temps, les enfants sont en classe, puis sortent en récréation et jouent en petits groupes. De temps en temps, un enfant change de groupe...&lt;/p&gt;&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;p&gt;Habituellement, &lt;a class=&quot;lienPlus&quot; href=&quot;javascript:ouvreEncart(1,%20600,%20500%20);&quot;&gt;les interactions comme celles-ci&lt;/a&gt; sont étudiées sous forme de réseaux, ou graphes. Les individus sont représentés par des nœuds et un lien est présent entre deux nœuds si les deux individus correspondants ont été en contact. Autrement dit, on considère des ensembles de paires (&lt;em&gt;x&lt;/em&gt;, &lt;em&gt;y&lt;/em&gt;) indiquant que les individus &lt;em&gt;x&lt;/em&gt; et &lt;em&gt;y&lt;/em&gt; ont interagi. La figure ci-dessous montre un petit exemple.&lt;/p&gt;&lt;div align=&quot;center&quot;&gt;&lt;img title=&quot;fig-x1.&quot; src=&quot;upload/docs/image/gif/2015-12/fig-x1.gif&quot; alt=&quot;fig-x1&quot; width=&quot;300&quot; height=&quot;182&quot; /&gt;&lt;/div&gt;&lt;p class=&quot;legende&quot;&gt;Un réseau d’interactions entre des individus. Par exemple, l’individu vert foncé est en relation avec le vert clair, le bleu clair, le violet et le jaune, alors que l’individu rouge n’interagit qu’avec le violet. Les individus vert clair, vert foncé, violet et jaune sont tous en relation les uns avec les autres. Il en va de même pour les individus bleu clair, bleu foncé et vert clair.&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;Dans une société, certains groupes d’individus sont densément reliés : il y a beaucoup d&apos;interactions entre eux. C’est par exemple le cas des membres d’une famille, de groupes d’amis ou de collègues. On peut évaluer ceci par la densité d’un groupe dans un réseau : il s’agit de la probabilité, quand on choisit deux individus du groupe au hasard, qu’il y ait un lien entre eux. Autrement dit, la densité indique à quel point tous les membres du groupe interagissent entre eux : si elle est égale à 0 alors il n’y a aucune interaction, et plus elle se rapproche de 1 plus on est dans une situation où tout le monde interagit avec tout le monde dans le groupe. Ainsi, dans l’exemple ci-dessus, la densité entre les enfants est plus grande qu’entre enfants et adultes : les enfants interagissent plus entre eux qu’avec les adultes. De même, la densité entre adultes est élevée, et elle l’est également entre les membres d’une même famille.&lt;/p&gt;&lt;p&gt;Formellement, pour un ensemble de &lt;em&gt;n&lt;/em&gt; noeuds entre lesquels &lt;em&gt;m&lt;/em&gt; liens sont présents, la densité &lt;em&gt;δ&lt;/em&gt; est égale au nombre de liens &lt;em&gt;m&lt;/em&gt; divisé par le nombre maximal de liens possibles entre &lt;em&gt;n&lt;/em&gt; nœuds soit &lt;em&gt;n&lt;/em&gt; . (&lt;em&gt;n&lt;/em&gt;-1) / 2. On a donc &lt;em&gt;δ&lt;/em&gt; = 2 . &lt;em&gt;m&lt;/em&gt; / (&lt;em&gt;n&lt;/em&gt; . (&lt;em&gt;n&lt;/em&gt;-1))&lt;/p&gt;&lt;p&gt;Parfois, les individus d’un groupe interagissent carrément avec tous les autres membres du groupe. Lorsqu’on prend deux individus au hasard, on est sûr qu’ils interagissent, la densité du groupe est alors égale à 1. Un tel groupe est appelé une clique dans le réseau. En voyez-vous dans la figure ci-dessus ? Elle contient en particulier une clique de 4 individus. Les cliques sont étudiées par les scientifiques depuis longtemps, car elles sont révélatrices de groupes particuliers et ont des propriétés algorithmiques extrêmement fortes.&lt;/p&gt;&lt;p&gt;Ces notions de réseaux, de densité et de cliques ont donné lieu à de nombreux résultats mathématiques et à des applications variées, aussi bien en &lt;a href=&quot;jcms/c_42760/des-peptides-a-explorer&quot;&gt;bioinformatique&lt;/a&gt; que dans les télécommunications. Toutefois, elles ignorent un point essentiel : la dynamique des interactions, c’est-à-dire le fait qu’elles ont lieu à des moments spécifiques dans le temps. Difficile dans ces conditions d’obtenir un éclairage sur la régularité des relations, sur les événements inhabituels, sur la diffusion de maladies ou de rumeurs entre individus... Beaucoup d’information est ainsi perdue, quel dommage !&lt;/p&gt;&lt;h2&gt;Pourquoi étudier la dynamique des interactions&lt;/h2&gt;&lt;p&gt;De très nombreuses situations peuvent se modéliser comme des interactions au cours du temps : des appels téléphoniques, du trafic réseau, des échanges de messages, des achats en ligne, des flux financiers, des contacts physiques, même l’activité cérébrale, et bien d’autres... Mieux comprendre la structure et la dynamique de ces interactions a donc de nombreuses applications : la détection d’attaques menées par plusieurs machines sur l’internet, la lutte contre les fraudes à la carte bancaire ou le blanchiment d’argent, la distribution de contenus comme des actualités sur les téléphones mobiles, l’optimisation des services et produits proposés aux usagers, la détection de signes avant-coureurs de crises d’épilepsie...&lt;/p&gt;&lt;p&gt;Par exemple, dans des forums de discussion entre personnes sur l’internet, la densité des interactions révèle des événements comme des controverses ou des scissions. On peut détecter et gérer au mieux de tels événements directement en étudiant la structure et la dynamique des échanges, sans avoir besoin d’en analyser le contenu, c&apos;est-à-dire le texte des messages. Ceci permet de préserver la confidentialité des échanges, ce qui n’est pas crucial sur un forum public mais prend une tout autre dimension si les échanges ne sont pas publics, par téléphone par exemple, ou par messagerie personnelle.&lt;/p&gt;&lt;p&gt;Autre exemple, les séries d’interactions denses dans du trafic réseau sur l’internet peuvent révéler des ensembles de machines se coordonnant, potentiellement pour en attaquer une autre. Prévenir de telles attaques est crucial, et être capable d’analyser finement des séries d’interactions temporelles ouvre de nouvelles perspectives très prometteuses dans cette direction.&lt;/p&gt;&lt;h2&gt;Comment étudier la dynamique des interactions&lt;/h2&gt;&lt;p&gt;Depuis quelques années, dans ce qu’on appelle la science des réseaux, beaucoup d’efforts sont consacrés à l’étude de la dynamique des réseaux. Beaucoup d’idées intéressantes ont été proposées, mais la plupart reviennent d’une façon ou d’une autre à couper le temps en tranches : on regarde qui a interagi avec qui pendant une première période de temps, puis qui a interagi avec qui pendant la seconde période, puis pendant la suivante, et ainsi de suite. On obtient ainsi une série de réseaux, dont on peut étudier les propriétés au fil du temps.&lt;/p&gt;&lt;p&gt;Pour l’ensemble de contacts de notre exemple initial, on étudiera par exemple le réseau des individus interagissant de 7 heures à 8 heures, de 8 heures à 9 heures, de 9 heures à 10 heures, etc. On obtiendra alors un réseau pour chaque tranche d’une heure, sans distinction de la chronologie des rencontres  à l&apos;intérieur de chaque tranche horaire. L’étude de la dynamique des interactions sera ramenée à l’étude de cette série de réseaux. On regardera par exemple l’évolution de leur densité, ou encore si certains groupes denses à un moment donné restent denses au cours du temps.&lt;/p&gt;&lt;p&gt;Dans cette approche où l&apos;on discrétise le temps de manière uniforme, un problème bien identifié est celui de la granularité de la discrétisation. Pour plus de précision, faudrait-il considérer des tranches d&apos;un quart d&apos;heure, ou d&apos;une minute ? Et pourquoi pas des tranches de taille variable ?  Dans cet exemple on pourrait distinguer le temps du trajet, de 8 h à 8 h 30, puis le temps de classe, de 8 h 30 à 11h30, la pause de midi, de 11 h 30 à 13 h 30, etc. &lt;/p&gt;&lt;p&gt;Plus grave, une fois les interactions représentées par une série de réseaux, on ne sait pas vraiment comment étudier cette série. Par exemple, on peut regarder comment évolue la densité du réseau au cours du temps, mais comment pourrait-on définir une densité des interactions au cours du temps ?&lt;/p&gt;&lt;p&gt;Pour répondre à cette problématique, une nouvelle approche est actuellement développée. Plutôt que de transformer les interactions en séries de réseaux qu’on espère étudier grâce aux outils de la science des réseaux, il s’agit de développer directement une science des interactions. L’objet considéré est alors un ensemble de triplets (&lt;em&gt;t&lt;/em&gt;, &lt;em&gt;x&lt;/em&gt;, &lt;em&gt;y&lt;/em&gt;) indiquant le fait que les individus &lt;em&gt;x&lt;/em&gt; et &lt;em&gt;y&lt;/em&gt; ont interagi à l’instant &lt;em&gt;t&lt;/em&gt;, comme représenté sur la figure ci-dessous. De cette façon, on n’a plus à transformer les données, à se débarrasser du temps en le découpant en tranches : on &lt;span class=&quot;lienPlus&quot;&gt;intègre le temps&lt;/span&gt; directement à la description des interactions.&lt;/p&gt;&lt;p&gt;&lt;img title=&quot;fig-y2.&quot; src=&quot;upload/docs/image/gif/2015-12/fig-y2.gif&quot; alt=&quot;fig-y2&quot; width=&quot;700&quot; height=&quot;186&quot; /&gt;&lt;/p&gt;&lt;p class=&quot;legende&quot;&gt;Une série d&apos;interactions entre cinq individus. Les individus sont notés a, b, c, d et e. Le temps est découpé en instants numérotés à partir de 0. Chaque lien représente une interaction à un certain instant. Par exemple, à l&apos;instant 5, b et c sont en interaction, ainsi que d et e. Chaque zone colorée indique un sous-ensemble d&apos;interactions particulièrement denses. Cette densité est temporelle, les interactions sont nombreuses entre deux instants proches. Elle est aussi structurelle, les individus impliqués interagissent presque tous entre eux.&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;La question posée est alors de définir une notion de densité qui convienne à cette nouvelle représentation, afin de mesurer non seulement à quel point tout le monde interagit avec tout le monde mais également à quel point cela se produit tout le temps. On obtient alors une notion simple à énoncer : la densité des interactions est la probabilité, quand on prend deux individus au hasard et un instant au hasard, que ces deux individus interagissent à cet instant-là.&lt;/p&gt;&lt;p&gt;Formellement, on considère un ensemble de &lt;em&gt;n&lt;/em&gt; nœuds dont on observe les interactions pendant une durée dont le nombre total d&apos;instants est noté τ. On note &lt;em&gt;T&lt;/em&gt;(&lt;em&gt;x&lt;/em&gt;, &lt;em&gt;y&lt;/em&gt;) le nombre d’instants où a été observée une interaction entre &lt;em&gt;x&lt;/em&gt; et &lt;em&gt;y. &lt;/em&gt;La densité &lt;em&gt;δ&lt;/em&gt; se calcule avec la formule suivante, où &lt;em&gt;x&lt;/em&gt; et &lt;em&gt;y&lt;/em&gt; parcourent l&apos;ensemble des nœuds :&lt;/p&gt;&lt;p&gt;\[\delta = \frac{2\cdot \sum_{x,y} T(x,y)}{n\cdot(n-1)\cdot {\tau}}\]&lt;/p&gt;&lt;p&gt;Une fois cette notion de densité définie, une foule d&apos;autres notions en découlent. En particulier, une clique dans une série d’interactions est tout simplement un ensemble d’individus et un intervalle de temps tels que tous ces individus interagissent en permanence pendant cet intervalle de temps : leurs interactions ont une densité égale à 1. Ainsi, dans l’exemple des contacts sur le chemin de l’école, la densité entre vous et votre fils est égale à 1 pendant la durée du trajet : vous interagissez en permanence et donc formez une clique. Vous formez également une clique avec les parents d’élèves qui vous accompagnent prendre un café, pendant la durée de cette pause. Et ainsi de suite.&lt;/p&gt;&lt;p&gt;Cette nouvelle approche, qui préfère définir une science des séries d’interactions plutôt que de transformer les séries d’interactions en réseaux plus ou moins dynamiques, est en plein développement. Elle permet d’intégrer de façon cohérente la nature à la fois structurelle et temporelle des interactions : qui interagit avec qui, et quand.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</item>
    </field>
    <field name='imagette'>upload/docs/image/jpeg/2015-12/parc-enfants115.jpg</field>
    <field name='encarts'>
      <item>&lt;div class=&quot;wysiwyg classic&quot;&gt;&lt;h3&gt;Mesurer les interactions entre individus&lt;/h3&gt;&lt;p&gt;En pratique, les interactions ne sont en général pas connues de façon aussi parfaite que dans l’exemple donné. Elles sont plutôt obtenues par des capteurs capables de détecter à intervalles de temps réguliers (par exemple toutes les vingt secondes) les autres capteurs qui sont à proximité (par exemple à moins de deux mètres). On fait alors porter des capteurs de ce type à l’ensemble des individus que l’on veut étudier (par exemple les élèves d’une école, le personnel d’un hôpital, ou encore des animaux domestiques ou sauvages). Chaque capteur enregistre les interactions qu’il détecte et on rassemble ensuite les données collectées. Celles-ci sont partielles et contiennent des erreurs. Par exemple, si un contact entre deux individus est trop bref, aucun des deux capteurs ne va le détecter et il n’apparaîtra pas.  À l’inverse, les capteurs de deux personnes séparées par une cloison peuvent détecter une interaction, alors que les individus ne sont pas même conscients de leur proximité. Par ailleurs, un contact prolongé est vu comme une série de contacts ponctuels (chaque fois que le capteur a sondé son environnement). Reconstruire les interactions réelles et s’assurer qu’elles ont du sens est donc un défi en soi.&lt;/p&gt;&lt;/div&gt;</item>
    </field>
    <field name='auteurs'>
      <item id='p_83443' class='generated.Auteur'>Latapy</item>
    </field>
    <field name='moissonnable'>false</field>
  </data>
</dataset>

